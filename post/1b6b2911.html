<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>大数据基础知识总结 | 蜡笔梦工厂</title><meta name="author" content="Lorinda"><meta name="copyright" content="Lorinda"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="本文详细总结了大数据的基础知识，包括核心概念与技术体系、云计算与物联网关联、Hadoop生态（HDFS、HBase）、NoSQL数据库及MapReduce分布式计算框架等核心内容，适合大数据初学者入门学习。">
<meta property="og:type" content="article">
<meta property="og:title" content="大数据基础知识总结">
<meta property="og:url" content="http://labi.com/post/1b6b2911.html">
<meta property="og:site_name" content="蜡笔梦工厂">
<meta property="og:description" content="本文详细总结了大数据的基础知识，包括核心概念与技术体系、云计算与物联网关联、Hadoop生态（HDFS、HBase）、NoSQL数据库及MapReduce分布式计算框架等核心内容，适合大数据初学者入门学习。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112844.png">
<meta property="article:published_time" content="2024-05-23T02:30:00.000Z">
<meta property="article:modified_time" content="2025-09-02T07:10:30.372Z">
<meta property="article:author" content="Lorinda">
<meta property="article:tag" content="NoSQL">
<meta property="article:tag" content="Hadoop">
<meta property="article:tag" content="HDFS">
<meta property="article:tag" content="MapReduce">
<meta property="article:tag" content="大数据">
<meta property="article:tag" content="云计算">
<meta property="article:tag" content="物联网">
<meta property="article:tag" content="HBase">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112844.png"><link rel="shortcut icon" href="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2024_1123_155552.png"><link rel="canonical" href="http://labi.com/post/1b6b2911.html"><link rel="preconnect" href="//cdnjs.cloudflare.com"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/node-snackbar/0.1.16/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.36/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!true && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?bf06f078fafddfd82b474ce179303666";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
btf.addGlobalFn('pjaxComplete', () => {
  _hmt.push(['_trackPageview',window.location.pathname])
}, 'baidu_analytics')
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":{"enable":true},"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"已切换为繁体中文","cht_to_chs":"已切换为简体中文","day_to_night":"已切换为深色模式","night_to_day":"已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdnjs.cloudflare.com/ajax/libs/egjs-infinitegrid/4.12.0/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: true,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '大数据基础知识总结',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><link rel="stylesheet" href="/css/wave.css"><link rel="stylesheet" href="/css/readPercent.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_2264842_b004iy0kk2b.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="/css/loading.css"><link rel="stylesheet" href="/css/about.css"><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/sweetalert2@11"></script><link rel="stylesheet" href="https://fastly.jsdelivr.net/gh/HCLonely/images@master/others/heartbeat.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/l-lin/font-awesome-animation/dist/font-awesome-animation.min.css"  media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/ethan4116-blog/lib/css/plane_v2.css"><link rel="stylesheet" href="/css/universe.css"><link rel="stylesheet" href="/css/progress_bar.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://cdn1.tianli0.top/npm/element-ui@2.15.6/packages/theme-chalk/lib/index.css"><span id="fps"></span><svg aria-hidden="true" style="position:absolute; overflow:hidden; width:0; height:0"><symbol id="icon-sun" viewBox="0 0 1024 1024"><path d="M960 512l-128 128v192h-192l-128 128-128-128H192v-192l-128-128 128-128V192h192l128-128 128 128h192v192z" fill="#FFD878" p-id="8420"></path><path d="M736 512a224 224 0 1 0-448 0 224 224 0 1 0 448 0z" fill="#FFE4A9" p-id="8421"></path><path d="M512 109.248L626.752 224H800v173.248L914.752 512 800 626.752V800h-173.248L512 914.752 397.248 800H224v-173.248L109.248 512 224 397.248V224h173.248L512 109.248M512 64l-128 128H192v192l-128 128 128 128v192h192l128 128 128-128h192v-192l128-128-128-128V192h-192l-128-128z" fill="#4D5152" p-id="8422"></path><path d="M512 320c105.888 0 192 86.112 192 192s-86.112 192-192 192-192-86.112-192-192 86.112-192 192-192m0-32a224 224 0 1 0 0 448 224 224 0 0 0 0-448z" fill="#4D5152" p-id="8423"></path></symbol><symbol id="icon-moon" viewBox="0 0 1024 1024"><path d="M611.370667 167.082667a445.013333 445.013333 0 0 1-38.4 161.834666 477.824 477.824 0 0 1-244.736 244.394667 445.141333 445.141333 0 0 1-161.109334 38.058667 85.077333 85.077333 0 0 0-65.066666 135.722666A462.08 462.08 0 1 0 747.093333 102.058667a85.077333 85.077333 0 0 0-135.722666 65.024z" fill="#FFB531" p-id="11345"></path><path d="M329.728 274.133333l35.157333-35.157333a21.333333 21.333333 0 1 0-30.165333-30.165333l-35.157333 35.157333-35.114667-35.157333a21.333333 21.333333 0 0 0-30.165333 30.165333l35.114666 35.157333-35.114666 35.157334a21.333333 21.333333 0 1 0 30.165333 30.165333l35.114667-35.157333 35.157333 35.157333a21.333333 21.333333 0 1 0 30.165333-30.165333z" fill="#030835" p-id="11346"></path></symbol></svg><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-categories-card@1.0.0/lib/categorybar.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.css" /><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><div class="loading-img"></div><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><script>window.paceOptions = {
  restartOnPushState: false
}

btf.addGlobalFn('pjaxSend', () => {
  Pace.restart()
}, 'pace_restart')

</script><link rel="stylesheet" href="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2024_1123_160015.png"/><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js"></script><div id="web_bg" style="background-image: url(https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/af380cb8a5ed3f047e66dbfe731f488.jpg);"></div><div id="an_music_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2024_1123_155535.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">29</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">109</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><i class="fa-fw icon-hexoa-homezhuyefangzijia"></i><svg class="icon fas fa-home" aria-hidden="true"><use xlink:href="#icon-hexoa-homezhuyefangzijia"></use></svg><span> 首页</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/comments/"><i class="fa-fw icon-hexoshouhuiban"></i><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-hexoshouhuiban"></use></svg><span> 留言板</span></a></div><div class="menus_item"><a class="site-page group faa-parent animated-hover" href="javascript:void(0);"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-hexohuanjiaowenzhang"></use></svg><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/categories/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-hexofenlei"></use></svg><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-hexobiaoqian"></use></svg><span> 标签</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/archives/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-hexoguidang"></use></svg><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover" href="javascript:void(0);"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-hexoicon_liebiao"></use></svg><span> 娱乐</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/music/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-hexoyinle"></use></svg><span> 音乐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/gallery/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-hexotubiaozhizuomoban"></use></svg><span> 相册</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/link/"><i class="fa-fw icon-hexopengyou"></i><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-hexopengyou"></use></svg><span> 友链</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/about/"><i class="fa-fw icon-hexowode"></i><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-hexowode"></use></svg><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112844.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2024_1123_155552.png" alt="Logo"><span class="site-name">蜡笔梦工厂</span></a><a class="nav-page-title" href="/"><span class="site-name">大数据基础知识总结</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i></span></div><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><i class="fa-fw icon-hexoa-homezhuyefangzijia"></i><svg class="icon fas fa-home" aria-hidden="true"><use xlink:href="#icon-hexoa-homezhuyefangzijia"></use></svg><span> 首页</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/comments/"><i class="fa-fw icon-hexoshouhuiban"></i><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-hexoshouhuiban"></use></svg><span> 留言板</span></a></div><div class="menus_item"><a class="site-page group faa-parent animated-hover" href="javascript:void(0);"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-hexohuanjiaowenzhang"></use></svg><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/categories/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-hexofenlei"></use></svg><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-hexobiaoqian"></use></svg><span> 标签</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/archives/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-hexoguidang"></use></svg><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover" href="javascript:void(0);"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-hexoicon_liebiao"></use></svg><span> 娱乐</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/music/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-hexoyinle"></use></svg><span> 音乐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/gallery/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-hexotubiaozhizuomoban"></use></svg><span> 相册</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/link/"><i class="fa-fw icon-hexopengyou"></i><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-hexopengyou"></use></svg><span> 友链</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/about/"><i class="fa-fw icon-hexowode"></i><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-hexowode"></use></svg><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div><div id="randomPost"><a class="site-page social-icon search" href="javascript:;" onclick="randomPost()" title="随机访问一篇文章"><i class="fas fa-circle-notch fa-fw"></i></a></div></nav><div id="post-info"><h1 class="post-title">大数据基础知识总结</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-05-23T02:30:00.000Z" title="发表于 2024-05-23 10:30:00">2024-05-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-09-02T07:10:30.372Z" title="更新于 2025-09-02 15:10:30">2025-09-02</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/">大数据技术</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">41.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>141分钟</span></span><span class="post-meta-separator">|</span><span id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="twikoo_visitors"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>大数据应用的三个层次：一只猫<br>
大数据技术：彩存储因<br>
大数据计算模式：批、流、图、查分<br>
云→大 计算基础<br>
大→云 用武之地<br>
物→大 重要来源<br>
大→物 数据分析的支撑<br>
云→物 海量的数据存储能力<br>
物→云 广阔的应用空间<br>
云：关键技术：虚拟化、分布式存储、分布式计算、多租户 IPS<br>
物：识别与感知（二维码、RFID、传感器）、网络与通信、数据挖掘与融合技术<br>
云：整合和优化各种IT资源，并以廉价的方式提供给用户<br>
物：物物相连，应用创新，与智慧产品息息相关<br>
大：数据存储分析处理</p>
<p>Hadoop：可笑扩容成鲤鱼<br>
put上传：Linux→HDFS<br>
get下载：HDFS→Linux</p>
<p>HDFS特性、目标：</p>
<ol>
<li>兼容廉价硬件</li>
<li>流数据读写</li>
<li>一次写入，多次读取。写入关闭后不可修改，只读，一致性</li>
<li>跨平台兼容</li>
</ol>
<p>局限：</p>
<ol>
<li>不能实时访问</li>
<li>无法存储大量小文件</li>
<li>不支持多用户写入及任意修改文件</li>
</ol>
<p>HDFS主从：一个名称多个数据<br>
namenode是访问HDFS的唯一入口<br>
HDFS中，同一时间只有一个客户端能获取到主节点（名称节点 ）上的契约</p>
<table>
<thead>
<tr>
<th><strong>维度</strong></th>
<th><strong>名称节点</strong></th>
<th><strong>数据节点</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>存储内容</strong></td>
<td>元数据（文件系统结构、块映射）</td>
<td>实际数据块（文件拆分后的二进制数据）</td>
</tr>
<tr>
<td><strong>存储介质</strong></td>
<td>本地磁盘（FsImage/EditLog）+ 内存</td>
<td>本地磁盘（数据块文件）</td>
</tr>
<tr>
<td><strong>数据冗余</strong></td>
<td>通常需手动配置备份（如双 NameNode）</td>
<td>自动按副本数冗余（默认 3 副本）</td>
</tr>
<tr>
<td><strong>存储目的</strong></td>
<td>管理文件系统逻辑结构</td>
<td>存储物理数据</td>
</tr>
<tr>
<td>namenode：管理文件系统的命名空间，维护文件块与数据块之间的映射关系</td>
<td></td>
<td></td>
</tr>
<tr>
<td>FsImage：记录文件系统树及所有文件、目录的元数据</td>
<td></td>
<td></td>
</tr>
<tr>
<td>EditLog：记录所有针对文件的创建删除重命名</td>
<td></td>
<td></td>
</tr>
<tr>
<td>DataNode：是HDFS工作节点，负责存储与读取数据，响应客户端读写请求，并按名称节点指令完成数据块的创建、删除及冗余复制操作。</td>
<td></td>
<td></td>
</tr>
<tr>
<td>数据节点定期向名称节点发心跳，未按时发送会被标记为 “死机”，接受名称节点的调度。</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>数据块是数据读写的基本单位</p>
<p>HDFS设计需求：透明性、并发控制、文件复制、硬件和操作系统的异构性、可伸缩性、容错及安全性<br>
透明：一定程度的访问透明，完全的位置透明、伸缩透明、性能透明<br>
并发：只允许一个程序写入<br>
复制：多副本机制<br>
容错：多副本、故障自动检测、恢复<br>
安全性弱</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://images2018.cnblogs.com/blog/1230701/201804/1230701-20180417210519233-442718251.png" alt="image.png"><br>
1. 第二名称节点周期性与名称节点通信→停止使用EditLog文件，将 HDFS 更新记录写入新的文件 EditLog.new<br>
2. SecondaryNameNode通过 HTTP GET 方式从NameNode节点上→获取 EditLog 和 FsImage 文件<br>
3. 将获取的文件加载到本地内存→逐条执行 EditLog 操作并应用到 FsImage 上→合并生成 FsImage.ckpt<br>
4. 将 FsImage.ckpt 通过 HTTP POST 方式传回名称节点<br>
5. 名称节点用 FsImage.ckpt 替换原 FsImage，用 EditLog.new 替换原 EditLog<br>
出于可扩展性和容错性考虑，第二名称节点应单独运行在一台非名称节点的机器上<br>
为了有效解决EditLog逐渐变大带来的问题<br>
定期把名称节点里的一些元数据信息进行合并整理<br>
保存名称节点对HFDS元数据的备份，并减少名称节点的重启时间</p>
<p>块默认128MB</p>
<ul>
<li>好处：
<ul>
<li>支持<strong>大规模文件存储</strong></li>
<li><strong>简化</strong>系统设计</li>
<li>适合<strong>数据备份</strong></li>
</ul>
</li>
</ul>
<p>命名空间：HDFS 中用于<strong>唯一标识文件</strong> / 目录的逻辑结构，包含目录、文件和块，避免命名冲突。整个HDFS集群只有一个</p>
<p>数据存取：核心，以机架为基础<br>
多副本冗余存储<br>
优点：加快数据传输速度、容易检查数据错误、保证数据的可靠性</p>
<ul>
<li><strong>第 1 副本</strong>：上传节点（或集群外随机选磁盘不满、CPU 不忙的节点）。</li>
<li><strong>第 2 副本</strong>：与第 1 副本<strong>不同机架</strong>的节点。</li>
<li><strong>第 3 副本</strong>：与第 2 副本<strong>同机架</strong>的其他节点（与第一个副本不同节点）。</li>
<li><strong>更多副本</strong>：随机分配节点。</li>
</ul>
<p>HDFS的硬件出错是常态，不是异常<br>
3种错误情形出现会有相应的机制检测数据错误和进行自动恢复：<br>
（1）名称节点出错；（2）数据节点出错；（3）数据出错</p>
<ul>
<li><strong>读文件</strong>
<ul>
<li>客户端向名称节点查询文件块位置，直接到对应数据节点读取数据。<br>
注：<strong>名称节点并不参与数据的传输</strong>。使得一个文件的数据能够在不同的数据节点上实现并发访问，大大提高数据访问速度</li>
</ul>
<ol>
<li>客户端访问名称节点，查询并获取文件的数据块位置列表，返回输入流对象。</li>
<li><strong>就近</strong>挑选一台数据节点服务器，请求建立输入流 。</li>
<li>数据节点向输入流中中写数据。</li>
<li>关闭输入流。<br>
conf.set(“fs.defaultFS”, “hdfs://localhost:9000”);<br>
String content = d.readLine();</li>
</ol>
</li>
<li><strong>写文件</strong>
<ul>
<li>名称节点分配存储位置，客户端将数据写入数据节点，并由名称节点管理冗余复制。</li>
</ul>
<ol>
<li>客户端向名称发出写文件请求。</li>
<li>检查是否已存在文件、检查权限。若通过检查，返回输出流对象。</li>
<li>客户端<strong>按128MB的块</strong>切分文件。</li>
<li>名称节点返回可写数据节点列表<br>
客户端将数据块与节点列表发送给最近的节点 ，形成管道。<br>
客户端逐 packet 写入数据，管道内节点依次转发</li>
<li>每个数据节点写完一个块后，会返回<strong>确认信息</strong>。</li>
<li>写完数据，关闭输输出流。</li>
<li>发送完成信号给名称节点。<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://images2018.cnblogs.com/blog/1230701/201804/1230701-20180413185643839-1854886696.png" alt="image.png"><br>
FSDataOutputStream os = fs.create(new Path(filename));<br>
FileSystem fs = FileSystem.get(conf);<br>
boolean created = parentDir.mkdirs();</li>
</ol>
</li>
</ul>
<p>copyToLocalFile(是否删除源文件true删false保留，HDFS源文件路径，本地目标文件路径，是否处理校验文件)</p>
<p><strong>HDFS体系结构的局限性</strong>：<br>
名称节点唯一导致：  <br>1. <strong>命名空间受限</strong>：名称节点内存大小限制其容纳对象数量  <br>2. <strong>性能瓶颈</strong>：集群吞吐量受限于单个名称节点吞吐量  <br>3. <strong>隔离问题</strong>：无法对不同应用程序隔离  <br>4. <strong>可用性风险</strong>：名称节点故障会导致整个集群不可用</p>
<p>hdfs dfs -appendToFile local.txt text.txt<br>
hdfs dfs -rmdir dir1/dir2</p>
<p>HBase是一个<strong>稀疏，多维度，有序</strong>的映射表<br>
索引：行键、列族、列限定符、时间戳<br>
HDFS不支持随机写入<br>
HBase的实现包括三个主要的<strong>功能组件</strong><br>
<strong>1)库函数：连接到每个客户端</strong><br>
<strong>2)一个Master主服务器</strong><br>
<strong>3)许多个Region 服务器</strong></p>
<table>
<thead>
<tr>
<th>对比维度</th>
<th>传统数据库</th>
<th>HBase</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>数据类型</strong></td>
<td>采用<strong>关系模型</strong>，有丰富数据类型和存储方式</td>
<td>数据模型简单，数据存储为未经解释的<strong>字符串</strong>，用户自行解析不同数据类型</td>
</tr>
<tr>
<td><strong>数据操作</strong></td>
<td><strong>操作丰富</strong>，含插入、删除、更新、查询等，涉及复杂多表连接</td>
<td><strong>操作简单</strong>，有插入、查询、删除、清空等，无复杂表间关系，仅<strong>单表主键查询，不支持表连接</strong></td>
</tr>
<tr>
<td><strong>存储模式</strong></td>
<td>基于<strong>行模式存储</strong>，元组或行连续存于磁盘页，读取可能浪费资源</td>
<td>基于<strong>列存储</strong>，列族独立存于不同文件，降低 I/O 开销，支持<strong>并发查询</strong>，列族数据压缩比高</td>
</tr>
<tr>
<td><strong>数据索引</strong></td>
<td>可针对不同列构建复杂<strong>多个索引</strong></td>
<td>只有<strong>行键一个索引</strong>，可通过 Hadoop MapReduce 生成索引表</td>
</tr>
<tr>
<td><strong>数据维护</strong></td>
<td>更新用新值替换旧值，<strong>旧值被覆盖</strong></td>
<td>更新生成新版本，<strong>旧版本保留</strong></td>
</tr>
<tr>
<td><strong>可伸缩性</strong></td>
<td><strong>难横向扩展</strong>，纵向扩展空间有限</td>
<td>为灵活<strong>水平扩展</strong>开发，可通过增减集群硬件实现性能伸缩</td>
</tr>
<tr>
<td><strong>局限性</strong></td>
<td>——</td>
<td><strong>不支持事务</strong>，无法实现跨行原子性</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th><strong>概念</strong></th>
<th><strong>定义与特性</strong></th>
<th><strong>作用与特点</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>表（Table）</strong></td>
<td>数据组织的<strong>最高单位</strong>，由<strong>行和列族</strong>组成，列族是列的分组。</td>
<td>类似传统数据库的表，但<strong>列族需提前定义</strong>，<strong>列可动态添加</strong>。</td>
</tr>
<tr>
<td><strong>行（Row）</strong></td>
<td><strong>表的基本数据单元</strong>，由<strong>行键</strong>（Row Key）唯一标识，按<strong>行键字典序排序</strong>存储。<br>行键可以是任意字符，保存为字节数组</td>
<td>访问方式：单行键查询、行键区间查询、全表扫描；行键设计影响数据读取效率。</td>
</tr>
<tr>
<td><strong>列族（Column Family）</strong></td>
<td>列的分组，<strong>是访问控制、存储优化的基本单元</strong>，需在表创建时定义，数量有限（几十个）。</td>
<td><strong>同列族数据类型一致</strong>，压缩率高；可配置访问模式（如内存存储），支持权限控制。</td>
</tr>
<tr>
<td><strong>列限定符（Column Qualifier）</strong></td>
<td>列族下的具体列标识，<strong>无需提前定义</strong>，动态添加，视为<strong>字节数组</strong>。</td>
<td>与列族组合成完整列名（如<code>列族:限定符</code>），灵活扩展列结构。</td>
</tr>
<tr>
<td><strong>单元格（Cell）</strong></td>
<td>由行键、列族、列限定符唯一确定，存储具体数据，视为字节数组，支持多版本。</td>
<td>数据的<strong>最小存储单元</strong>，<strong>版本由时间戳区分</strong>。</td>
</tr>
<tr>
<td><strong>时间戳（Timestamp）</strong></td>
<td>单元格数据版本的索引，64 位整型，可自动生成或用户自定义，按降序存储。</td>
<td>实现数据多版本管理，<strong>最新版本优先读取</strong>，避免版本冲突。</td>
</tr>
</tbody>
</table>
<p><strong>HBase客户端并不依赖Master服务器，而是借助ZooKeeper来获得Region的位置信息</strong>，所以大多数客户端从来不和Master通信</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://i-blog.csdnimg.cn/blog_migrate/1b9399d83a765495256acce37926b026.png" alt="image.png"></p>
<table>
<thead>
<tr>
<th>层次</th>
<th>名称</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>第一层</td>
<td>Zookeeper 文件</td>
<td>记录了 - ROOT - 表的位置信息</td>
</tr>
<tr>
<td>第二层</td>
<td>-ROOT- 表</td>
<td>记录了.META.表的 Region 位置信息<br>-ROOT- 表只能有一个 Region。通过-ROOT-表可访问.META.表中的数据</td>
</tr>
<tr>
<td>第三层</td>
<td>.META.表</td>
<td>记录了用户数据表的 Region 位置信息；.META.表可有多个 Region，保存 HBase 中所有用户数据表的 Region 位置信息</td>
</tr>
</tbody>
</table>
<p>假设.META.表的每行（一个映射条目，即记录一个 Region 与 Region 服务器的映射关系 ）在内存中大约占用 1KB，每个 Region 大小限制为 128MB 。</p>
<ol>
<li><strong>-ROOT- 表可寻址.META.表的 Region 个数</strong>：<br>
-ROOT- 表只有一个 Region，其大小最多为 128MB。因为每行映射条目占用 1KB 内存，根据可容纳行数 = -ROOT- 表大小 ÷ 每行占用内存，即 128MB/1KB​=2^17 。这意味着 -ROOT- 表可以寻址 2^17 个.META.表的 Region。</li>
<li><strong>每个.META.表的 Region 可寻址用户数据表的 Region 个数</strong>：<br>
每个.META.表的 Region 大小同样为 128MB，每行映射条目占用 1KB 内存，同理可得，每个.META.表的 Region 可容纳的映射条目数为 128MB/1KB​=2^17 ，即每个.META.表的 Region 可以寻址 2^17 个用户数据表的 Region。</li>
<li><strong>三层结构可保存的用户数据表的 Region 总数</strong>：<br>
根据前面两步，三层结构可保存的 Region 数目 = -ROOT- 表能够寻址的.META.表的 Region 个数 × 每个.META.表的 Region 可以寻址的用户数据表的 Region 个数，即 2^17×2^17=2^34 个 。</li>
</ol>
<p>Region服务器是HBase 最核心模块</p>
<p>HBase自身不具备数据复制和维护数据副本的功能，HDFS可以为HBase提供这些支持</p>
<p>每个 Region 对象由<strong>多个 Store 组成</strong>，<strong>一个 Store 对应表中一个列族存储</strong> 。比如一个学生信息表，“基本信息” 列族、“成绩信息” 列族等可能分别对应不同 Store<br>
每个Store包含一个MemStore和多个StroeFile</p>
<ul>
<li><strong>MemStore</strong>：是<strong>内存</strong>中的<strong>缓存</strong>，保存<strong>最近更新的数据</strong>。如同一个临时 “收纳箱”，新数据先存这里，等达到一定条件（如大小阈值）后再批量写入磁盘，减少磁盘 I/O 次数。<br>
新数据来就先放这里，等箱子满了，就把东西（数据）规整到磁盘上的 StoreFile 文件里 。</li>
<li><strong>StoreFile</strong>：StoreFile 在<strong>磁盘</strong>，是货物长期存放的货柜，用 <strong>B 树</strong>结构，方便快速找货（<strong>读取数据</strong>） 。它其实是 HDFS 里的 <strong>HFile</strong>，数据块还会<strong>压缩</strong>，省空间、减少搬运（I/O）工作量 。</li>
</ul>
<p><strong>每个Region服务器只需要维护一个HLog文件</strong>，<strong>所有Region对象共用一个HLog文件</strong></p>
<ol>
<li>
<p><strong>清空指定的表的所有记录数据</strong>：truncate ‘s1’</p>
</li>
<li>
<p><strong>deleteall ‘student’,‘95001’</strong></p>
</li>
<li>
<p>scan ‘students’,{COLUMNS =&gt; [‘Gender’,‘Height’]}<br>
alter ‘students’,‘Age’<br>
describe ‘students’<br>
alter ‘students’,{NAME=&gt;‘Weight’,VERSIONS=&gt;3}<br>
scan ‘students’,{LIMIT=&gt;10}<br>
get ‘students’,‘192001’,{COLUM =&gt; ‘Weight’, TTL =&gt; true}</p>
</li>
</ol>
<p>connection.close();<br>
TableName tablename = TableName.valueOf(tableName);</p>
<table>
<thead>
<tr>
<th>对比指标</th>
<th>NoSQL</th>
<th>关系数据库</th>
</tr>
</thead>
<tbody>
<tr>
<td>数据库原理</td>
<td>部分支持</td>
<td>完全支持</td>
</tr>
<tr>
<td>数据规模</td>
<td>超大</td>
<td>大</td>
</tr>
<tr>
<td>数据库模式</td>
<td>灵活</td>
<td>固定</td>
</tr>
<tr>
<td>查询效率</td>
<td>简单查询高效，复杂查询不佳</td>
<td>快</td>
</tr>
<tr>
<td>一致性</td>
<td>弱一致性</td>
<td>强一致性</td>
</tr>
<tr>
<td>数据完整性</td>
<td>很难实现</td>
<td>容易实现</td>
</tr>
<tr>
<td>扩展性</td>
<td>好</td>
<td>一般</td>
</tr>
<tr>
<td>可用性</td>
<td>很好</td>
<td>好</td>
</tr>
</tbody>
</table>
<p>NoSQL：键值、列族、文档、图<br>
键值：Redis<br>
列族：Big Table、HBase、Cassandra、HadoopDB<br>
文档：MongoDB<br>
图：Neo4j<br>
三大基石：</p>
<ul>
<li>
<p>CAP（一致性、可用性、分区容忍性）</p>
</li>
<li>
<p>BASE（基本可用、软状态、最终一致性）</p>
</li>
<li>
<p>最终一致性：因果一致性、“读己之所写”、会话一致性、单调读一致性、单调写一致性<br>
ACID：原子、一致、隔离、持久</p>
</li>
<li>
<p>CA：把所有与事务相关的内容都放到同一台机器上，严重影响系统的可扩展性<br>
MySQL、SQL Server、PostgreSQL</p>
</li>
<li>
<p>CP：当出现网络分区时，受影响的服务需要等待数据已知，因此在等待期间就无法对外提供服务<br>
Neo4j、Big Table、HBase</p>
</li>
<li>
<p>AP：允许系统返回不一致的大数据<br>
对Web2.0网站可行<br>
可以不完全放弃一致性，采用最终一致性<br>
Dynamo DB、Riak、Couch DB、Cassandra</p>
<p><strong>OldSQL</strong> 继续用于对<strong>事务一致性</strong>要求极高的场景；<br>
<strong>NoSQL</strong> 凭借其灵活<strong>可扩展性</strong>用于互联网应用处理<strong>海量、非结构化</strong>数据；<br>
<strong>NewSQL</strong> 结合了 <strong>SQL 和 NoSQL</strong> 的优势，用于<strong>大数据分析</strong>等场景 。</p>
</li>
<li>
<p>不同的NewSQL数据库内部结构差异很大，但是又两个显著的共同特点：<br>
<strong>都支持关系数据模型</strong><br>
<strong>都使用SQL作为其主要的接口</strong></p>
</li>
<li>
<p>NewSQL数据库的<strong>Spanner</strong>是以<strong>可扩展、多版本、全球分布式且支持同步复制</strong>的数据库</p>
<p>特性：<strong>无锁读事务、原子模式修改、读历史数据无阻塞</strong></p>
</li>
</ul>
<table>
<thead>
<tr>
<th>阶段</th>
<th>输入示例</th>
<th>处理逻辑</th>
<th>输出示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>Map 输入</td>
<td><code>&lt;行号1, &quot;Hello World&quot;&gt;</code></td>
<td>拆分单词，每个单词计为 1</td>
<td><code>List(&lt;&quot;Hello&quot;,1&gt;, &lt;&quot;World&quot;,1&gt;)</code></td>
</tr>
<tr>
<td>Shuffle</td>
<td>中间键值对</td>
<td>按键分组排序</td>
<td><code>&lt;&quot;Hello&quot;,[1,1]&gt;, &lt;&quot;World&quot;,[1]&gt;</code></td>
</tr>
<tr>
<td>Reduce 输入</td>
<td><code>&lt;&quot;Hello&quot;,[1,1]&gt;</code></td>
<td>对 value 列表求和</td>
<td><code>&lt;&quot;Hello&quot;,2&gt;</code></td>
</tr>
<tr>
<td>最终结果</td>
<td></td>
<td>单词总次数统计</td>
<td>所有单词的<code>&lt;单词, 次数&gt;</code>对</td>
</tr>
<tr>
<td>MapReduce 工作流程通俗解析</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ol>
<li><strong>InputFormat 预处理与逻辑切分</strong>
<ul>
<li>验证输入数据格式，将文件切分为逻辑上的 InputSplit（非物理切割，仅记录数据位置和长度）。</li>
<li>InputSplit 是 MapReduce 的输入单位，为后续处理提供数据范围标识。</li>
</ul>
</li>
<li><strong>RecordReader 加载数据</strong>
<ul>
<li>根据 InputSplit 信息，将数据转换为 Map 任务可读取的键值对（&lt;k1,v1&gt;），作为 Map 输入。</li>
</ul>
</li>
<li><strong>Map 任务处理</strong>
<ul>
<li>按用户自定义规则处理输入键值对，输出中间键值对（&lt;k2,v2&gt;）。</li>
<li>比如输入 &lt;行号，“a b a”&gt;，Map 输出 &lt;“a”,1&gt;、&lt;“b”,1&gt;、&lt;“a”,1&gt;，就像把每个单词挑出来并标上 “出现 1 次”。</li>
</ul>
</li>
<li><strong>Shuffle 阶段（分区、排序、合并）</strong>
<ul>
<li>对 Map 输出进行分区、排序、合并，将无序的 &lt;k2,v2&gt; 整理为有序的 &lt; k2,value-list&gt;，以便 Reduce 并行处理。</li>
</ul>
</li>
<li><strong>Reduce 任务聚合</strong>
<ul>
<li>以 &lt;k2,value-list&gt; 为输入，按用户逻辑聚合数据，输出最终键值对（&lt;k3,v3&gt;）。</li>
</ul>
</li>
<li><strong>OutputFormat 输出结果</strong>
<ul>
<li>验证输出目录和结果类型，将 Reduce 结果写入分布式文件系统。</li>
</ul>
</li>
</ol>
<p>概念</p>
<ol>
<li><strong>Map 函数的 “分解” 作用</strong>：<br>
将大任务拆分为独立的小任务（每行文本处理），每个任务生成中间结果，类似 “每个人分别统计自己手中的书页单词”。</li>
<li><strong>Shuffle 的 “整理” 作用</strong>：<br>
把不同 Map 任务中相同单词的计数结果汇总到一起，类似 “把所有人统计的‘Hello’次数收集到同一堆”。</li>
<li><strong>Reduce 函数的 “聚合” 作用</strong>：<br>
对同一单词的所有计数求和，得到最终结果，类似 “计算这一堆‘Hello’的总次数”。</li>
</ol>
<p>Shuffle 是对 Map 输出结果进行分区、排序、合并等处理并交给 Reduce 的过程，<strong>分 Map 端和 Reduce 端操作</strong>。</p>
<p><strong>Map 端的 Shuffle 过程</strong>：</p>
<ol>
<li><strong>输入数据和执行 Map 任务</strong>：Map 任务先对输入数据进行处理，生成中间结果。</li>
<li><strong>写入缓存</strong>：Map 输出结果先写入缓存，缓存用于暂存数据，提高处理效率。</li>
<li><strong>溢出（分区、排序和合并）</strong>：缓存满时，启动溢写操作。先对缓存数据分区，将数据按规则分到不同区域，便于后续 Reduce 处理；接着对每个分区数据排序，让相同键值对集中；然后合并相同键值对，减少数据量。之后将处理后的数据写入磁盘文件，每次溢写生成新文件。</li>
<li><strong>文件归并</strong>：Map 任务结束前，将多个溢写文件归并成一个大磁盘文件，减少文件数量。最后通知相应 Reduce 任务来领取属于自己的数据。</li>
</ol>
<p><strong>Reduce 端的 Shuffle 过程</strong></p>
<ol>
<li><strong>“领取” 数据</strong>：Reduce 任务从 Map 端不同机器上获取属于自己要处理的数据，就像去仓库取货。</li>
<li><strong>归并数据</strong>：对领取到的数据进行归并操作，将来自不同 Map 任务的数据整合，使其有序。</li>
<li><strong>把数据输入给 Reduce 任务</strong>：将归并好的数据交给 Reduce 任务处理，Reduce 按用户定义逻辑对数据进行聚合计算等操作，输出最终结果。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Map</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Object, Text, Text, Text&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">Text</span> <span class="variable">text</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>(); <span class="comment">// 存储输出键的文本对象</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Object key, Text value, Context context)</span></span><br><span class="line">            <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        text = value;                          <span class="comment">// 直接复用输入value作为输出key</span></span><br><span class="line">        context.write(text, <span class="keyword">new</span> <span class="title class_">Text</span>(<span class="string">&quot;&quot;</span>));      <span class="comment">// 输出键值对（文本内容，空值）</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Reduce</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, Text, Text, Text&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values, Context context)</span></span><br><span class="line">            <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        context.write(key, <span class="keyword">new</span> <span class="title class_">Text</span>(<span class="string">&quot;&quot;</span>));  <span class="comment">// 输出去重后的键（每个键仅输出一次）</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    <span class="comment">// 1. 配置HDFS连接参数</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    conf.set(<span class="string">&quot;fs.default.name&quot;</span>, <span class="string">&quot;hdfs://localhost:9000&quot;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Map</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Object, Text, IntWritable, IntWritable&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">IntWritable</span> <span class="variable">data</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(); <span class="comment">// 存储整数的输出键</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Object key, Text value, Context context)</span></span><br><span class="line">            <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">text</span> <span class="operator">=</span> value.toString();                  <span class="comment">// 读取输入文本</span></span><br><span class="line">        data.set(Integer.parseInt(text));                <span class="comment">// 转换为整数</span></span><br><span class="line">        context.write(data, <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>));          <span class="comment">// 输出(整数, 1)</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Reduce</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;IntWritable, IntWritable, IntWritable, IntWritable&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">IntWritable</span> <span class="variable">lineNum</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>); <span class="comment">// 排序位次计数器</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(IntWritable key, Iterable&lt;IntWritable&gt; values, Context context)</span></span><br><span class="line">            <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="keyword">for</span> (IntWritable val : values) &#123;                    <span class="comment">// 遍历计数（实际用于控制输出次数）</span></span><br><span class="line">            context.write(lineNum, key);                    <span class="comment">// 输出(位次, 整数)</span></span><br><span class="line">            lineNum = <span class="keyword">new</span> <span class="title class_">IntWritable</span>(lineNum.get() + <span class="number">1</span>);   <span class="comment">// 位次自增</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>数据库面向<strong>事务</strong>设计，数据仓库面向<strong>主题</strong>设计</li>
<li>数据仓库是一个<strong>面向主题的、集成的、相对稳定的、反映历史变化的数据集合</strong>，用于支持<strong>管理决策</strong>。</li>
</ul>
<table>
<thead>
<tr>
<th>特性</th>
<th>数据仓库</th>
<th>数据湖</th>
<th>湖仓一体</th>
</tr>
</thead>
<tbody>
<tr>
<td>数据格式</td>
<td><strong>专有</strong>格式</td>
<td>开放格式</td>
<td>开放格式</td>
</tr>
<tr>
<td>数据类型</td>
<td><strong>结构化</strong>/半结构化</td>
<td>原始类型（所有类型、无论来源或结构）</td>
<td>结构化数据、半结构化数据、非结构化数据</td>
</tr>
<tr>
<td>数据访问</td>
<td>SQL</td>
<td>Open API（SQL/R/Python 等）</td>
<td>Open API（SQL/R/Python 等）</td>
</tr>
<tr>
<td>可靠性</td>
<td><strong>高质量</strong>可靠数据（事务保障）</td>
<td><strong>低质量</strong>数据</td>
<td><strong>高质量</strong>可靠数据（事务保障）</td>
</tr>
<tr>
<td>治理与安全</td>
<td>行级 / 字段级细粒度安全和治理</td>
<td>弱</td>
<td>行级 / 字段级细粒度安全和治理</td>
</tr>
<tr>
<td>性能</td>
<td>高</td>
<td>低</td>
<td>高</td>
</tr>
<tr>
<td>扩展性</td>
<td>高扩展性、成本同比例增加</td>
<td>高扩展性、成本低</td>
<td>高扩展性、成本低</td>
</tr>
<tr>
<td>用户场景支持</td>
<td><strong>B</strong>I、批处理报告、可视化分析</td>
<td>机器学习</td>
<td>数据分析和机器学习工作负载</td>
</tr>
<tr>
<td>是否符合ACID</td>
<td>√</td>
<td>×</td>
<td>√</td>
</tr>
<tr>
<td>成本</td>
<td>起步高，本地存储查询快</td>
<td>起步低，计算与存储分类</td>
<td></td>
</tr>
<tr>
<td>适用对象</td>
<td>业务分析师</td>
<td>数据科学家、数据开发人员</td>
<td></td>
</tr>
</tbody>
</table>
<p>hive<br>
由<strong>用户接口模块、驱动模块、元数据存储模块</strong>组成</p>
<table>
<thead>
<tr>
<th>对比内容</th>
<th>Hive</th>
<th>传统数据库</th>
</tr>
</thead>
<tbody>
<tr>
<td>数据存储</td>
<td>HDFS</td>
<td>本地文件系统</td>
</tr>
<tr>
<td>索引</td>
<td>支持有限索引</td>
<td>支持复杂索引</td>
</tr>
<tr>
<td>分区</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>执行引擎</td>
<td>MapReduce、Tez、Spark</td>
<td>自身的执行引擎</td>
</tr>
<tr>
<td>执行延迟</td>
<td>高</td>
<td>低</td>
</tr>
<tr>
<td>扩展性</td>
<td>好</td>
<td>有限</td>
</tr>
<tr>
<td>数据规模</td>
<td>大</td>
<td>小</td>
</tr>
</tbody>
</table>
<p>create database if not exists hive;</p>
<p>create table if not exists hive.usr(<br>
id bigint,<br>
name string,<br>
age int)<strong>location</strong> ‘/usr/local/hive/warehouse/hive/usr’</p>
<p>row format delimited terminated by’,’ location ‘/usr/local/data’</p>
<ol start="39">
<li><strong>本地路径装载数据（覆盖）</strong>：<br>
<strong>load data local inpath ‘/usr/local/data’ overwrite into table usr;</strong></li>
<li><strong>本地路径装载数据（追加）</strong>：<br>
<strong>load data local inpath ‘/usr/local/data’ into table usr;</strong></li>
<li><strong>HDFS 路径装载数据（覆盖）</strong>：<br>
<strong>load data inpath ‘hdfs://master_server/usr/local/data’ overwrite into table usr;</strong></li>
<li><strong>插入数据（覆盖目标表）</strong>：<br>
<strong>insert overwrite table usr1 select * from usr where age=10;</strong></li>
<li><strong>插入数据（追加到目标表）</strong>：<br>
<strong>insert into table usr1 select * from usr where age=10;</strong></li>
</ol>
<p>spark<br>
特点：</p>
<ul>
<li>运行速度快</li>
<li>容易使用</li>
<li>通用</li>
<li>运行模式多样</li>
</ul>
<p>Scala<br>
优点：<br>
① Scala具备强大的<strong>并发性</strong>，支持<strong>函数式编程</strong>，可以更好地支持分布式系统<br>
② Scala<strong>语法简洁</strong>，能提供优雅的API<br>
③ Scala<strong>兼容Java</strong>，运行速度快，且能融入到Hadoop生态环境中。<br>
<strong>Scala是Spark的主要编程语言</strong>，但Spark还支持Java、Python、R作为编程语言。因此若仅仅只是编写Spark程序，并非一定要Scala。<br>
Scala的优势是提供<strong>交互式解释器REPL</strong></p>
<table>
<thead>
<tr>
<th>对比维度</th>
<th>Hadoop（MapReduce）</th>
<th>Spark</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>计算模型</strong></td>
<td><strong>仅支持 Map 和 Reduce 操作</strong>，表达能力有限，难以处理复杂逻辑</td>
<td>基于 MapReduce 扩展，支持多种数据集操作（如 filter、join、aggregate 等），编程模型更灵活</td>
</tr>
<tr>
<td><strong>数据存储与计算</strong></td>
<td>数据和计算强绑定，每次计算需从<strong>磁盘</strong>读取 / 写入中间结果，IO 开销大</td>
<td>支持<strong>内存</strong>计算，中间结果可<strong>缓存</strong>至内存，大幅减少磁盘 IO，提升迭代效率</td>
</tr>
<tr>
<td><strong>任务执行机制</strong></td>
<td>任务按<strong>顺</strong>序执行，Map 和 Reduce 阶段需等待前一阶段完成，延迟高</td>
<td>基于 <strong>DAG</strong>（有向无环图）调度，可<strong>并行</strong>执行多阶段任务，减少任务间衔接延迟</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>适合<strong>离线批处理、大规模数据存储与简单计算</strong></td>
<td>更适合<strong>迭代计算</strong>、<strong>实时流处理</strong>、复杂多阶段任务（如机器学习、图计算）</td>
</tr>
<tr>
<td><strong>硬件要求</strong></td>
<td>可使用<strong>廉价异构机器</strong>，对硬件要求低</td>
<td>对<strong>内存和 CPU 要求较高</strong>，需更优质硬件支撑内存计算</td>
</tr>
<tr>
<td><strong>生态定位</strong></td>
<td>分布式存储（HDFS）与计算的一体化解决方案，生态完整</td>
<td>主要替代 Hadoop 的计算层（MapReduce），<strong>需依赖 HDFS 等存储系统</strong></td>
</tr>
</tbody>
</table>
<p><strong>Spark</strong>与Hadoop的对比，<strong>Hadoop存在以下缺点</strong><br>
1)   表达能力有限。</p>
<p>2)   磁盘IO开销大。</p>
<p>3)   延迟高。</p>
<p>相比于MapReduce，<strong>Spark主要具有如下优点</strong><br>
1)   Spark的计算模式也属于MapReduce，但不局限于Map和Reduce操作，还提供了多种数据集操作类型，编程模型比MapReduce更灵活。</p>
<p>2)   Spark提供了内存计算，中间结果直接放到内存中，带来了更高的迭代运算效率。</p>
<p>3)   Spark基于DAG的任务调度执行机制，要优于MapReduce的迭代执行机制。</p>
<p>大数据场景：批量、历史数据、实时数据流</p>
<ul>
<li>阶段：是<strong>作业的基本调度单位</strong>，阶段是「作业的分段计划」，把作业拆分成多个可并行执行的小组任务。</li>
</ul>
<p>RDD 本质是一个<strong>只读的分区记录集合</strong>，类似分布式的 “数据数组”，但数据分散在集群不同节点上。<br>
例如：100 万条用户数据分成 10 个包裹，每个包裹存 10 万条，放在 10 台机器上。每台机器可同时处理自己的包裹（并行计算）。</p>
<ul>
<li>每个 RDD 可拆分为多个分区（Partition），每个分区是数据的一个片段。</li>
<li>不同分区可存储在集群不同节点，天然支持并行计算（每个节点处理本地分区数据）。</li>
</ul>
<ol>
<li><strong>受限的共享内存模型</strong>
<ul>
<li>RDD 是只读的，不能直接修改，只能通过以下方式创建：
<ul>
<li>基于<strong>物理存储</strong>的数据集（如 HDFS 文件）。<br>
从硬盘读取原始数据（如 HDFS 文件，相当于拿原件复印）。</li>
<li>对其他 RDD 执行转换操作（如<code>map</code>、<code>filter</code>、<code>join</code>）生成新 RDD。</li>
</ul>
</li>
<li><strong>类比</strong>：RDD 像复印件，每次修改必须基于原件或已有复印件生成新复印件，原件始终不变。</li>
</ul>
</li>
<li><strong>转换（Transformation）与动作（Action）</strong>
<ul>
<li>两种操作用于支持常见的数据运算</li>
<li><strong>转换</strong>：<strong>执行计算并指定输出的形式</strong>，接收RDD并返回RDD<br>
<strong>map、filter、groupBy、join</strong><br>
定义数据处理逻辑（如筛选、聚合），返回新 RDD，不触发实际计算（<strong>惰性执行</strong>）。<br>
例：<code>rdd.filter(x =&gt; x &gt; 10)</code>（筛选大于 10 的数据，仅记录操作逻辑）。</li>
<li><strong>动作</strong>：<strong>触发实际计算并拿结果</strong>（如 “统计符合条件的用户数量”），指定RDD之间的依赖关系，接收RDD但返回非RDD（即输出一个值或结果）<br>
<strong>count、collect</strong><br>
触发实际计算并返回结果，例：<code>rdd.count()</code>（统计元素数量，此时才真正执行计算）。</li>
</ul>
</li>
<li><strong>粗粒度操作为主</strong>
<ul>
<li>支持<code>map</code>、<code>filter</code>、<code>groupBy</code>、<code>join</code>等粗粒度转换，不支持细粒度修改（如单独修改某条数据）。<br>
支持对整批数据做统一处理（如用<code>map</code>给所有用户年龄 + 1，用<code>groupBy</code>按城市分组），但不能单独修改某条数据（如 “把用户 A 的年龄从 20 改成 21”）。<br>
RDD适用于对数据集中的元素执行相同操作的批处理式应用，不适合需要异步、细粒度状态的应用</li>
<li><strong>不适合场景</strong>：网页爬虫（需逐页精细处理），更适合批量数据聚合分析。</li>
</ul>
</li>
<li><strong>编程模型兼容性</strong>
<ul>
<li>看似功能简单，实则能模仿多种工具的逻辑：</li>
<li><strong>MapReduce</strong>：用<code>map</code>+<code>reduceByKey</code>实现 “先映射后聚合”。</li>
<li><strong>SQL</strong>：用<code>join</code>模拟表关联，<code>groupBy</code>模拟分组统计。</li>
<li><strong>图计算</strong>：用 GraphX 组件实现社交网络关系分析（类似 Pregel 框架）。</li>
</ul>
</li>
</ol>
<p><strong>RDD 的惰性调用机制</strong><br>
真正的计算发生在<font color="#ff0000">行动</font>中，对于行动之前的所有转换操作，不会发生真正的计算</p>
<ol>
<li>
<p><strong>执行流程</strong></p>
<ul>
<li><strong>转换阶段</strong>：记录操作轨迹（如<code>map</code>→<code>filter</code>→<code>groupBy</code>），不计算。</li>
<li><strong>动作阶段</strong>：触发计算时，按记录的轨迹反向推导依赖关系，生成 DAG（有向无环图）并执行。</li>
</ul>
</li>
<li>
<p><strong>惰性调用的优点</strong></p>
<ul>
<li><strong>管道化优化</strong>：<strong>多个转换可合并为一个计算流程</strong>，减少中间数据落地。</li>
<li><strong>避免同步等待</strong>：无需等待前一步计算完成，仅记录逻辑。</li>
<li><strong>节省资源</strong>：<strong>不需要保存中间结果</strong>，每次操作逻辑简单，降低系统复杂度。</li>
</ul>
</li>
</ol>
<h3 id="font-color-ff0000-RDD之间的依赖关系-font"><font color="#ff0000">RDD之间的依赖关系</font></h3>
<ol>
<li><strong>依赖关系（Dependency）</strong>
<ul>
<li><strong>定义</strong>：若 RDD A 的计算依赖于 RDD B 的数据，则称 A 依赖于 B（A←B）。</li>
<li><strong>例子</strong>：<code>rdd1 = rdd2.map(_ * 2)</code>中，rdd1 依赖于 rdd2。</li>
</ul>
</li>
<li><strong>血缘关系（Lineage）</strong>
<ul>
<li><strong>定义</strong>：多个连续 RDD 的依赖关系链（如 RDD1←RDD2←RDD3），形成数据处理的 “血统链条”。</li>
<li><strong>作用</strong>：RDD 通过记录血缘关系，在数据丢失时可重新计算恢复，类似 “家谱” 记录数据来源。</li>
</ul>
</li>
<li><strong>窄依赖（Narrow Dependency）</strong>
<ul>
<li><strong>特点</strong>：父 RDD 的每个分区最多被子 RDD 的一个分区依赖。</li>
<li><strong>容错恢复</strong>：子分区数据丢失时，只需重新计算对应的父分区。</li>
<li><strong>示例操作</strong>：<code>map</code>、<code>filter</code>、<code>union</code>。<br>
<strong>通俗理解</strong>：</li>
</ul>
<blockquote>
<p>窄依赖像一对一接力赛，每个队员（子分区）只依赖前一棒的一个队员（父分区）。</p>
</blockquote>
</li>
<li><strong>宽依赖（Shuffle/Wide Dependency）</strong>
<ul>
<li><strong>特点</strong>：父 RDD 的每个分区可能被子 RDD 的多个分区依赖（需跨节点混洗数据）。</li>
<li><strong>容错恢复</strong>：子分区数据丢失时，需重新计算<strong>所有父分区</strong>。</li>
<li><strong>示例操作</strong>：<code>reduceByKey</code>、<code>groupByKey</code>、<code>join</code>（未分区时）。<br>
<strong>通俗理解</strong>：</li>
</ul>
<blockquote>
<p>宽依赖像多人合作拼图，每个子分区需要多个父分区的碎片，一旦丢失需重新收集所有碎片。</p>
</blockquote>
</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic2.zhimg.com/v2-635b9840b3f3bfb06c310a9e8dcd5439_1440w.jpg" alt="image.png"></p>
<table>
<thead>
<tr>
<th><strong>类型</strong></th>
<th><strong>窄依赖（Narrow Dependency）</strong></th>
<th><strong>宽依赖（Wide Dependency/Shuffle Dependency）</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>数据依赖</strong></td>
<td>子 RDD 的一个分区仅依赖父 RDD 的<strong>一个分区</strong>（一对一）。</td>
<td>子 RDD 的一个分区依赖父 RDD 的<strong>多个分区</strong>（一对多）。</td>
</tr>
<tr>
<td><strong>形象比喻</strong></td>
<td>“独生子女”：每个孩子（子分区）只有一个父亲（父分区）。</td>
<td>“多子女”：每个孩子依赖多个父亲的资源。</td>
</tr>
<tr>
<td><strong>典型操作</strong></td>
<td><code>map</code>、<code>filter</code>、<code>union</code>、join协同划分（分区数不变或合并）</td>
<td><code>groupByKey</code>、<code>join</code>非协同划分（需跨分区洗牌）</td>
</tr>
<tr>
<td><strong>数据传输</strong></td>
<td>无需跨节点传输，在<strong>本地节点</strong>完成</td>
<td>必须通过 <strong>Shuffle</strong> 跨节点传输数据（如不同节点的分区合并）。</td>
</tr>
<tr>
<td><strong>容错成本</strong></td>
<td>某分区丢失时，仅需重算对应的单个父分区，效率高。</td>
<td>某分区丢失时，可能需重算所有父分区（如<code>groupByKey</code>后丢失分区，需重算所有父数据）。</td>
</tr>
<tr>
<td>两种依赖中，<strong>窄依赖的失败恢复效率更高</strong>，它只需要根据父RDD分区重新计算丢失的分区就可以，不需要重新计算所有分区，而且可以并行地在不同节点进行重新计算</td>
<td></td>
<td></td>
</tr>
<tr>
<td>此外，Spark还提供了<strong>数据检查点</strong>和<strong>记录日志</strong>，用于<strong>持久化中间RDD</strong>，使得在恢复时不需要从最开始进行，Spark会对数据检查点开销和重新计算RDD分区的开销进行对比，从而<strong>自动选择最优的策略</strong>。</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>二者的主要区别：<strong>是否包含Shuffle操作</strong><br>
Shuffle 是 Spark 中触发数据<strong>重新分发</strong>的关键操作，涉及 <strong>Map 端写入与 Reduce 端读取</strong>，会产生磁盘 I/O 和网络开销。<br>
其核心目的是<strong>将 Map 任务的输出数据按 key 分组，传递给对应的 Reduce 任务处理</strong>，是分布式计算中数据重新组织的必经环节。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic4.zhimg.com/v2-35bf21e308f8c431d7e46f76fd8234b7_1440w.jpg" alt="image.png"></p>
<p><strong>传统桶机制与问题</strong></p>
<ul>
<li><strong>桶的概念</strong>：每个 Map 任务根据 Reduce 任务数量创建 “桶”（Bucket），用于存储对应分区的数据。桶的数量为 <code>m×r</code>（m 是 Map 任务数，r 是 Reduce 任务数）。</li>
<li><strong>分区算法</strong>：默认按 key 的哈希值将数据分配到不同桶中，也可自定义分区逻辑。</li>
<li><strong>传统实现问题</strong>：若 Map 和 Reduce 任务数均为 1000，则生成 100 万个文件，严重消耗文件系统资源。</li>
</ul>
<p><strong>优化后的文件写入机制</strong>（Spark 新版本）</p>
<ul>
<li><strong>单文件写入 + 索引文件</strong>：每个 Map 任务仅生成两个文件：
<ul>
<li><strong>数据文件</strong>：存储所有输出数据，按分区划分。</li>
<li><strong>索引文件</strong>：记录数据文件中各分区的起始位置和大小，便于 Reduce 任务快速定位数据。</li>
</ul>
</li>
<li><strong>示例</strong>：1000 个 Map 任务仅生成 1000 个数据文件和 1000 个索引文件，大幅减少文件数量。</li>
</ul>
<ol>
<li>
<p><strong>Shuffle 过程</strong>：</p>
<ul>
<li><strong>第一步：洗牌搬家</strong>：所有<code>A</code>用户的数据（不管原来在哪个机器）必须集中到同一台机器；<code>B</code>和<code>C</code>同理。</li>
<li><strong>第二步：重组计算</strong>：在新机器上对同一用户的消费额求和，得到<code>(A, 250), (B, 200), (C, 50)</code>。</li>
</ul>
</li>
<li>
<p><strong>Shuffle 的核心阶段：拆、搬、合</strong></p>
<ul>
<li><strong>Map 阶段（拆分与标记）</strong>：</li>
<li>每个 Map 任务只打包一个大包裹（数据文件），再附一张清单（索引文件），标注每个用户的清单在大包裹里的位置。比如：“张三的清单在包裹第 10-20 页，李四的在第 50-60 页”。</li>
<li>每个节点处理本地分区数据，给数据打上 “目标标签”（如用户 ID）。<br>
例：机器 1 处理<code>(A, 100)</code>，标记 “发给 A 组”；机器 2 处理<code>(A, 150)</code>，同样标记 “发给 A 组”。</li>
<li><strong>Shuffle Write（数据搬家）</strong>：</li>
<li>按标签将数据 “打包” 发送到对应节点。比如所有 “发给 A 组” 的数据都被送到机器 5。</li>
<li><strong>Shuffle Read（重组计算）</strong>：</li>
<li>目标节点接收所有同类数据，合并处理（如求和、排序）。</li>
</ul>
</li>
</ol>
<p><strong>Reduce 端 Shuffle 读取（Shuffle Fetch）</strong></p>
<ol>
<li>与 Hadoop MapReduce 的区别
<ul>
<li><strong>Hadoop 的归并排序</strong>：Reduce 端拉取数据后需进行归并（Merge）和排序（Sort），耗时且占用资源。</li>
<li><strong>Spark 的 Aggregator 机制</strong>：</li>
<li>采用 HashMap 存储拉取的（key, value）对，直接进行聚合（如词频统计中的累加），<strong>无需预先排序</strong>。</li>
<li>示例：接收到（“apple”, 1）时，若 HashMap 中已有 “apple”，则累加值；若无则插入，避免外部排序开销。</li>
</ul>
</li>
</ol>
<p><strong>Shuffle 面临的核心问题与矛盾</strong></p>
<ol>
<li>
<p>分区数量与内存的权衡</p>
<ul>
<li><strong>增加分区的优势</strong>：减小单个分区数据量，降低内存溢出风险。</li>
<li><strong>增加分区的代价</strong>：增加Map和Reduce任务的数量虽然可以减小分区的大小，但是在Shuffle写入环节，桶数量是由Map和Reduce任务的数量决定的，随任务数增加而增多，需更多缓冲区（Buffer），消耗更多内存。</li>
</ul>
</li>
<li>
<p>内存与磁盘的妥协</p>
<ul>
<li>当内存不足时，Spark 会将 Aggregator 的数据溢写到磁盘，尽管 Spark 以 “内存计算” 为核心，但 Shuffle 仍依赖磁盘 I/O。</li>
</ul>
</li>
</ol>
<h3 id="font-color-ff0000-阶段的划分-font"><font color="#ff0000">阶段的划分</font></h3>
<p>在DAG中进行<strong>反向解析</strong>，遇到<strong>宽依赖</strong>就<strong>断开</strong>，遇到<strong>窄依赖</strong>就<strong>把当前的RDD加入到当前的阶段中</strong>；将窄依赖尽量划分在<strong>同一个阶段</strong>中，可以实现<strong>流水线计算</strong>。</p>
<ol>
<li><strong>反向解析</strong>：像拆礼物包装一样，从最外层（目标 RDD）往内拆（原始 RDD）。</li>
<li><strong>宽依赖 = 拆包节点</strong>：遇到宽依赖（如<code>groupByKey</code>）就断开，作为新阶段的起点。</li>
<li><strong>窄依赖 = 打包在一起</strong>：遇到窄依赖（如<code>map</code>）就把对应的 RDD 操作归到同一阶段。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">目标：烤好的蛋糕（最终RDD）</span><br><span class="line">↓ 反向解析</span><br><span class="line">阶段3：烘烤（宽依赖：必须等所有材料混合好）</span><br><span class="line">↓ 遇到宽依赖，断开</span><br><span class="line">阶段2：混合材料（窄依赖：打蛋、加糖、加面粉可并行）</span><br><span class="line">↓ 遇到窄依赖，合并</span><br><span class="line">阶段1：准备材料（窄依赖：买鸡蛋、买面粉可并行）</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>宽依赖场景</strong>：混合材料后才能烘烤（类似分组后才能统计），必须拆成阶段 2 和阶段 3。</li>
<li><strong>窄依赖场景</strong>：买鸡蛋和买面粉可同时进行（类似<code>map</code>和<code>filter</code>并行），归为阶段 1。</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://i-blog.csdnimg.cn/blog_migrate/b23ffac94912fdfad4102a42c84ae16b.png" alt="image.png"><br>
把一个 DAG 图划分成多个 “阶段” 以后，每个阶段都代表了一组关联的、相互之间没有 Shuffle 依赖关系的任务组成的任务集合。每个任务集合会被提交给任务调度器（TaskScheduler）进行处理，由任务调度器将任务分发给 Executor 运行。</p>
<h1>基本概念</h1>
<p>大数据技术就是一种能对海量、复杂的数据进行收集、存储、处理、分析和可视化展现，从而挖掘出有价值信息的技术。<br>
大数据就是：使用<mark>分布式</mark>技术完成<mark>海量</mark>数据的处理，得到数据背后蕴含的<mark>价值</mark><br>
狭义上：大数据是一类技术栈，是一种用来处理海量数据的软件技术体系。<br>
广义上：大数据是数字化时代、信息化时代的基础(技术)支撑，以数据为生活赋能。</p>
<h2 id="传统的数据处理架构">传统的数据处理架构</h2>
<ul>
<li>结构化数据【严格的数据类型限制】：数据库、数据仓库</li>
<li>非结构化【图片、视频、音频】</li>
<li>半结构化数据【日志、json，不严格】：NoSQL数据库、并发程序</li>
</ul>
<h2 id="在大数据背景下存在的问题：">在大数据背景下存在的问题：</h2>
<ul>
<li>结构化数据：单机处理速度慢，MPP（基于单机的集群）存在扩展新、热点问题</li>
<li>非结构化、半结构化数据：NoSQL数据库只负责存储；程序处理时涉及到数据移动，速度慢</li>
</ul>
<h2 id="大数据的特征">大数据的特征</h2>
<ol>
<li>数据规模巨大（Volume）</li>
<li>生成和处理速度极快（Velocity）</li>
<li>数据类型多样（Variety）</li>
<li>价值巨大但密度较低（Value）</li>
</ol>
<p>满足这四个的场景称为大数据场景<br>
不适合中小规模数据</p>
<h2 id="大数据的核心工作">大数据的核心工作</h2>
<p>从海量的高增长、多类别、低信息密度的数据中挖据出高质量的结果</p>
<ul>
<li>数据存储：可以妥善存储海量待处理数据</li>
<li>数据计算：可以从海量数据中计算出背后的价值</li>
<li>数据传输：协助在各个环节中完成海量数据的传播</li>
</ul>
<h3 id="为什么需要分布式存储">为什么需要分布式存储</h3>
<ul>
<li>数据量太大，单机存储能力有上限，需要靠数量来解决问题</li>
<li>数量的提升带来的是网络传输、磁盘读写、CPU、内存等各方面的综合提升。分布式组合在一起可以达到1+1&gt;2的效果</li>
</ul>
<h2 id="大数据应用场景">大数据应用场景</h2>
<ol>
<li>离线处理场景（有界数据、批处理）
<ul>
<li>数据仓库</li>
<li>搜索与检索</li>
<li>图计算<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%205.png" alt="image 5|image 5.png"><br>
批处理是在处理过程中，若任意一个时间去观察整个数据的处理情况，所有数据会处在同一个阶段</li>
</ul>
</li>
<li>实时处理场景（无界数据、流处理）
<ul>
<li>实时流处理<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%201%202.png" alt="image 1 2|image 1 2.png"><br>
流处理是在任意时刻观察，数据都处于持续流动的处理过程中，没有固定的阶段划分，是实时地对每个到来的数据元素进行处理。</li>
</ul>
</li>
</ol>
<p>大数据处理的基本思想是分治法<br>
大数据技术的基本思想：<br>
移动计算而非移动数据（MapReduce）</p>
<h2 id="大数据发展阶段">大数据发展阶段</h2>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%202%202.png" alt="image 2 2|image 2 2.png"><br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%203%202.png" alt="image 3 2|image 3 2.png"><br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%204%202.png" alt="image 4 2|image 4 2.png"></p>
<h2 id="大数据软件生态">大数据软件生态</h2>
<p>基本上围绕三大工作体系（数据存储、数据计算、数据传输）<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%205%202.png" alt="image 5 2|image 5 2.png"></p>
<h3 id="常见的大数据技术框架">常见的大数据技术框架</h3>
<h4 id="一、数据存储与计算框架">一、数据存储与计算框架</h4>
<ol>
<li>
<p><strong>Hadoop 生态</strong></p>
<ul>
<li><strong>HDFS</strong>：<mark>分布式文件系统</mark>，提供<mark>高容错性</mark>存储，适用于<mark>海量数据</mark>存储。</li>
<li><strong>MapReduce</strong>：<mark>批处理计算</mark>模型，适合<mark>离线数据处理</mark>，但性能较低。</li>
<li><strong>YARN</strong>：<mark>资源管理和调度框架</mark>，支持<mark>多任务并发</mark>执行。</li>
</ul>
</li>
<li>
<p><strong>Spark</strong></p>
<ul>
<li><strong>核心优势</strong>：基于<mark>内存</mark>计算，比 MapReduce 快 10~100 倍。</li>
<li><strong>适用场景</strong>：批处理、流处理（Spark Streaming）、机器学习（MLlib）、图计算（GraphX）。</li>
<li><strong>特点</strong>：统一 API（RDD、DataFrame、Dataset），支持多种语言（Scala、Java、Python、R）。</li>
</ul>
</li>
<li>
<p><strong>Flink</strong></p>
<ul>
<li><strong>核心优势</strong>：真正的<mark>流处理</mark>引擎（低延迟），支持批流一体化。</li>
<li><strong>适用场景</strong>：<mark>实时</mark>数据处理、复杂事件处理（CEP）、状态化计算。</li>
<li><strong>特点</strong>：Exactly-Once 语义，高吞吐量，与 Kubernetes 深度集成。</li>
</ul>
</li>
<li>
<p><strong>Storm</strong></p>
<ul>
<li><strong>核心优势</strong>：早期流处理框架，低延迟（毫秒级）。</li>
<li><strong>适用场景</strong>：实时监控、日志处理。</li>
<li><strong>现状</strong>：逐渐被 Flink 替代。</li>
</ul>
</li>
</ol>
<h4 id="二、分布式数据库与存储">二、分布式数据库与存储</h4>
<ol>
<li>
<p><strong>HBase</strong></p>
<ul>
<li><strong>定位</strong>：基于 <mark>HDFS</mark> 的分布式 <mark>NoSQL</mark> 数据库，<mark>强一致性</mark>。</li>
<li><strong>适用场景</strong>：<mark>实时</mark>读写海量数据（如用户画像、日志存储）。</li>
<li><strong>特点</strong>：列式存储，支持快速<mark>随机</mark>访问。</li>
</ul>
</li>
<li>
<p><strong>Cassandra</strong></p>
<ul>
<li><strong>定位</strong>：去中心化的分布式 NoSQL 数据库，高可用性。</li>
<li><strong>适用场景</strong>：跨地域数据存储（如物联网时序数据）。</li>
<li><strong>特点</strong>：最终一致性，无单点故障。</li>
</ul>
</li>
<li>
<p><strong>ClickHouse</strong></p>
<ul>
<li><strong>定位</strong>：高性能列式 OLAP 数据库。</li>
<li><strong>适用场景</strong>：实时分析、复杂聚合查询。</li>
<li><strong>特点</strong>：向量化执行引擎，支持 PB 级数据秒级响应。</li>
</ul>
</li>
<li>
<p><strong>Druid</strong></p>
<ul>
<li><strong>定位</strong>：实时分析型数据库，支持高并发查询。</li>
<li><strong>适用场景</strong>：实时监控、广告分析。</li>
<li><strong>特点</strong>：时间序列优化，预聚合查询加速。</li>
</ul>
</li>
</ol>
<h4 id="三、数据仓库与查询引擎">三、数据仓库与查询引擎</h4>
<ol>
<li>
<p><strong>Hive</strong></p>
<ul>
<li><strong>定位</strong>：基于 <mark>Hadoop</mark> 的<mark>数据仓库工具</mark>，提供类 <mark>SQL</mark> 接口（HiveQL）。</li>
<li><strong>适用场景</strong>：<mark>离线批处理</mark>分析（底层依赖 MapReduce/Tez/Spark）。</li>
<li><strong>特点</strong>：<mark>元数据管理</mark>（Metastore），支持复杂 ETL。</li>
</ul>
</li>
<li>
<p><strong>Presto/Trino</strong></p>
<ul>
<li><strong>定位</strong>：分布式 SQL 查询引擎，支持多数据源联邦查询。</li>
<li><strong>适用场景</strong>：交互式分析（如跨 Hive、MySQL、Kafka 查询）。</li>
<li><strong>特点</strong>：内存计算，秒级响应，适合 Ad-Hoc 查询。</li>
</ul>
</li>
<li>
<p><strong>Iceberg</strong></p>
<ul>
<li><strong>定位</strong>：开源表格式（Table Format），用于管理大规模数据集。</li>
<li><strong>适用场景</strong>：ACID 事务支持，时间旅行查询。</li>
<li><strong>特点</strong>：解耦存储与计算，兼容 Hive、Spark、Flink。</li>
</ul>
</li>
</ol>
<h4 id="四、消息队列与流数据集成">四、消息队列与流数据集成</h4>
<ol>
<li>
<p><strong>Kafka</strong></p>
<ul>
<li><strong>定位</strong>：<mark>分布式消息队列</mark>，高吞吐、低延迟。</li>
<li><strong>适用场景</strong>：日志收集、实时数据管道、事件源架构。</li>
<li><strong>特点</strong>：持久化存储，支持 Exactly-Once 语义。</li>
</ul>
</li>
<li>
<p><strong>Pulsar</strong></p>
<ul>
<li><strong>定位</strong>：云原生消息系统，替代 Kafka 的下一代方案。</li>
<li><strong>适用场景</strong>：多租户消息队列、分层存储。</li>
<li><strong>特点</strong>：计算存储分离，支持跨地域复制。</li>
</ul>
</li>
<li>
<p><strong>Flume</strong></p>
<ul>
<li><strong>定位</strong>：分布式日志收集工具。</li>
<li><strong>适用场景</strong>：从日志文件到 HDFS/HBase 的数据传输。</li>
<li><strong>特点</strong>：可扩展的 Channel 机制（Memory/File/Kafka）。</li>
</ul>
</li>
</ol>
<h4 id="五、资源调度与集群管理">五、资源调度与集群管理</h4>
<ol>
<li>
<p><strong>Kubernetes</strong></p>
<ul>
<li><strong>定位</strong>：容器编排平台，支持大数据应用容器化部署。</li>
<li><strong>适用场景</strong>：Spark、Flink 等框架的云原生部署。</li>
<li><strong>特点</strong>：弹性扩缩容，高资源利用率。</li>
</ul>
</li>
<li>
<p><strong>Apache Mesos</strong></p>
<ul>
<li><strong>定位</strong>：分布式资源管理框架，支持混合负载调度。</li>
<li><strong>现状</strong>：逐渐被 Kubernetes 取代。</li>
</ul>
</li>
</ol>
<h4 id="六、数据挖掘与机器学习">六、数据挖掘与机器学习</h4>
<ol>
<li>
<p><strong>Spark MLlib</strong></p>
<ul>
<li><strong>定位</strong>：Spark 的<mark>机器学习</mark>库，支持分布式模型训练。</li>
<li><strong>适用场景</strong>：分类、回归、聚类等传统机器学习任务。</li>
</ul>
</li>
<li>
<p><strong>TensorFlow/PyTorch</strong></p>
<ul>
<li><strong>定位</strong>：深度学习框架，支持分布式训练。</li>
<li><strong>适用场景</strong>：图像识别、自然语言处理（NLP）。</li>
<li><strong>大数据集成</strong>：与 Spark、Flink 结合处理特征工程。</li>
</ul>
</li>
<li>
<p><strong>Horovod</strong></p>
<ul>
<li><strong>定位</strong>：分布式深度学习训练框架。</li>
<li><strong>适用场景</strong>：多 GPU/多节点训练加速。</li>
</ul>
</li>
</ol>
<h4 id="七、数据可视化与BI工具">七、数据可视化与BI工具</h4>
<ol>
<li>
<p><strong>Superset</strong></p>
<ul>
<li><strong>定位</strong>：开源 BI 工具，支持多数据源可视化。</li>
<li><strong>特点</strong>：拖拽式图表，SQL 编辑器，权限管理。</li>
</ul>
</li>
<li>
<p><strong>Tableau</strong></p>
<ul>
<li><strong>定位</strong>：商业智能工具，交互式数据探索。</li>
<li><strong>适用场景</strong>：企业级数据可视化报表。</li>
</ul>
</li>
</ol>
<h4 id="存储、计算与传输的协同架构">存储、计算与传输的协同架构</h4>
<ol>
<li><strong>数据存储：解决海量数据的持久化问题</strong><br>
<strong>核心需求</strong>：高扩展、高可靠、低成本存储海量数据。<br>
<strong>典型技术</strong>：</li>
</ol>
<table>
<thead>
<tr>
<th>类型</th>
<th>代表技术</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>分布式文件系统</td>
<td>HDFS（Hadoop）、Ceph、MinIO</td>
<td>支持海量文件存储，适合非结构化数据（如日志、图片、视频）。</td>
</tr>
<tr>
<td>分布式数据库</td>
<td>HBase（列式存储）、Cassandra（宽表）、MongoDB（文档型）</td>
<td>支持高并发读写和横向扩展，适合半结构化数据存储。</td>
</tr>
<tr>
<td>数据仓库</td>
<td>Hive、ClickHouse、Snowflake、Doris</td>
<td>基于 SQL 的离线分析，适合结构化数据的快速查询和聚合。</td>
</tr>
<tr>
<td>对象存储</td>
<td>Amazon S3、阿里云 OSS、腾讯云 COS</td>
<td>云原生的低成本存储服务，适合冷数据和备份。</td>
</tr>
<tr>
<td><strong>场景示例</strong>：</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li><strong>HDFS</strong> 存储原始日志文件 → <strong>Hive</strong> 进行离线分析 → <strong>HBase</strong> 支持实时查询。</li>
</ul>
<ol start="2">
<li><strong>数据计算：从原始数据中提取价值</strong><br>
<strong>核心需求</strong>：高效处理海量数据，支持实时和离线计算。<br>
<strong>典型技术</strong>：</li>
</ol>
<table>
<thead>
<tr>
<th>计算类型</th>
<th>代表技术</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>批处理</td>
<td>Hadoop MapReduce、Spark</td>
<td>处理离线数据（如 T+1 报表），适合大规模数据的高吞吐计算。</td>
</tr>
<tr>
<td>流处理</td>
<td>Flink、Spark Streaming、Kafka Streams</td>
<td>实时处理数据流（如实时监控、风控），支持低延迟和高吞吐。</td>
</tr>
<tr>
<td>交互式查询</td>
<td>Presto、Impala、Doris</td>
<td>支持秒级响应的 SQL 查询，适合即席分析。</td>
</tr>
<tr>
<td>机器学习</td>
<td>TensorFlow、PyTorch、Spark MLlib</td>
<td>分布式训练模型，支持特征工程、模型训练和推理。</td>
</tr>
<tr>
<td>图计算</td>
<td>Apache Giraph、Neo4j、Spark GraphX</td>
<td>处理复杂关系数据（如社交网络分析、推荐系统）。</td>
</tr>
</tbody>
</table>
<p><strong>场景示例</strong>：</p>
<ul>
<li><strong>Spark</strong> 清洗原始数据 → <strong>Flink</strong> 实时统计用户行为 → <strong>TensorFlow</strong> 训练推荐模型。</li>
</ul>
<ol start="3">
<li><strong>数据传输：数据流动与集成</strong><br>
<strong>核心需求</strong>：高效、可靠地在不同系统间传输数据。<br>
<strong>典型技术</strong>：</li>
</ol>
<table>
<thead>
<tr>
<th>类型</th>
<th>代表技术</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>消息队列</td>
<td>Kafka、RabbitMQ、RocketMQ</td>
<td>高吞吐、低延迟的消息传递，支持削峰填谷和解耦系统。</td>
</tr>
<tr>
<td>数据集成</td>
<td>Flume、Sqoop、DataX</td>
<td>支持异构数据源（如数据库、文件系统）之间的数据迁移和同步。</td>
</tr>
<tr>
<td>实时同步</td>
<td>Debezium、Canal</td>
<td>基于数据库日志的实时数据捕获（CDC），用于实时数仓和数据湖。</td>
</tr>
<tr>
<td>服务间通信</td>
<td>gRPC、RESTful API</td>
<td>微服务架构下的轻量级数据传输协议。</td>
</tr>
<tr>
<td><strong>场景示例</strong>：</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Kafka</strong> 接收用户行为日志 → <strong>Flink</strong> 实时处理 → <strong>HBase</strong> 存储结果。</li>
</ul>
<h4 id="新兴趋势与选型建议">新兴趋势与选型建议</h4>
<ol>
<li>
<p><strong>技术选型关键点</strong></p>
<ul>
<li><strong>批处理</strong>：Spark、Hive</li>
<li><strong>流处理</strong>：Flink、Kafka Streams</li>
<li><strong>实时分析</strong>：ClickHouse、Druid</li>
<li><strong>机器学习</strong>：Spark MLlib、TensorFlow</li>
<li><strong>云原生</strong>：Kubernetes + Flink/Spark</li>
</ul>
</li>
<li>
<p><strong>趋势方向</strong></p>
<ul>
<li><strong>批流一体</strong>：Flink 主导，Spark Structured Streaming 跟进。</li>
<li><strong>湖仓一体</strong>：Delta Lake、Iceberg、Hudi 推动数据湖与数据仓库融合。</li>
<li><strong>Serverless 化</strong>：云厂商提供托管服务（如 AWS EMR、阿里云 MaxCompute）。</li>
</ul>
</li>
</ol>
<h3 id="大数据处理流程">大数据处理流程</h3>
<h4 id="1-数据仓库构建流程">1. <strong>数据仓库构建流程</strong></h4>
<ol>
<li>
<p><strong>数据抽取</strong>：</p>
<ul>
<li>使用 <strong>Sqoop</strong> 从关系型数据库（如 MySQL、Oracle）中抽取结构化数据。</li>
<li>使用 <strong>Flume</strong> 收集日志文件等半结构化数据。</li>
</ul>
</li>
<li>
<p><strong>数据存储</strong>：</p>
<ul>
<li>将抽取的数据暂存到 <strong>HDFS</strong>（Hadoop 分布式文件系统）中。</li>
<li>对于需要快速查询的数据，可以存储到 <strong>HBase</strong>（分布式列式数据库）中。</li>
</ul>
</li>
<li>
<p><strong>数据清洗与转换</strong>：</p>
<ul>
<li>使用 <strong>Hive</strong> 或 <strong>Pig</strong> 对暂存的数据进行清洗、转换和集成。</li>
<li>将清洗后的数据加载到 <strong>HBase</strong> 或 <strong>HDFS</strong> 中。</li>
</ul>
</li>
<li>
<p><strong>数据分析</strong>：</p>
<ul>
<li>使用 <strong>ElasticSearch</strong> 对数据进行快速搜索和分析。</li>
<li>使用 <strong>Spark SQL</strong> 进行复杂的 SQL 查询和分析。</li>
</ul>
</li>
<li>
<p><strong>资源管理与调度</strong>：</p>
<ul>
<li><strong>Yarn</strong> 负责为计算任务分配资源。</li>
<li><strong>Oozie</strong> 或 <strong>Azkaban</strong> 用于编排和调度数据处理任务。</li>
</ul>
</li>
<li>
<p><strong>分布式协调</strong>：</p>
<ul>
<li><strong>Zookeeper</strong> 提供分布式协调服务，确保各组件协调工作及数据的一致性和完整性。</li>
</ul>
</li>
</ol>
<h4 id="2-流处理流程">2. <strong>流处理流程</strong></h4>
<ol>
<li>
<p><strong>数据捕获</strong>：</p>
<ul>
<li>使用 <strong>OGG/CDC</strong> 捕获数据库中的数据变更。</li>
</ul>
</li>
<li>
<p><strong>数据传输</strong>：</p>
<ul>
<li>将捕获的实时数据传输到 <strong>Kafka</strong>（高吞吐量的分布式消息队列系统）。</li>
<li>Kafka 接收来自各种数据源的实时数据，并可靠地存储和传输。</li>
</ul>
</li>
<li>
<p><strong>数据处理</strong>：</p>
<ul>
<li><strong>Spark Streaming</strong> 从 Kafka 中获取实时数据流。</li>
<li>将数据流切分成小的时间片（batch），在每个时间片内采用类似批处理的方式进行处理。</li>
<li>实现近实时的数据分析。</li>
</ul>
</li>
<li>
<p><strong>分布式协调</strong>：</p>
<ul>
<li><strong>Zookeeper</strong> 提供分布式协调服务，确保各组件正常运行和协调工作。</li>
</ul>
</li>
</ol>
<p>数据仓库构建流程：<br>
构建<strong>数据仓库</strong>时，首先利用Sqoop从关系型数据库等数据源抽取结构化数据，Flume收集日志等半结构化数据，将其汇聚后暂存于HDFS。接着借助Hive或Pig在Hadoop集群上对暂存数据进行清洗、转换和集成等操作，然后将转换后的数据加载到HBase中。通过ElasticSearch可快速搜索分析数据，SparkSQL可进行复杂SQL查询分析。分布式资源调度Yarn为计算任务分配资源，Oozie或Azkaban编排调度任务，Zookeeper则负责分布式协调 ，确保各组件协调工作及数据的一致性和完整性，从而构建起完整的数据仓库体系，为企业决策提供数据支持。</p>
<pre><code class="highlight mermaid">graph TD
    A[数据源] --&gt;|数据库| B[Sqoop 抽取数据]
    A --&gt;|日志文件| C[Flume 收集数据]
    B --&gt; D[暂存到 HDFS/HBase]
    C --&gt; D
    D --&gt; E[Hive/Pig 清洗、转换、集成]
    E --&gt; F[加载到 HBase/HDFS]
    F --&gt; G[ElasticSearch/Spark SQL 分析]
    G --&gt; H[Yarn 资源分配]
    H --&gt; I[Oozie/Azkaban 任务调度]
    I --&gt; J[Zookeeper 分布式协调]
    J --&gt; K[数据仓库（支持企业决策）]
流处理流程</code></pre>
<p>流处理过程：<br>
数据源的实时数据通过OGG/CDC捕获数据库中的数据变更，并传输到Kafka，Kafka作为高吞吐量的分布式消息队列系统接收来自各种数据源的实时数据并可靠存储和传输，Spark Streaming从Kafka中获取实时数据流，将其切分成小的时间片（batch），然后在每个时间片内采用类似批处理的方式进行处理，实现近实时的数据分析，整个过程中Zookeeper提供分布式协调服务确保各组件正常运行和协调工作。</p>
<pre><code class="highlight mermaid">graph TD
    A[数据源（数据库）] --&gt; B[OGG/CDC 捕获数据变更]
    B --&gt; C[Kafka 接收和传输实时数据]
    C --&gt; D[Spark Streaming 处理数据流]
    D --&gt; E[Zookeeper 分布式协调]
    E --&gt; F[近实时数据分析]</code></pre>
<ol>
<li>
<p><strong>数据仓库构建</strong>：</p>
<ul>
<li>强调从数据抽取到存储、清洗、转换、分析的完整流程。</li>
<li>使用多种工具（如 Sqoop、Flume、Hive、Spark SQL）实现数据的多维度处理。</li>
</ul>
</li>
<li>
<p><strong>流处理</strong>：</p>
<ul>
<li>强调实时数据的捕获、传输和处理。</li>
<li>使用 Kafka 和 Spark Streaming 实现高吞吐量和低延迟的实时分析。</li>
</ul>
</li>
<li>
<p><strong>分布式协调</strong>：</p>
<ul>
<li>Zookeeper 在整个流程中起到关键作用，确保各组件协调工作。</li>
</ul>
</li>
<li>
<p><strong>资源管理</strong>：</p>
<ul>
<li>Yarn 负责资源分配，Oozie/Azkaban 负责任务调度，确保系统高效运行。</li>
</ul>
</li>
</ol>
<h1>Hadoop</h1>
<p>Hadoop 是一个开源的<strong>分布式</strong>计算框架，主要用于处理海量数据。Hadoop 生态系统包括多个核心组件，其中最为关键的三个组件是 <mark>HDFS、YARN、MapReduce</mark>。这三者各自承担着不同的职责，并且密切协作，共同完成大规模数据存储与计算任务的处理。<br>
Hadoop是一个集合了<mark>存储、计算、资源调度</mark>为一体的大数据分布式框架<br>
<strong>分布式系统的常见组织形式</strong>：</p>
<ul>
<li>去中心化模式：没有明确的中心，大家协调工作</li>
<li>中心化模式：有明确的中心，基于中心节点分配工作</li>
</ul>
<p>Hadoop是一个主从模式（中心化模式）架构的技术框架<br>
<a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_38141444/article/details/144107438">https://blog.csdn.net/m0_38141444/article/details/144107438</a></p>
<h2 id="HDFS（数据存储）">HDFS（数据存储）</h2>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/lydms/article/details/133521657">HDFS最基础使用_hdfs的基本操作-CSDN博客</a><br>
HDFS是<mark>Hadoop分布式文件系统</mark>，是一个高度容错性的系统，适合部署在廉价商用机器上。它可以存储大规模的数据，并提供高吞吐量的数据访问，能为上层的大数据处理框架提供可靠的数据存储基础。时GFS的开源实现<br>
在开源大数据体系中，地位无可替代<br>
<strong>设计目标</strong>：<br>
运行在大量廉价商用机器上，硬件错误是常态，提供<mark>容错</mark>机制<br>
简单一致性模型：一次写入多次读取，支持<mark>追加</mark>，不允许修改，保证数据一致性<br>
流式数据访问：<mark>批量</mark>读而非随机读，关注<mark>吞吐量</mark>而非时间<br>
存储<mark>大规模</mark>数据集：典型文件大小GB~TB，关注横向线性扩展</p>
<p><strong>优点</strong>：</p>
<ul>
<li><strong>高容错、高可用、高扩展</strong>：
<ul>
<li>数据冗余多副本，副本丢失后自动恢复。</li>
<li>具备NameNode HA（高可用性）、安全模式。</li>
<li>可支持10K节点规模。</li>
</ul>
</li>
<li><strong>海量数据存储</strong>：典型文件大小GB~TB，能处理百万以上文件数量，数据规模达PB以上。</li>
<li><strong>构建成本低、安全可靠</strong>：构建在廉价的商用服务器上，并提供了容错和恢复机制。</li>
<li><strong>适合大规模离线批处理</strong>：支持流式数据访问，且数据位置暴露给计算框架。</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>不适合<strong>低延迟</strong>数据访问。[延迟很高，因为更关注可靠性，看是否可以存储海量数据，不关注是否可以快速存储；<mark>HBase</mark>关注延迟，延迟低]</li>
<li>不支持<strong>并发</strong>写入：一个文件同时只能有一个写入者。</li>
<li>不适合<strong>大量小文件</strong>存储：元数据会占用NameNode大量内存空间，且磁盘寻道时间超过读取时间。<br>
<mark>元数据</mark>：指关于文件或目录的描述信息，包括文件所在路径、文件名称、文件类型、生成时间、副本、权限等</li>
<li>不支持文件<strong>随机修改</strong>：仅支持<strong>追加</strong>写入。【<mark>HBase</mark>支持随即修改】</li>
</ul>
<h3 id="架构">架构</h3>
<h2 id="HDFS采用主从架构，主要由NameNode、DataNode和Standby-NameNode组成。image-png-450主从（Master-Slave）加主备（Active-Standby）架构的系统架构图image-6">HDFS采用<mark>主从架构</mark>，主要由NameNode、DataNode和Standby NameNode组成。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/20250320193602782.png" alt="image.png|450"><br>
主从（Master/Slave）加主备（Active/Standby）架构的系统架构图<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%206.png" alt="image 6"></h2>
<h4 id="一、核心角色">一、核心角色</h4>
<ol>
<li>
<p><strong>NameNode (Active)</strong></p>
<ul>
<li><strong>角色</strong>：主名称节点，负责管理文件系统的命名空间（Namespace）和元数据（Metadata）。</li>
<li><strong>功能</strong>：
<ul>
<li>维护文件系统的目录树结构和文件元数据（如文件名、权限、块位置）。</li>
<li>处理客户端的读写请求，协调数据存储与访问。</li>
<li>监控 DataNode 的状态，确保数据块的复制和平衡。</li>
</ul>
</li>
<li><strong>特点</strong>：
<ul>
<li><strong>单点故障</strong>：在非 HA 架构中，NameNode 是单点，故障会导致集群不可用。</li>
<li><strong>高可用扩展</strong>：在 HA 架构中，通过 Standby NameNode 实现故障自动切换。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>NameNode (Standby)</strong></p>
<ul>
<li><strong>角色</strong>：备用名称节点，作为 Active NameNode 的热备份。</li>
<li><strong>功能</strong>：
<ul>
<li>实时同步 Active NameNode 的命名空间和元数据。</li>
<li>在 Active NameNode 故障时，通过 ZooKeeper 自动切换为主节点。</li>
</ul>
</li>
<li><strong>特点</strong>：
<ul>
<li><strong>零恢复时间</strong>：实现秒级故障切换（Failover）。</li>
<li><strong>依赖组件</strong>：需 JournalNode 和 ZooKeeper 支持。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>DataNode</strong></p>
<ul>
<li><strong>角色</strong>：数据节点，负责存储实际的数据块。</li>
<li><strong>功能</strong>：
<ul>
<li>执行数据块的本地存储、读取和删除操作。</li>
<li>定期向 NameNode 发送心跳信号和块报告（Block Report）。</li>
<li>根据 NameNode 指令进行数据块复制或删除。</li>
</ul>
</li>
<li><strong>特点</strong>：
<ul>
<li><strong>横向扩展</strong>：通过增加 DataNode 提升存储容量和吞吐量。</li>
<li><strong>数据冗余</strong>：默认每个数据块复制 3 份，确保容错性。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Secondary NameNode</strong></p>
<ul>
<li><strong>角色</strong>：辅助节点，用于元数据维护（非热备）。</li>
<li><strong>功能</strong>：
<ul>
<li>定期从 NameNode 下载 FsImage（文件系统镜像）和 EditLog（编辑日志）。</li>
<li>合并生成新的 FsImage，减少 NameNode 启动时间。</li>
</ul>
</li>
<li><strong>特点</strong>：
<ul>
<li><strong>非热备节点</strong>：无法接管 NameNode 工作，仅用于元数据维护。</li>
<li><strong>逐步淘汰</strong>：在 HA 架构中被 Standby NameNode 取代。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="二、组件间关系">二、组件间关系</h4>
<ol>
<li>
<p><strong>HDFS Client</strong></p>
<ul>
<li><strong>角色</strong>：HDFS 客户端，用于与 NameNode 进行交互。</li>
<li><strong>功能</strong>：
<ul>
<li>执行文件系统操作（如创建、读取、写入文件）。</li>
<li>通过 NameNode 获取数据块位置，直接与 DataNode 通信进行数据读写。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Namespace/Metadata</strong></p>
<ul>
<li><strong>角色</strong>：文件系统的命名空间和元数据，由 NameNode 管理。</li>
<li><strong>内容</strong>：
<ul>
<li>文件目录树结构。</li>
<li>文件元数据（如文件名、权限、块位置）。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Namespace/Metadata Backup</strong></p>
<ul>
<li><strong>角色</strong>：备用名称节点保存的命名空间和元数据备份。</li>
<li><strong>功能</strong>：
<ul>
<li>在主节点故障时提供数据一致性和快速恢复。</li>
<li>在 HA 架构中，通过 JournalNode 实时同步元数据。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="三、数据传输与管理">三、数据传输与管理</h4>
<ol>
<li>
<p><strong>心跳机制（Heartbeats）</strong></p>
<ul>
<li><strong>功能</strong>：DataNode 定期向 NameNode 发送心跳信号，汇报存储状态。</li>
<li><strong>作用</strong>：
<ul>
<li>确保 NameNode 能够监控 DataNode 的健康状态。</li>
<li>检测故障节点并触发数据块复制。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>数据平衡（Balancing）</strong></p>
<ul>
<li><strong>功能</strong>：NameNode 根据 DataNode 的存储负载，调度数据块迁移。</li>
<li><strong>目标</strong>：
<ul>
<li>均衡集群存储负载，避免单点过载。</li>
<li>提升数据读写性能。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>数据复制（Replication）</strong></p>
<ul>
<li><strong>功能</strong>：NameNode 根据配置的副本因子（默认 3），调度数据块复制。</li>
<li><strong>目标</strong>：
<ul>
<li>确保数据的可靠性和容错性。</li>
<li>支持高并发读取。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>本地磁盘存储</strong></p>
<ul>
<li><strong>功能</strong>：DataNode 将数据块写入本地磁盘进行存储。</li>
<li><strong>特点</strong>：
<ul>
<li>数据块以文件形式存储，支持高效读写。</li>
<li>默认存储路径为 <code>dfs.data.dir</code>（如 <code>/data/hadoop/hdfs/datanode</code>）。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="四、架构演进">四、架构演进</h4>
<ol>
<li>
<p><strong>传统架构（非 HA）</strong></p>
<ul>
<li><strong>组成</strong>：<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">NameNode（主） + Secondary NameNode（辅助） + DataNodes（从）</span><br></pre></td></tr></table></figure>
</li>
<li><strong>问题</strong>：NameNode 单点故障，Secondary NameNode 无法接管服务。</li>
</ul>
</li>
<li>
<p><strong>HA 架构</strong></p>
<ul>
<li><strong>组成</strong>：<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Active NameNode（主） + Standby NameNode（备） + JournalNodes（日志同步） + ZooKeeper（协调） + DataNodes（从）</span><br></pre></td></tr></table></figure>
</li>
<li><strong>改进</strong>：通过热备和自动故障切换解决单点问题，Secondary NameNode 不再需要。</li>
</ul>
</li>
</ol>
<h4 id="五、操作建议">五、操作建议</h4>
<ol start="2">
<li>
<p><strong>非 HA 集群</strong></p>
<ul>
<li>使用 Secondary NameNode 辅助维护元数据，但需定期备份 FsImage 和 EditLog 以应对 NameNode 故障。</li>
</ul>
</li>
<li>
<p><strong>HA 集群</strong></p>
<ul>
<li>部署 Standby NameNode + JournalNode + ZooKeeper，彻底消除单点故障风险。</li>
</ul>
</li>
</ol>
<h3 id="数据存储Block">数据存储Block</h3>
<p>HDFS的最小存储单元<br>
DataNode在存储数据的时候是按照block为单位读写数据的<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%207.png" alt="image 7"></p>
<ol>
<li><strong>数据分块</strong>：当用户上传一个大文件到 HDFS 时，文件系统会将其切割成固定大小的 block 块（在 HDFS 中，默认 block 大小通常为 128MB 或 256MB 等，可配置）。这样做是为了便于管理和存储。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%208.png" alt="image 8"></li>
<li><strong>存储分配</strong>：这些 block 块会被分散存储到集群中的多个 DataNode 节点上。NameNode 负责记录每个文件的元数据信息，包括文件由哪些 block 组成，以及这些 block 分别存储在哪些 DataNode 上。【hdfs中block默认保存3个备份，多个副本不会存放在同一个 DataNode 上】<br>
HDFS分配策略：
<ol>
<li>机架感知：尽量将副本分布在不同机架的 DataNode 上，以提升数据的容错能力</li>
<li>副本均匀分布：DataNode的Block的副本数和访问负荷要比较接近，以实现<strong>负载均衡</strong><br>
Block副本放置策略：</li>
</ol>
<ul>
<li><strong>副本1</strong>：优先放置在<mark>Client所在节点</mark>上。若Client是远程的，系统会随机选择机架和节点放置。这样做可以减少数据传输的网络开销，因为客户端可以直接在本地节点上访问副本，提高读取效率。</li>
<li><strong>副本2</strong>：放置在<mark>与副本1不同的机架</mark>上。这是为了提升数据的容错能力，因为如果某个机架出现故障（如网络中断、电力问题等），另一个机架上的副本仍然可用，保证了数据的可靠性。</li>
<li><strong>副本3</strong>：放置在<mark>与副本2同一机架的不同节点</mark>上。一方面，在同一机架内节点间的网络传输速度通常较快，有助于提高数据读取性能；另一方面，也提供了一定的冗余和容错能力。</li>
<li><strong>副本N（N &gt; 3）</strong>：在遵循相关原则的前提下<mark>随机</mark>选择节点放置。这些原则确保了副本的分散性和集群的负载均衡。
<ul>
<li><strong>避免选择访问负荷太重的节点</strong>：防止因某个节点负载过高而影响整个集群的性能。如果将副本放置在已经繁忙的节点上，可能会导致该节点的响应速度变慢，影响数据的读写操作。</li>
<li><strong>避免选择存储太满的节点</strong>：确保集群的存储资源得到合理利用。将副本放置在存储已满或接近满的节点上，可能会导致该节点无法存储新的数据，或者引发数据迁移等额外操作。</li>
<li><strong>避免将Block的所有副本都放在同一机架上</strong>：进一步增强数据的容错能力。如果所有副本都在同一机架，一旦该机架出现问题，数据将无法访问，通过分散在不同机架，可以有效降低这种风险。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%209.png" alt="image 9"></li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="Block文件的存储和元数据">Block文件的存储和元数据</h3>
<p>Block文件存储</p>
<ul>
<li><strong>文件命名</strong>：DataNode本地磁盘中的Block文件名为“blk_blockId”形式，这是一种在Linux系统下的文件命名规则。</li>
<li><strong>目录创建</strong>：DataNode启动时会自动创建存储目录，无需手动格式化。</li>
<li><strong>目录结构</strong>：在DataNode的存储目录（由配置项${dfs.datanode.data.dir}指定）下，有一个名为“current”的目录，该目录下的文件名都以“blk_”为前缀，用于存放实际的Block数据文件。</li>
</ul>
<p>Block元数据文件</p>
<ul>
<li><strong>文件构成</strong>：Block元数据文件（以“.meta”为后缀）由一个包含版本、类型信息的头文件和一系列校验值组成。这些元数据对于验证和管理Block数据的完整性和正确性非常重要。<br>
图中展示了一个具体的目录结构示例：<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2010.png" alt="image 10"></li>
<li>在${dfs.datanode.data.dir}目录下，有“current”目录。</li>
<li>“current”目录下有一个以“BP-”开头的子目录（如BP-526805057-127.0.0.1-1411980876842），该子目录下又有一个“current”子目录。</li>
<li>此“current”子目录下包含“VERSION”文件、“finalized”目录（存放已完成的Block数据文件及对应的元数据文件，如blk_1073741825和blk_1073741825_1001.meta ）、“rbw”目录（可能与正在进行读写操作的Block相关）。</li>
<li>最外层的“current”目录同层级还有“VERSION”文件和“in_use.lock”文件，其中“in_use.lock”表示DataNode正在对文件夹进行操作，用于防止并发访问冲突。</li>
</ul>
<h3 id="元数据存储">元数据存储</h3>
<p>元数据是描述数据的数据，在HDFS中，主要包括：</p>
<ul>
<li><strong>目录文件的基本属性</strong>：例如名称、所有者等信息，这些属性用于标识和管理文件系统中的目录和文件。</li>
<li><strong>Block相关信息</strong>：记录文件包含哪些数据块（Block），以及这些Block分别存储在哪些节点上。这对于文件的读写操作以及数据的定位至关重要。</li>
<li><strong>DataNode相关信息</strong>：包含DataNode节点的相关信息，如节点的状态、存储容量等，帮助NameNode管理和监控DataNode。</li>
</ul>
<p>NameNode将元数据存储在内存中，同时将元数据的持久化信息存储在本地磁盘的文件中，以确保在系统重启后能够恢复元数据。</p>
<h3 id="内存元数据">内存元数据</h3>
<p>内存元数据是存储在NameNode内存中的元数据信息，具有实时性，分为：</p>
<ul>
<li><strong>Active NameNode</strong>：保存最新的元数据，由fsimage和edits组成。fsimage是文件系统元数据的静态快照，而edits记录了自上次fsimage创建以来的所有元数据更改操作，Active NameNode会实时更新这些元数据。</li>
<li><strong>Standby NameNode</strong>：通过Quorum Journal Manager（QJM）定期（默认60秒）从Active NameNode同步元数据，作为热备份，以确保在Active NameNode出现故障时能够快速切换，保证系统的高可用性。</li>
</ul>
<h3 id="文件元数据">文件元数据</h3>
<p>在HDFS中，不同元数据的持久化需求因特性和作用而异：<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/28ef4cd4c4d7e3c9bd6be9e1391f230.jpg" alt="28ef4cd4c4d7e3c9bd6be9e1391f230"></p>
<ul>
<li><strong>数据块位置信息（如Block1：node01,node02,node03）</strong>：虽重要但无需强一致持久化。DataNode定期向NameNode发送心跳并汇报数据块存储信息，NameNode故障或重启时可借此重建位置信息，且频繁持久化会增加磁盘I/O开销，动态收集维护方式更有利系统性能与灵活性。</li>
<li><strong>文件 - 数据块映射元数据（如file:block1,block2,……）</strong>：需持久化。它是文件系统元数据核心，用于维护文件系统结构，NameNode启动时依此恢复目录树和文件组织形式；同时保证数据一致性，在文件读写、副本管理等操作中，确保数据正确处理与存储，对保障数据完整性和可用性十分关键。</li>
</ul>
<p>文件元数据是内存元数据持久化后形成的文件，主要包括：</p>
<ol>
<li>fsimage（元数据检查点镜像文件）
<ul>
<li><strong>含义</strong>：它是文件系统元数据的<mark>静态</mark>快照，包含了文件系统的目录树结构、文件和目录的属性（如名称、所有者、权限等）以及文件到数据块（Block）的映射关系等完整信息。</li>
<li><strong>重要性</strong>：是文件系统元数据的基础，当NameNode启动时，会加载fsimage来恢复文件系统的元数据状态，是系统恢复和正常运行的关键数据，不可或缺。</li>
<li><strong>fsimage 的生成</strong>：Standby NameNode 在 Checkpoint 检查点定期对内存中的元数据进行持久化，从而生成 fsimage 镜像文件。</li>
<li><strong>fsimage 的特性</strong>：其写入速度较慢，因此无法对变更操作进行实时持久化。</li>
<li><strong>fsimage 文件名</strong>：标记出了最后一个变更操作的 Transaction Id（事务 ID）。例如，载入 fsimage_*19，然后在内存中执行 edits_inprogress_*20，就可以还原出最新的元数据。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2011.png" alt="image 11"></li>
<li><strong>目录结构示例</strong>：图中展示了 ${dfs.namenode.name.dir}/current 目录下的相关文件，包括 VERSION 文件、不同的 edits 文件（如 edits_00000000000000000019、edits_inprogress_00000000000000000020 ）、fsimage 文件（如 fsimage_00000000000000000019 ）及其对应的 md5 校验文件，还有 seen_txid 文件和 in_use.lock 文件（表示 NameNode 正在对文件夹进行操作）</li>
</ul>
<h3 id="edits-定期合并到-fsimage-的过程"><strong>edits 定期合并到 fsimage 的过程</strong></h3>
HA（High - Availability）即高可用，在Hadoop分布式文件系统（HDFS）中是指通过一系列技术和机制确保系统在出现硬件故障、软件错误等异常情况下仍能持续对外提供服务，保证数据的可用性和系统的稳定性。以下是使用HA和不使用HA的区别：<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2012.png" alt="image 12"><br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2013.png" alt="image 13">
<ol>
<li>节点角色与功能
<ul>
<li><strong>不使用HA</strong>：典型的是Hadoop 1.x架构，存在单一的NameNode（Primary NameNode，PN）和Secondary NameNode（SN）。Secondary NameNode主要负责定期合并fsimage和edits文件，起到辅助NameNode管理元数据的作用，但它并不能在Primary NameNode故障时立即接管服务，无法真正实现热备份。</li>
<li><strong>使用HA</strong>：如Hadoop 2.x引入的Active - Standby模式，有Active NameNode（AN）和Standby NameNode（SN）。Active NameNode负责处理客户端的读写请求，维护元数据的实时更新；Standby NameNode则实时同步Active NameNode的元数据信息，在Active NameNode出现故障时能够迅速切换为Active状态，接替其工作，保证服务的连续性。</li>
</ul>
</li>
<li>元数据管理与可靠性
<ul>
<li><strong>不使用HA</strong>：Primary NameNode上的edits文件没有高可用保障，如果Primary NameNode的edits文件损坏，将导致元数据丢失，影响系统恢复和正常运行。而且Secondary NameNode上的edits不是最新的，在故障恢复时可能无法完全恢复到最新的元数据状态。</li>
<li><strong>使用HA</strong>：借助Quorum Journal Manager（QJM）共享存储系统，基于Paxos算法实现的JournalNode集群，实现了edits的高可用存储和共享访问。Active NameNode将变更操作同步写入本地和QJM的edits，只要过半（≥n + 1，n为JournalNode节点数的一半）JournalNode节点写入成功，写操作就完成，即使部分节点故障也不会丢失edits数据，大大提高了元数据的可靠性。</li>
</ul>
</li>
<li>服务可用性与故障恢复
<ul>
<li><strong>不使用HA</strong>：当NameNode出现故障时，系统无法对外提供完整的服务，需要人工干预进行恢复操作，恢复时间较长，在此期间可能影响业务的正常进行。</li>
<li><strong>使用HA</strong>：Standby NameNode会持续监控Active NameNode的状态，当检测到Active NameNode故障时，能够自动快速地进行主备切换，由Standby NameNode变为Active状态继续提供服务，整个切换过程对客户端透明，大大缩短了服务中断时间，提高了系统的可用性。</li>
</ul>
</li>
</ol>
<h3 id="4-性能与负载均衡">4. 性能与负载均衡</h3>
<ul>
<li><strong>不使用HA</strong>：所有的元数据管理和客户端请求处理都集中在单一的NameNode上，容易成为性能瓶颈，且无法实现负载均衡。</li>
<li><strong>使用HA</strong>：Active - Standby模式下，Standby NameNode可以在一定程度上分担部分元数据的同步和管理任务，并且通过合理的配置和管理，可以更好地实现集群的负载均衡，提升系统的整体性能。<br>
使用HA：</li>
</ul>
<ol>
<li><strong>日常操作记录</strong>：在 HDFS 正常运行过程中，NameNode 将对文件系统元数据的变更操作（如文件创建、删除、重命名等）首先记录到 edits 文件中，同时更新内存中的元数据。由于 edits 记录操作相对快速，能够满足实时性要求。</li>
<li><strong>Checkpoint 触发</strong>：达到一定条件（如时间间隔或事务数量阈值等，具体可配置）时，会触发 Checkpoint 操作。Standby NameNode 负责执行该操作（在一些配置下也可能有其他机制参与）。</li>
<li><strong>元数据同步</strong>：Standby NameNode 从 Active NameNode 获取最新的 edits 文件和 fsimage 文件（或相关元数据信息）。</li>
<li><strong>合并操作</strong>：Standby NameNode 将 edits 文件中的变更操作应用到 fsimage 上，即在内存中把 fsimage 加载并根据 edits 中的记录更新元数据状态，生成新的 fsimage 文件，这个新的 fsimage 反映了截止到 Checkpoint 时刻的最新文件系统元数据状态。</li>
<li><strong>文件更新与清理</strong>：新生成的 fsimage 文件会被写回磁盘存储，同时旧的 edits 文件可以被标记为不再使用（后续可能会被清理或归档），并创建一个新的空的 edits_inprogress 文件，用于记录下一轮 Checkpoint 之前的新的元数据变更操作。<br>
通过这种定期合并机制，HDFS 能够在保证元数据实时更新的同时，定期对元数据进行持久化存储，确保系统在重启或故障恢复时能够正确还原文件系统状态。</li>
</ol>
</li>
<li>edits**（编辑日志文件）**：
<ul>
<li><strong>含义</strong>：记录了自上次fsimage创建或Checkpoint之后，文件系统的所有元数据变更操作，比如文件的创建、删除、重命名，以及数据块的位置变化等。<br>
Checkpoint是将内存中的元数据状态合并到fsimage文件的过程，而edits记录了两次Checkpoint之间的操作变化。</li>
<li><strong>重要性</strong>：由于NameNode的内存元数据会不断因各种操作而变化，edits保存了这些操作记录，使得系统在重启或故障恢复时，能够基于fsimage和edits重新构建出最新的完整元数据状态，保证数据的一致性和完整性。</li>
<li><strong>操作顺序</strong>：变更操作应先写入edits文件，然后再更新内存中的元数据，以保证数据的一致性和持久性。</li>
<li><strong>文件名</strong>：edits文件名通过“Transaction Id前后缀”标记所包含更新操作的范围，便于管理和追踪元数据的变更历史。</li>
</ul>
</li>
</ol>
<h3 id="读写流程">读写流程</h3>
<p>写流程：<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2014.png" alt="image 14"></p>
<ol>
<li>Client（客户端）：用来发起读写请求，并拆分文件成多个 Block；</li>
<li>NameNode：全局的协调和把控所有的请求，提供 Block 存放在 DataNode 上的地址；</li>
<li>DataNode：负责数据的存储，可以有很多个；</li>
</ol>
<p>注：block由客户端分割</p>
<p>读流程：<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2015.png" alt="image 15"></p>
<ul>
<li>客户端：提供文件名、副本数、Block 数量、Block 地址；</li>
<li>NameNode：提供 DataNode 地址及内部位置；</li>
<li><strong>读流程</strong>：客户端向NameNode发送读请求，NameNode根据请求返回文件的数据块位置信息，客户端根据这些信息直接从相应的DataNode读取数据。</li>
<li><strong>写流程</strong>：客户端向NameNode发送写请求，NameNode根据文件大小和块大小等信息，确定数据块的分布位置，并返回可用的DataNode列表。客户端将数据分块写入这些DataNode，DataNode之间会进行数据的复制和同步。</li>
</ul>
<h3 id="安全模式">安全模式</h3>
<p>安全模式定义：</p>
<ul>
<li><strong>读写特性</strong>：安全模式是HDFS的特殊状态，在此状态下，HDFS仅接收<mark>读</mark>数据请求，不接收写入、删除、修改等变更请求，即系统处于“只读”状态。</li>
<li><strong>保护机制</strong>：它是HDFS确保Block数据安全的一种保护机制。当Active NameNode启动时，HDFS会进入安全模式。期间，DataNode主动向NameNode汇报可用Block列表等信息，在系统达到安全标准之前，一直维持该只读状态。<br>
正常离开安全模式的条件</li>
<li><strong>Block上报率</strong>：其计算方式为DataNode上报的可用Block个数除以NameNode元数据记录的Block个数。</li>
<li><strong>阈值判断</strong>：当Block上报率大于或等于阈值时，HDFS才能离开安全模式。默认阈值为0.999，即当DataNode上报的可用Block个数达到NameNode元数据记录的Block个数的99.9%及以上时，系统可正常离开安全模式。</li>
<li><strong>操作建议</strong>：不建议手动强制退出安全模式，以保障数据安全和系统稳定。<br>
HDFS触发安全模式的原因</li>
<li><strong>NameNode相关</strong>：
<ul>
<li><strong>NameNode重启</strong>：启动时，HDFS会进入安全模式，等待DataNode汇报可用Block列表等信息，以确保数据状态的一致性和安全性。</li>
<li><strong>NameNode磁盘空间不足</strong>：可能影响元数据的正常存储和操作，为避免数据损坏等问题，HDFS进入安全模式，此时仅允许读操作。</li>
</ul>
</li>
<li><strong>DataNode相关</strong>：
<ul>
<li><strong>Block上报率低于阈值</strong>：DataNode上报的可用Block个数与NameNode元数据记录的Block个数的比率低于默认阈值（0.999）时，意味着系统数据完整性可能存在风险，触发安全模式。</li>
<li><strong>DataNode无法正常启动</strong>：部分DataNode无法正常工作，会导致部分数据不可用或数据块信息无法正常上报，从而触发安全模式。</li>
</ul>
</li>
<li><strong>系统异常相关</strong>：
<ul>
<li><strong>日志中出现严重异常</strong>：日志记录了系统运行的关键信息，严重异常可能预示着潜在的系统故障或数据问题，为保障数据安全，HDFS进入安全模式。</li>
</ul>
</li>
<li><strong>人为操作相关</strong>：
<ul>
<li><strong>用户操作不当，如强制关机</strong>：这种突然的、非正常的操作可能破坏系统的正常运行状态和数据一致性，进而触发安全模式。<br>
故障排查</li>
</ul>
</li>
<li><strong>针对DataNode无法正常启动</strong>：找到DataNode不能正常启动的具体原因，如硬件故障、软件错误、配置问题等，解决后重启DataNode，使其能够正常向NameNode汇报数据块信息，帮助系统满足离开安全模式的条件。</li>
<li><strong>针对NameNode磁盘空间不足</strong>：清理NameNode磁盘，释放足够的空间，确保元数据存储和操作的正常进行，使系统能够稳定运行并可能正常离开安全模式。</li>
</ul>
<h3 id="高可用（HA）">高可用（HA）</h3>
<p>HDFS通过多种方式实现高可用。例如，NameNode采用主备模式，当主NameNode出现故障时，备用NameNode会自动接管工作，确保系统的正常运行。同时，数据块在多个DataNode上进行复制，即使部分DataNode故障，也能保证数据的可用性。<br>
架构相关<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2016.png" alt="image 16"></p>
<ul>
<li><strong>组件构成</strong>：如第一张图所示，包含ZooKeeper集群、JournalNode集群、两个NameNode（Active NameNode和Standby NameNode）以及两个FailoverController。ZooKeeper集群用于进行领导者选举和故障检测；JournalNode集群实现edits文件的高可用存储和共享访问；FailoverController负责监控NameNode状态，并在必要时执行故障转移操作。</li>
<li><strong>工作机制</strong>：Active NameNode负责处理客户端读写请求并更新元数据，同时将元数据变更写入本地和JournalNode集群的edits文件；Standby NameNode从JournalNode集群读取edits并应用到自己的元数据，与Active NameNode保持同步。DataNode同时向Active和Standby NameNode汇报块信息。FailoverController通过与ZooKeeper交互，监控NameNode状态，当Active NameNode故障时，Standby NameNode借助ZooKeeper实现自动切换为Active状态，接管集群。</li>
</ul>
<p>实现细节：</p>
<ul>
<li><strong>热备机制</strong>：Hadoop 2.x中提供两台NameNode做热备，即Active和Standby。Active NameNode处理业务请求，Standby NameNode处于待命状态，实时同步元数据。</li>
<li><strong>元数据同步</strong>：通过edits和fsimage文件保证两台NameNode元数据信息一致。Active NameNode将变更操作写入edits，Standby NameNode从JournalNode集群获取edits并应用到本地fsimage，定期合并以维护最新元数据状态。</li>
<li><strong>故障迁移</strong>：依赖ZooKeeper集群实现自动故障迁移。ZooKeeper实时监控NameNode状态，当Active NameNode出现故障，ZooKeeper通知FailoverController，触发故障转移流程，将Standby NameNode切换为Active状态，保证服务连续性。</li>
</ul>
<p>优势与劣势：</p>
<ul>
<li><strong>优势</strong>：具备高容错性，可应对节点故障等异常情况；扩展性良好，便于适应集群规模增长；能实现海量数据的高效读、写，满足大数据存储和处理需求。</li>
<li><strong>劣势</strong>：NameNode存在内存受限问题，虽有Federation机制缓解，但仍有挑战；早期存在NameNode单点故障问题，不过通过HA方案在一定程度上得到解决。</li>
</ul>
<h3 id="基本用法">基本用法</h3>
<ol>
<li>文件系统命令shell【运维人员】<br>
HDFS的shell命令提供了便捷的方式来完成HDFS文件系统的基本操作，常见命令如下：
<ul>
<li><strong>文件和目录操作</strong>：
<ul>
<li><code>hdfs dfs -mkdir &lt;path&gt;</code>：在HDFS上创建目录，例如<code>hdfs dfs -mkdir /test</code>会在根目录下创建名为test的目录。</li>
<li><code>hdfs dfs -ls &lt;path&gt;</code>：列出指定路径下的文件和目录信息，如<code>hdfs dfs -ls /</code>会显示根目录下的内容。</li>
<li><code>hdfs dfs -put &lt;local_path&gt; &lt;hdfs_path&gt;</code>：将本地文件<strong>上传</strong>到HDFS，比如<code>hdfs dfs -put local_file.txt /hdfs_dir/</code>可把本地的local_file.txt文件上传到HDFS的/hdfs_dir/目录下。</li>
<li><code>hdfs dfs -get &lt;hdfs_path&gt; &lt;local_path&gt;</code>：从HDFS<strong>下载</strong>文件到本地，例如<code>hdfs dfs -get /hdfs_file.txt local_dir/</code>会把HDFS上的/hdfs_file.txt文件下载到本地的local_dir/目录。</li>
<li><code>hdfs dfs -rm &lt;hdfs_path&gt;</code>：删除HDFS上的文件或空目录，<code>hdfs dfs -rm -r &lt;hdfs_path&gt;</code>可递归删除目录及其内容（<code>r</code>表示递归）。</li>
</ul>
</li>
<li><strong>文件查看操作</strong>：
<ul>
<li><code>hdfs dfs -cat &lt;hdfs_path&gt;</code>：查看HDFS上文本文件的内容，如<code>hdfs dfs -cat /hdfs_text_file.txt</code>。</li>
<li><code>hdfs dfs -text &lt;hdfs_path&gt;</code>：以文本形式显示HDFS上文件的内容，适用于二进制文件转换为文本显示。<br>
注：<code>hadoop fs &lt;args&gt;</code> 等同于 <code>hdfs dfs &lt;args&gt;</code></li>
</ul>
</li>
</ul>
</li>
<li>REST API【开发人员】<br>
HDFS的REST API提供了除Shell、Java API和C API以外的其他接口，可通过此接口监控HDFS状态等信息。以WebHDFS为例（常见的HDFS REST API实现方式），其使用方法如下：
<ul>
<li><strong>基本访问方式</strong>：WebHDFS开启后，有对应的rest端口（如默认14000 ，不同集群可能不同）。通过HTTP的GET、POST、PUT、DELETE等请求方法来操作HDFS资源。</li>
<li><strong>示例操作</strong>：
<ul>
<li><strong>获取文件或目录信息</strong>：使用GET请求，例如<code>GET http://&lt;namenode_host&gt;:&lt;port&gt;/webhdfs/v1/&lt;path&gt;?op=LISTSTATUS</code>可获取指定路径下的文件和目录列表信息，<code>&lt;namenode_host&gt;</code>是NameNode主机名，<code>&lt;port&gt;</code>是WebHDFS端口，<code>&lt;path&gt;</code>是HDFS路径。</li>
<li><strong>上传文件</strong>：使用PUT请求，如<code>PUT http://&lt;namenode_host&gt;:&lt;port&gt;/webhdfs/v1/&lt;hdfs_path&gt;?op=CREATE&amp;user.name=&lt;username&gt;</code>，并在请求体中包含要上传的文件内容，<code>&lt;username&gt;</code>是用户名，<code>&lt;hdfs_path&gt;</code>是HDFS上的目标路径。</li>
<li><strong>下载文件</strong>：使用GET请求，<code>GET http://&lt;namenode_host&gt;:&lt;port&gt;/webhdfs/v1/&lt;hdfs_path&gt;?op=OPEN</code>，然后读取响应体中的文件内容。<br>
在使用REST API时，如果集群配置了Kerberos认证等安全机制，还需要在请求中处理好认证相关的内容，以确保合法访问HDFS资源。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="运维管理">运维管理</h3>
<p>HDFS的运维管理包括节点的监控、数据的备份和恢复、性能的优化等方面。管理员需要定期检查节点的状态，确保数据的完整性和系统的稳定性。同时，还需要根据业务需求对系统进行性能优化，以提高数据的读写速度和处理效率。<br>
<strong>配置管理</strong></p>
<ul>
<li><strong>核心配置文件</strong>：
<ul>
<li><strong>core - site.xml</strong>：用于Hadoop全局配置(HDFS+Yarn+MapReduce)，例如配置NameNode的URI，通过<code>fs.defaultFS</code>属性指定，如  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://nameservice:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><strong>hdfs - site.xml</strong>：进行HDFS局部配置，如<code>dfs.namenode.name.dir</code>指定NameNode存储元数据（fsimage）的本地文件系统位置；<code>dfs.datanode.data.dir</code>确定DataNode存储数据块的位置；<code>dfs.blocksize</code>设置新文件的默认块大小；<code>dfs.replication</code>设定默认的数据块复制因子；<code>fs.trash.interval</code>配置垃圾回收时间间隔，0表示禁用回收站功能。</li>
</ul>
</li>
<li><strong>环境变量文件</strong>：<code>Hadoop - env.sh</code>设置HDFS运行所需的环境变量，比如Java环境变量等。<br>
<strong>节点管理</strong></li>
<li><strong>NameNode操作</strong>：
<ul>
<li><strong>格式化</strong>：使用<code>hdfs namenode -format</code>命令初始化NameNode，若要强制格式化已存在的目录，可添加<code>force</code>选项；还可通过<code>nonInteractive</code>选项实现非交互式操作。</li>
<li><strong>恢复</strong>：当文件系统损坏时，<code>hdfs namenode -recover</code>用于恢复丢失的元数据，<code>force</code>可用于强制恢复。</li>
<li><strong>主备切换（HA）</strong>：在NameNode高可用架构中，<code>hdfs haadmin -failover</code>用于在两个NameNode间发起故障转移；<code>hdfs haadmin -getServiceState</code>可确定给定NameNode是Active还是Standby状态；<code>hdfs haadmin -transitionToActive</code>将指定NameNode转换为Active状态；<code>hdfs haadmin -transitionToStandby</code>则将其转换为Standby状态。</li>
</ul>
</li>
<li><strong>DataNode操作</strong>：
<ul>
<li><strong>退役和服役</strong>：退役DataNode时，先将计划退役的DataNode列表加入<code>dfs.hosts.exclude</code>文件，然后执行<code>hdfs dfsadmin -refreshNodes</code>；等待其状态由In - service变为Decommission后，从<code>dfs.hosts</code>文件中删除该节点。重新服役时，从<code>dfs.hosts.exclude</code>文件中移除相关信息，再执行<code>hdfs dfsadmin -refreshNodes</code>。<br>
<strong>数据管理</strong></li>
</ul>
</li>
<li><strong>数据重分布</strong>：使用<code>hdfs balancer</code>命令平衡DataNode上的数据分布，<code>threshold</code>选项可设置磁盘容量百分比阈值（默认10%），以确定集群平衡标准；<code>exclude</code>可指定不参与平衡的DataNode；<code>include</code>则指定仅参与平衡的DataNode。</li>
<li><strong>文件系统信息报告</strong>：通过<code>hdfs dfsadmin -report</code>获取文件系统基本信息和统计数据，还可使用<code>live</code>、<code>dead</code>、<code>decommissioning</code>等选项过滤显示的DataNode列表。</li>
<li><strong>文件系统健康检查</strong>：利用<code>hdfs fsck</code>检查文件系统健康状况，如<code>hdfs fsck /tmp</code>可检查<code>/tmp</code>路径下文件系统的状态，包括总大小、目录数、文件数、块信息等。<br>
<strong>状态管理</strong></li>
<li><strong>安全模式</strong>：NameNode启动时自动进入，也支持手动进入（<code>hdfs dfsadmin -safemode enter</code>）。该模式下HDFS为只读状态，只支持读操作，不接受写、删除、修改等变更请求。当DataNode上报的Block上报率超过阈值（默认0.999），且满足最小副本条件后，经过一定时间（由<code>dfs.safemode.extension</code>配置，默认30000毫秒），NameNode自动离开安全模式。也可手动离开（<code>hdfs dfsadmin -safemode leave</code>），但需谨慎操作。可使用<code>hdfs dfsadmin -safemode get</code>查看是否处于安全模式，<code>hdfs dfsadmin -safemode wait</code>等待退出安全模式。<br>
<strong>数据均衡带宽设置（BalancerBandwidth）</strong></li>
<li><strong>默认配置</strong>：HDFS数据均衡器（Balancer）的默认带宽为1MB/s，此设置旨在在进行数据均衡操作时，尽量减少对HDFS其他正常操作的影响。</li>
<li><strong>调整建议</strong>：在进行数据均衡时，为加快均衡速度，建议将带宽设置为10MB/s，但同时为避免冲突，最好停止对HDFS的其他操作。可通过命令<code>hdfs dfsadmin -setBalancerBandwidth &lt;bandwidth in bytes per second&gt;</code>来调整带宽，例如<code>hdfs dfsadmin -setBalancerBandwidth 10</code>（单位为字节/秒），该命令会为相关DataNode设置新的均衡带宽。<br>
<strong>分布式拷贝（Distcp）</strong></li>
<li><strong>工具用途</strong>：Distcp是用于大规模集群内部和集群之间拷贝的工具，例如可将数据从一个HDFS集群（H1）拷贝到另一个HDFS集群（H2）。</li>
<li><strong>实现机制</strong>：它使用MapReduce框架来实现文件分发、错误处理与恢复，以及报告生成等功能。</li>
<li><strong>命令选项</strong>：
<ul>
<li><code>m &lt;num_maps&gt;</code>：用于设置最大同时拷贝数，即并行执行拷贝任务的Map数量。</li>
<li><code>overwrite</code>：表示覆盖目标路径已存在的文件。</li>
<li><code>bandwidth</code>：指定每个Map的带宽，单位为MB/秒，用于控制拷贝过程中的带宽使用。<br>
<strong>配额限制（Quota）</strong></li>
</ul>
</li>
<li><strong>限制维度</strong>：HDFS允许管理员对用户目录设置配额，主要从文件数量和文件大小两个维度进行限制。可以限制指定目录及其子目录中的文件总数，以及指定目录中所有文件的容量大小（需考虑副本数）。</li>
<li><strong>相关命令</strong>：
<ul>
<li><code>hdfs dfsadmin -setSpaceQuota &lt;N&gt; &lt;directory&gt;...&lt;directory&gt;</code>：为每个指定目录设置空间配额为N字节。</li>
<li><code>hdfs dfsadmin -clrSpaceQuota &lt;directory&gt;...&lt;directory&gt;</code>：移除每个指定目录的空间配额。</li>
<li><code>hadoop fs -count -q [-h] [-v] &lt;directory&gt;...&lt;directory&gt;</code>：使用 -q选项可报告每个目录设置的名称配额值、剩余可用名称配额、设置的空间配额值以及剩余可用空间配额。 -h选项以人类可读格式显示大小， -v选项显示标题行。<br>
<strong>快照（Snapshot）</strong></li>
</ul>
</li>
<li><strong>基本特性</strong>：HDFS快照是只读的，记录了文件系统在某个时间点的副本，可应用于根目录或其他子目录。</li>
<li><strong>相关命令</strong>：
<ul>
<li><code>hdfs lsSnapshottableDir</code>：获取当前用户有权限创建快照的所有目录。</li>
<li><code>hdfs snapshotDiff &lt;path&gt; &lt;fromSnapshot&gt; &lt;toSnapshot&gt;</code>：获取两个快照之间的差异，此操作需要对两个快照中所有文件/目录具有读访问权限。</li>
<li><code>hdfs dfsadmin -allowSnapshot &lt;path&gt;</code>：允许为指定目录创建快照。</li>
<li><code>hdfs dfsadmin -disallowSnapshot &lt;path&gt;</code>：禁止为指定目录创建快照。</li>
<li><code>hdfs dfs -createSnapshot &lt;path&gt; [&lt;snapshotName&gt;]</code>：为可创建快照的目录创建一个快照，此操作需要该目录所有者权限。</li>
<li><code>hdfs dfs -deleteSnapshot &lt;path&gt; &lt;snapshotName&gt;</code>：从可创建快照的目录中删除一个快照，同样需要目录所有者权限。创建好的Snapshot文件夹在源文件夹下，命名为<code>.snapshot/[&lt;snapshotName&gt;]</code>，恢复时可直接使用cp命令。<br>
<strong>Active NameNode WebUI</strong></li>
</ul>
</li>
<li><strong>访问地址</strong>：可通过<code>http://activeNameNodeHost:50070</code>访问Active NameNode的Web用户界面。</li>
<li><strong>界面信息</strong>：该界面提供了丰富的集群信息，如Overview页面显示集群的基本信息，包括启动时间、版本、集群ID、块池ID等，还展示了安全模式状态、文件和目录数量、块数量、内存使用情况等摘要信息，方便管理员监控集群状态。</li>
</ul>
<h1>Yarn（分布式资源管理系统）</h1>
<p>Hadoop 1.X 中 MapReduce 的先天缺陷</p>
<ol>
<li><strong>架构设计问题：角色耦合</strong>
<ul>
<li><strong>身兼两职</strong>：只有Hadoop【用于存储】和MapReduce 【同时承担了 <strong>计算框架</strong> 和 <strong>资源管理框架</strong> 的职责】。</li>
<li><strong>JobTracker 单点瓶颈</strong>：
<ul>
<li>既负责资源管理（如节点资源分配），又负责任务调度（如监控任务进度）。</li>
<li>任务过重，导致性能开销大，易成为系统瓶颈。</li>
<li>单点故障风险：JobTracker 宕机将导致整个集群不可用。</li>
</ul>
</li>
</ul>
</li>
<li><strong>资源管理模型缺陷</strong>
<ul>
<li><strong>资源描述简单化</strong>：
<ul>
<li>仅以 <strong>Task 数量</strong> 作为资源单位，未考虑 CPU、内存等实际资源需求，导致资源利用率低下。</li>
</ul>
</li>
<li><strong>资源划分僵化</strong>：
<ul>
<li>强制将集群资源划分为 <strong>Map Task Slot</strong> 和 <strong>Reduce Task Slot</strong>，二者无法共享。</li>
<li>例如：若 Map Slot 空闲但 Reduce Slot 不足，资源会被浪费。</li>
</ul>
</li>
</ul>
</li>
<li><strong>扩展性限制</strong>
<ul>
<li>集群规模上限约为 <strong>4000 节点</strong>，主要受限于 JobTracker 的单点处理能力，无法有效支持更大规模集群。</li>
</ul>
</li>
<li><strong>维护与开发困难</strong>
<ul>
<li>源码复杂且高度耦合，升级和维护成本高，难以快速响应新需求（如多计算框架支持）。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2017.png" alt="image 17"><br>
Hadoop 1.X 的 MapReduce 架构在资源管理、扩展性和可靠性上存在显著缺陷，最终被 YARN（Hadoop 2.X）取代。YARN 通过分离资源管理和任务调度的职责（ResourceManager + ApplicationMaster），支持多样化计算框架，并优化了资源利用率与扩展性。<br>
Apache Hadoop YARN（Yet Another Resource Negotiator，另一种资源协调者）是Hadoop的资源管理器，是通用资源管理系统，为上层应用提供统一资源管理和调度。其基本思想是分离JobTracker的资源管理和作业调度/监控功能，创建全局的ResourceManager（RM）和若干针对应用程序的ApplicationMaster（AM）<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2018.png" alt="image 18"><br>
YARN用来调度资源给MapReduce分配和管理运行资源，所以MapReduce需要YARN才能执行（普遍情况）<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2019.png" alt="image 19"><br>
对于资源的利用，有规划、有管理的调度资源使用，是效率最高的方式<br>
Hadoop YARN框架的作用：调度整个服务器集群的资源统一管理<br>
程序如何在YARN内运行</li>
</ul>
</li>
</ol>
<ul>
<li><strong>程序向YARN申请所需资源</strong></li>
</ul>
<h2 id="基本架构">基本架构</h2>
<p>采用 <strong>Master/Slave 架构</strong><br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2020.png" alt="image 20"><br>
主要包含三大模块：</p>
<ol>
<li>**ResourceManager (RM)：**整个集群的资源调度者， 负责协调调度各个程序所需的资源
<ul>
<li><strong>Master 节点</strong>，负责全局资源管理和分配。</li>
<li>功能：
<ul>
<li>接收客户端提交的作业。</li>
<li>分配资源给 ApplicationMaster（AM）。</li>
<li>监控 NodeManager（NM）状态。</li>
</ul>
</li>
<li><strong>高可用实现</strong>：通过 Active/Standby 双节点避免单点故障。</li>
</ul>
</li>
<li><strong>NodeManager (NM)</strong>：管理、分配单个服务器的资源，即创建管理容器，由容器提供资源供程序使用
<ul>
<li><strong>Slave 节点</strong>，部署在集群每个工作节点上。</li>
<li>功能：
<ul>
<li>管理本节点的资源（CPU、内存等）。</li>
<li>启动/监控 <strong>Container</strong>（资源隔离单位）。</li>
<li>向 RM 汇报资源使用情况。</li>
</ul>
</li>
</ul>
</li>
<li><strong>ApplicationMaster (AM)</strong>
<ul>
<li><strong>每个作业专属的管理者</strong>，由 RM 启动。</li>
<li>功能：
<ul>
<li>解析作业需求（如 MapReduce 的 Map/Reduce 阶段）。</li>
<li>向 RM 申请资源（Container）。</li>
<li>与 NM 协作启动任务，监控任务执行。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Container（容器）</strong>
<ul>
<li>容器（Container）是YARN的NodeManager在所属服务器上分配资源的手段</li>
<li>NodeManager预先占用这一部分资源，然后将这一部分资源提供给程序使用</li>
<li>创建一个资源容器，即由NodeManager占用这部分资源</li>
<li>然后应用程序运行在NodeManager创建的这个容器内</li>
<li>应用程序无法突破容器的资源限制</li>
<li><strong>资源抽象单位</strong>，封装了 CPU、内存等资源。</li>
<li>任务运行在 Container 中，由 NM 分配和管理。<br>
Container作为资源分配和调度的<mark>基本单位</mark>，其中封装了的资源如内存，CPU，磁盘，网络带宽等。 目前yarn仅仅封装内存和CPU<br>
Container由ApplicationMaster向ResourceManager申请的，由ResouceManager中的资源调度器异步分配给ApplicationMaster<br>
Container的运行是由ApplicationMaster向资源所在的NodeManager发起的，Container运行时需提供内部执行的任务命令.</li>
</ul>
</li>
</ol>
<ul>
<li>通俗解释</li>
</ul>
<ol>
<li>
<p><strong>ResourceManager（RM）</strong> → <strong>公司大老板</strong></p>
<ul>
<li><strong>职责</strong>：
<ul>
<li>管整个公司的“钱”和“人”（即集群的 CPU、内存等资源）。</li>
<li>决定哪个项目（作业）能拿到资源，分多少资源。</li>
</ul>
</li>
<li><strong>举个栗子</strong>：
<blockquote>
<p>你是老板，公司同时有10个项目要启动。你负责看公司账户有多少钱（资源），然后决定给每个项目分多少钱（比如项目A给100万，项目B给50万）。</p>
</blockquote>
</li>
</ul>
</li>
<li>
<p>NodeManager（NM）** → <strong>部门经理</strong></p>
<ul>
<li><strong>职责</strong>：
<ul>
<li>管自己部门（服务器节点）的“工位”和“员工”（即本机的 CPU、内存、磁盘）。</li>
<li>按照老板（RM）的指示，在自己的部门里腾出工位（Container）给项目用。</li>
</ul>
</li>
<li><strong>举个栗子</strong>：
<blockquote>
<p>你是IT部门经理，老板说要给项目A腾出5个工位。你负责清点部门有多少空工位，然后安排5个工位给项目A的员工干活。</p>
</blockquote>
</li>
</ul>
</li>
<li>
<p><strong>ApplicationMaster（AM）</strong> → <strong>项目经理</strong></p>
</li>
</ol>
<ul>
<li><strong>职责</strong>：<br>
- 每个项目（比如数据分析任务）都有一个专属的项目经理。<br>
- 负责向老板（RM）申请资源，再和部门经理（NM）协调具体执行。
<ul>
<li><strong>举个栗子</strong>：
<blockquote>
<p>你是项目A的经理，需要10个工位和5台电脑。你找老板（RM）申请资源，老板批准后，你去IT部门（NM）沟通：“我们要在你们的工位上安排10个人干活”。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<ol start="4">
<li><strong>Container</strong> → <strong>工位套餐</strong>
<ul>
<li><strong>本质</strong>：
<ul>
<li>一个“资源包”，包含CPU、内存等资源，就像工位上的电脑、桌子、网络。</li>
<li>任务必须在工位（Container）里才能运行。</li>
</ul>
</li>
<li><strong>举个栗子</strong>：
<blockquote>
<p>每个工位套餐（Container）包含：1台电脑（2核CPU）、一张桌子（4GB内存）、网络权限。项目A的员工必须坐在这些工位上才能工作。</p>
</blockquote>
</li>
</ul>
</li>
</ol>
<p>🌟 <strong>整体协作流程（超通俗版）</strong><br>
1. <strong>你（客户）</strong> 想做一个数据分析项目（作业），去找 <strong>大老板（RM）</strong> 申请资源。<br>
2. <strong>大老板（RM）</strong> 说：“行，先给你一个临时工位（Container），让你项目的经理（AM）过来吧！”<br>
3. <strong>项目经理（AM）</strong> 上任后，开始规划：“我需要10个工位，5台高性能电脑！” 然后找大老板（RM）要资源。<br>
4. <strong>大老板（RM）</strong> 联系各部门经理（NM）：“IT部腾出5个工位，市场部腾出5个工位！”<br>
5. <strong>部门经理（NM）</strong> 们清点工位，准备好后告诉项目经理（AM）：“工位搞定了，你的人可以来干活了！”<br>
6. <strong>项目经理（AM）</strong> 监督员工在工位上完成任务，完成后向大老板（RM）汇报：“项目做完了，工位可以收回了！”<br>
💡 <strong>关键理解</strong>：</p>
<ul>
<li><strong>YARN 的核心是“分工”</strong>：老板管全局资源，部门经理管本地资源，项目经理管具体项目。</li>
<li><strong>Container 是资源的最小单位</strong>，就像工位是办公的最小单位。</li>
<li>这种分工让 YARN 能同时跑多个任务（比如一边做数据分析，一边训练AI模型），且互不干扰！<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2021.png" alt="image 21"><br>
YARN 工作流程</li>
</ul>
<ol start="5">
<li>客户端提交作业到 RM。</li>
<li>RM 分配一个 Container，启动该作业的 AM。</li>
<li>AM 向 RM 申请资源（Container）。</li>
<li>RM 返回可用资源列表，AM 与对应 NM 通信启动任务。</li>
<li>任务在 Container 中执行，AM 监控任务状态。</li>
<li>作业完成后，AM 向 RM 注销并释放资源。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2022.png" alt="image 22"><br>
YARN 如何解决 MapReduce 的问题</li>
<li><strong>单点故障率高的问题</strong><br>
在早期的 Hadoop 1.x 中，<strong>JobTracker</strong> 是 MapReduce 的核心组件，既负责资源管理（比如分配 CPU 和内存），又负责任务调度（比如监控任务执行）。这就好比让一个人同时当“财务总监”和“项目经理”，一旦这个人请假或离职，整个公司的工作就会瘫痪。<br>
<strong>YARN 的解决方案</strong>：
<ul>
<li><strong>拆分职责</strong>：YARN 把资源管理和任务调度分开。
<ul>
<li><strong>ResourceManager（RM）</strong>：只当“财务总监”，管全公司的钱（集群资源），不管具体项目怎么用。</li>
<li><strong>ApplicationMaster（AM）</strong>：每个项目（比如 MapReduce 作业、Spark 任务）有自己的“项目经理”，负责向 RM 申请资源，并监督任务执行。</li>
</ul>
</li>
</ul>
</li>
</ol>
<ul>
<li><strong>高可用（HA）</strong>：
<ul>
<li>RM 可以配置成主备模式（类似双领导），主 RM 挂了，备用的立刻顶上，避免整个集群瘫痪。<br>
<strong>通俗比喻</strong>：</li>
</ul>
</li>
</ul>
<blockquote>
<p>以前公司只有一个全能领导（JobTracker），他一病倒，公司全乱套。现在公司分成了财务部（RM）和项目组（AM），财务部有双领导，一个倒了另一个顶上；每个项目组独立运作，互不影响。</p>
</blockquote>
<ol>
<li><strong>通用性差的问题</strong><br>
MapReduce 1.x 的设计是“一专多难”——只擅长批处理，但难以运行其他类型的任务（比如实时计算、机器学习）。比如你想用 Spark 或 Flink，得强行改造 MapReduce 的架构，效率低下。<br>
<strong>YARN 的解决方案</strong>：
<ul>
<li><strong>资源与框架解耦</strong>：YARN 只负责分配资源，不关心任务具体怎么跑。
<ul>
<li><strong>ResourceManager</strong>：统一管理资源，不绑定任何计算框架。</li>
<li><strong>ApplicationMaster</strong>：由不同框架自己实现（比如 MapReduce 有 MapReduce 的 AM，Spark 有 Spark 的 AM）。<br>
<strong>通俗比喻</strong>：</li>
</ul>
</li>
</ul>
<blockquote>
<p>以前公司只能用一种工具干活（比如只能用锤子），想换工具（比如用螺丝刀）得大改生产线。现在公司提供标准化的工作台（YARN），不管你是用锤子、螺丝刀还是电钻（各种计算框架），只要符合规范，都能直接开工。<br>
总结：YARN 的改进</p>
</blockquote>
</li>
</ol>
<ul>
<li><strong>单点故障</strong>：通过职责分离和高可用机制，让集群更稳定。</li>
<li><strong>通用性</strong>：通过资源与框架解耦，支持多种计算模型（批处理、流处理、机器学习等）。<br>
<strong>实际效果</strong>：</li>
<li>单点故障率大幅降低：RM 主备切换、AM 独立管理任务，局部故障不影响全局。</li>
<li>生态更丰富：Spark、Flink、Hive 等框架都可以在 YARN 上运行，共享集群资源。</li>
</ul>
<p>YARN 资源调度策略<br>
5. <strong>Capacity Scheduler</strong><br>
- 将集群划分为多个队列，每个队列有固定资源配额。<br>
- 适用于多租户场景，保证资源公平分配。<br>
6. <strong>Fair Scheduler</strong><br>
- 动态平衡资源分配，空闲资源可被其他作业借用。<br>
- 适合短作业优先的场景。</p>
<p>YARN 的优势<br>
5. <strong>解耦资源管理与计算框架</strong><br>
- 资源管理（RM）与任务调度（AM）分离，灵活性高。<br>
6. <strong>支持多计算范式</strong><br>
- 批处理（MapReduce）、流处理（Flink）、机器学习（Spark MLlib）等均可运行。<br>
7. <strong>高效利用资源</strong><br>
- 通过 Container 实现细粒度资源分配，避免资源浪费。<br>
<strong>YARN 与 Kubernetes 对比</strong></p>
<ul>
<li>YARN 专注大数据场景，与 Hadoop 生态深度集成。</li>
<li>Kubernetes 是通用容器编排平台，适合微服务架构。<br>
<strong>常见问题</strong></li>
<li><strong>资源竞争</strong>：可通过调整调度策略优化。</li>
<li><strong>作业失败</strong>：AM 会自动重试任务（可配置重试次数）。</li>
</ul>
<h2 id="YARN-的辅助角色">YARN 的辅助角色</h2>
<p><strong>核心角色：</strong></p>
<ol>
<li><strong>ResourceManager（RM）</strong>：
<ul>
<li><strong>功能</strong>：集群资源的总管家，负责全局资源的分配和调度。</li>
<li><strong>职责</strong>：
<ul>
<li>接收客户端提交的作业。</li>
<li>分配资源给 ApplicationMaster（AM）。</li>
<li>监控 NodeManager（NM）的状态。</li>
</ul>
</li>
</ul>
</li>
<li><strong>NodeManager（NM）</strong>：
<ul>
<li><strong>功能</strong>：单机资源管家，负责管理单个节点的资源。</li>
<li><strong>职责</strong>：
<ul>
<li>管理本节点的资源（CPU、内存等）。</li>
<li>启动和监控 Container（资源隔离单位）。</li>
<li>向 ResourceManager 汇报资源使用情况。<br>
<strong>辅助角色：</strong><br>
为了增强 YARN 集群的稳定性和安全性，YARN 提供了两个辅助角色：</li>
</ul>
</li>
</ul>
</li>
<li><strong>代理服务器（ProxyServer）</strong>
<ul>
<li><strong>功能</strong>：Web 应用程序代理，用于增强 YARN Web UI 的安全性。</li>
<li><strong>作用</strong>：
<ul>
<li>减少通过 YARN 进行基于网络的攻击的可能性。</li>
<li>提供额外的安全层，例如：
<ul>
<li>警告用户正在访问一个不受信任的站点。</li>
<li>剥离用户访问的 Cookie 等敏感信息。</li>
</ul>
</li>
</ul>
</li>
<li><strong>运行模式</strong>：
<ul>
<li>默认情况下，代理服务器作为 ResourceManager 的一部分运行。</li>
<li>可以配置为独立模式运行，以提高安全性。</li>
</ul>
</li>
<li><strong>配置与启动</strong>：
<ul>
<li>在 <code>yarn-site.xml</code> 中配置 <code>yarn.web-proxy.address</code> 参数。</li>
<li>启动命令：  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$</span><span class="language-bash">HADOOP_YARN_HOME/sbin/yarn-daemon.sh start proxyserver</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>历史服务器（JobHistoryServer）</strong>
<ul>
<li><strong>功能</strong>：记录历史运行的应用程序信息及其日志，并提供 Web UI 供用户查看。</li>
<li><strong>作用</strong>：
<ul>
<li>提供 Web UI 站点，方便用户在浏览器中查看程序日志。</li>
<li>保留历史数据，支持随时查看历史运行的程序信息。</li>
</ul>
</li>
<li><strong>必要性</strong>：
<ul>
<li>YARN 的运行机制决定了容器（Container）在任务完成后会被销毁，日志也会随之丢失。</li>
<li>历史服务器通过日志聚合功能，将日志从容器中抓取并集中存储到 HDFS，确保日志的持久化和可访问性。</li>
</ul>
</li>
<li><strong>配置与启动</strong>：
<ul>
<li>开启日志聚合功能，将日志集中存储到 HDFS。</li>
<li>配置历史服务器的端口和主机信息。</li>
<li>启动命令：  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$</span><span class="language-bash">HADOOP_YARN_HOME/sbin/mr-jobhistory-daemon.sh start historyserver</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>代理服务器的安全性</strong><br>
YARN 提供了一个 Web UI 站点（类似于 HDFS 的 Web UI），用户可以通过浏览器查看集群的运行信息。然而，对外提供 Web 站点会带来安全性问题。代理服务器的功能就是最大限度地保障对 Web UI 的访问是安全的。具体措施包括：<br>
5. <strong>警告用户</strong>：提示用户正在访问一个不受信任的站点。<br>
6. <strong>剥离敏感信息</strong>：例如剥离用户访问的 Cookie，防止信息泄露。<br>
7. <strong>提高安全性</strong>：虽然代理服务器不能提供绝对的安全保障，但可以辅助提高 YARN 在开放网络中的安全性。<br>
<strong>历史服务器的重要性</strong><br>
历史服务器的主要功能是记录和展示历史运行的应用程序信息及其日志。它的重要性体现在以下几个方面：<br>
8. <strong>日志持久化</strong>：<br>
- YARN 的容器在任务完成后会被销毁，日志也会丢失。<br>
- 历史服务器通过日志聚合功能，将日志集中存储到 HDFS，确保日志的持久化。<br>
9. <strong>便于排查问题</strong>：<br>
- 用户可以随时查看历史运行的程序信息及其日志，便于排查问题和分析性能。<br>
10. <strong>集中管理</strong>：<br>
- 历史服务器提供了一个集中的平台，方便用户管理和查看所有历史任务的日志。</p>
<h2 id="高可用">高可用</h2>
<ul>
<li><strong>1 个 Active RM</strong>：当前在岗的领导，负责资源分配。</li>
<li><strong>多个 Standby RM</strong>：待命的领导，随时准备顶替。<br>
<strong>ZooKeeper 的作用</strong>：</li>
<li><strong>选领导</strong>：通过投票机制，自动选举出新的 Active RM。【Active节点选择】</li>
<li><strong>记小本本</strong>：记录当前 Active RM 的状态（比如资源分配情况），新领导上任后能快速恢复工作。【回复Active RM的原有状态信息】<br>
<strong>切换方式</strong></li>
<li><strong>自动切换</strong>：Active RM 故障时，ZooKeeper 自动触发选举，秒级切换。</li>
<li><strong>手动切换</strong>：运维人员可以手动指定 Active RM（比如升级系统时）。</li>
</ul>
<p>通过配置多个ResourceManager，实现主备切换，保障服务的连续性。当主ResourceManager出现故障时，备用的ResourceManager能够自动接管其工作，继续进行资源管理和调度。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2023.png" alt="image 23"></p>
<h2 id="调度策略">调度策略</h2>
<ul>
<li><strong>资源分配策略</strong>：RM对集群资源进行管理和分配，包括容器的资源配额分配（可基于队列、用户、应用程序等配置）和调度算法（决定如何分配可用资源给等待的应用程序或作业）。</li>
<li><strong>调度器选择</strong>：
<ul>
<li><strong>Capacity Scheduler（容量调度器）</strong>：Apache默认调度器，将集群资源分成多个队列，不同开发组使用自己的资源队列实现资源隔离，默认有root根队列和default子队列。</li>
<li><strong>Fair Scheduler（公平调度器）</strong>：旨在为所有应用程序提供公平的资源分配，可配置每个应用程序的资源份额。</li>
<li><strong>Dominant Resource Fairness Scheduler</strong>：根据作业对不同资源（如CPU、内存）的需求进行公平调度。</li>
</ul>
</li>
<li><strong>优先级调度</strong>：支持设置作业或应用程序的优先级，高优先级作业可获得更多资源以尽快完成。</li>
<li><strong>预留资源</strong>：允许某些应用程序或作业在集群中保留一定比例资源，提高关键任务执行效率。</li>
<li><strong>队列管理</strong>：调度器支持队列概念，可根据不同队列配置资源配额和调度策略，实现资源隔离和公平共享。</li>
</ul>
<p>一、FIFO 调度器（先进先出）<br>
<strong>核心思想</strong>：像一个排队买奶茶的队伍，谁先来谁先被服务。</p>
<ul>
<li><strong>工作机制</strong>：
<ul>
<li>所有任务排成一个队列，先提交的任务先拿到资源，后提交的必须等前面的任务完成。</li>
<li>比如：任务1（需要1小时）和任务2（需要5分钟），任务2必须等任务1完成后才能运行。</li>
</ul>
</li>
<li><strong>缺点</strong>：
<ul>
<li><strong>资源浪费</strong>：大任务占用资源时，小任务只能干等。</li>
<li><strong>不灵活</strong>：紧急任务无法插队，用户体验差。</li>
</ul>
</li>
<li><strong>适用场景</strong>：仅适合测试环境或极简单的任务流。</li>
</ul>
<p>二、容量调度器（Capacity Scheduler）<br>
<strong>核心思想</strong>：像公司预算分配，每个部门有固定预算，但可以临时借用其他部门的空闲预算。</p>
<ul>
<li><strong>工作机制</strong>：
<ul>
<li>每个队列内部用 FIFO 策略，但空闲资源可以借给其他队列。</li>
</ul>
</li>
<li><strong>优点</strong>：
<ul>
<li><strong>资源隔离</strong>：保证每个队列至少有预设的资源（比如部门A永远有50%资源可用）。</li>
<li><strong>弹性分配</strong>：空闲资源灵活调配，提高利用率。</li>
</ul>
</li>
<li><strong>适用场景</strong>：适合多团队共享集群（如A团队做数据分析，B团队跑机器学习）。<br>
<strong>通俗比喻</strong>：</li>
</ul>
<blockquote>
<p>公司给市场部50万预算，技术部30万。如果市场部暂时不用钱，技术部可以借来用，但市场部需要时能随时收回。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2024.png" alt="image 24"><br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2025.png" alt="image 25"></p>
</blockquote>
<p>三、公平调度器（Fair Scheduler）<br>
<strong>核心思想</strong>：像分蛋糕，每人按需平分，不够时可以从别人那里“抢”一块。</p>
<ul>
<li><strong>工作机制</strong>：
<ul>
<li>所有队列动态平分资源，无需提前分配比例。</li>
<li>如果某个队列资源不足，可以“抢占”其他队列的资源。</li>
<li>比如：队列A和队列B各占50%，如果队列A的任务突然变多，可以从队列B拿资源。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2026.png" alt="image 26"></li>
</ul>
</li>
<li><strong>优点</strong>：
<ul>
<li><strong>公平性</strong>：小任务不会被大任务饿死。</li>
<li><strong>灵活性</strong>：资源按需动态调整。</li>
</ul>
</li>
<li><strong>适用场景</strong>：适合混合负载（如同时有实时计算和批处理）。<br>
<strong>通俗比喻</strong>：</li>
</ul>
<blockquote>
<p>共享办公桌，平时大家平分工位。如果某人今天活特别多，可以临时占用旁边空闲的工位。<br>
疑问：<br>
公平调度器修改权重是变成容量调度器了吗<br>
答案：公平调度器修改权重 ≠ 容量调度器<br>
<strong>核心区别</strong>：权重只是公平调度器中调节资源分配的一种手段，但不会改变其动态平衡的本质。两者的核心设计理念不同，具体对比如下👇</p>
</blockquote>
<ol>
<li><strong>公平调度器的权重是什么？</strong>
<ul>
<li><strong>作用</strong>：
<ul>
<li>当集群有<strong>空闲资源</strong>时，权重高的队列能分到更多资源。</li>
<li>权重仅影响空闲资源的分配，不强制保证队列的固定资源量。</li>
</ul>
</li>
<li><strong>举个栗子</strong>：
<blockquote>
<p>公司发年终奖，默认每人平分奖金（公平调度）。但老板说：“程序员贡献大，权重高，奖金池有剩余时，程序员多分点”。这并不改变“平时大家平分工位”的规则。</p>
</blockquote>
</li>
</ul>
</li>
<li><strong>容量调度器的核心特点</strong>
<ul>
<li><strong>固定预算</strong>：每个队列有预设的资源比例（如队列A占40%，队列B占60%）。</li>
<li><strong>资源隔离</strong>：即使队列A当前没有任务，其他队列也不能占用它的40%资源。</li>
<li><strong>举个栗子</strong>：
<blockquote>
<p>公司给市场部50%预算，技术部30%。市场部今天没事干，技术部最多只能借剩下的20%资源，但市场部的50%预算必须留着。</p>
</blockquote>
</li>
</ul>
</li>
</ol>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>特性</strong></td>
<td><strong>公平调度器（带权重）</strong></td>
<td><strong>容量调度器</strong></td>
</tr>
<tr>
<td><strong>资源分配基础</strong></td>
<td>动态按需分配</td>
<td>固定预设比例</td>
</tr>
<tr>
<td><strong>资源保证</strong></td>
<td>不保证队列的最低资源量</td>
<td>保证队列的最低资源量</td>
</tr>
<tr>
<td><strong>资源抢占</strong></td>
<td>支持抢占其他队列的资源</td>
<td>不支持抢占，只能借用空闲资源</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>混合负载、资源需求波动大</td>
<td>多团队需固定资源保障</td>
</tr>
<tr>
<td><strong>通俗总结</strong>：</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>公平调度器的权重是“加分项”，让某些队列在资源充足时多拿点，但资源不足时大家还是平摊。</li>
<li>容量调度器是“硬性规定”，每个队列有自己的“专属领地”，别人不能越界。</li>
<li><strong>公平调度器设置权重</strong>：  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 在 fair-scheduler.xml 中 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">queue</span> <span class="attr">name</span>=<span class="string">&quot;dev&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">weight</span>&gt;</span>2.0<span class="tag">&lt;/<span class="name">weight</span>&gt;</span>  <span class="comment">&lt;!-- 权重是其他队列的2倍 --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">queue</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><strong>容量调度器设置容量</strong>：  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 在 capacity-scheduler.xml 中 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.dev.capacity<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>40<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  <span class="comment">&lt;!-- 固定占40%资源 --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li>想强制保证队列资源量 → 用容量调度器。</li>
<li>想灵活动态分配 + 空闲时倾向某些队列 → 用公平调度器加权重。</li>
</ul>
<p>三种调度器对比</p>
<table>
<thead>
<tr>
<th><strong>调度器类型</strong></th>
<th><strong>优点</strong></th>
<th><strong>缺点</strong></th>
<th><strong>适用场景</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>FIFO</strong></td>
<td>简单易用</td>
<td>资源利用率低，不灵活</td>
<td>测试环境、单一任务流</td>
</tr>
<tr>
<td><strong>容量调度器</strong></td>
<td>资源隔离，弹性分配</td>
<td>配置复杂，需预设资源比例</td>
<td>多团队共享集群</td>
</tr>
<tr>
<td><strong>公平调度器</strong></td>
<td>动态平衡，避免资源饥饿</td>
<td>可能引发资源抢占冲突</td>
<td>混合负载（实时+批处理）</td>
</tr>
<tr>
<td>五、如何配置调度器？</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ol>
<li><strong>全局配置（yarn-site.xml）</strong>：
<ul>
<li>指定调度器类型，例如：  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><strong>容量调度器配置（capacity-scheduler.xml）</strong>：
<ul>
<li>定义队列资源比例、权限等，例如：  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.queues<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>dev,prod<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  <span class="comment">&lt;!-- 定义两个队列 --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.dev.capacity<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>40<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  <span class="comment">&lt;!-- dev队列占40%资源 --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ol>
<h2 id="运维和监控">运维和监控</h2>
<ul>
<li><strong>运维</strong>：包括对YARN相关配置参数的调整，如内存大小配置等；对集群资源的管理和维护，确保资源的合理分配和使用；处理应用程序运行过程中的异常情况等。</li>
<li><strong>监控</strong>：监控ResourceManager、NodeManager、ApplicationMaster等组件的运行状态，包括CPU、内存、磁盘等资源使用情况；监控作业的执行进度、资源占用情况等，以便及时发现和解决问题，保障集群的稳定运行。</li>
<li>常用运维命令<br>
<strong>1. 查看运行中的应用</strong>
<ul>
<li><strong>命令</strong>：<code>yarn application -list</code></li>
<li><strong>作用</strong>：列出当前集群中所有正在运行、已完成或失败的应用。</li>
<li><strong>使用场景</strong>：想快速知道有哪些任务在跑，比如检查自己的任务是否提交成功。<br>
<strong>2. 强制终止应用</strong></li>
<li><strong>命令</strong>：<code>yarn application -kill &lt;ApplicationId&gt;</code></li>
<li><strong>作用</strong>：直接终止指定应用，释放资源。</li>
<li><strong>注意</strong>：
<ul>
<li>用 <code>CTRL+C</code> 只能关闭控制台输出，任务仍在后台运行，必须用此命令才能真正终止。</li>
<li>示例：  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">先查应用ID</span></span><br><span class="line">yarn application -list</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">再终止</span></span><br><span class="line">yarn application -kill application_123456789_0001</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<strong>3. 查看应用状态</strong>
<ul>
<li><strong>命令</strong>：<code>yarn application -status &lt;ApplicationId&gt;</code></li>
<li><strong>作用</strong>：显示应用的详细信息，包括进度、资源使用情况等。</li>
<li><strong>使用场景</strong>：任务卡住时，检查它到底在做什么。</li>
</ul>
</li>
<li>监控集群状态（Web UI）<br>
通过浏览器访问 <code>http://集群IP:8088</code>（如 <code>http://172.16.140.204:8088</code>），进入 YARN 监控页面。<br>
<strong>1. 核心功能模块</strong>
<ul>
<li><strong>Applications</strong>：查看所有应用的状态（如 Running、Finished、Killed）。</li>
<li><strong>Nodes</strong>：监控各个工作节点（NodeManager）的健康状态和资源使用。</li>
<li><strong>Cluster Metrics</strong>：查看集群整体资源使用情况（CPU、内存、容器数量等）。<br>
<strong>2. 关键指标解释</strong></li>
<li><strong>Memory Used</strong>：已使用的内存量。</li>
<li><strong>Containers Running</strong>：当前运行的容器数量（一个容器对应一个任务）。</li>
<li><strong>Active Nodes</strong>：正常工作的节点数，如果数值下降，可能有节点故障。<br>
<strong>3. 节点详情表格解读</strong></li>
<li><strong>Node Address</strong>：节点地址，用于定位具体机器。</li>
<li><strong>Containers</strong>：该节点上正在运行的容器数量。</li>
<li><strong>Mem Used/Avail</strong>：内存使用量和剩余量，帮助判断是否资源不足。</li>
<li><strong>Health-report</strong>：节点健康状态，如果显示异常需联系运维检查。</li>
</ul>
</li>
</ul>
<h1>MapReduce</h1>
<ul>
<li><strong>起源</strong>：
<ul>
<li>2004年10月，Google 发表 MapReduce 论文，提出一种处理海量数据的编程模型。</li>
<li><strong>设计初衷</strong>：解决搜索引擎中大规模网页数据的并行计算问题（例如网页索引构建）。</li>
<li><strong>开源实现</strong>：Apache Hadoop 的 MapReduce 是其开源版本，成为 Hadoop 生态的核心组件。</li>
</ul>
</li>
</ul>
<p>MapReduce是“分散-&gt;汇总”模式的分布式计算框架，可供开发人员开发相关程序进行分布式数据计算。</p>
<ul>
<li>Map功能接口提供了“分散”的功能， 由服务器分布式对数据进行处理</li>
<li>Reduce功能接口提供了“汇总（聚合）”的功能，将分布式的处理结果汇总统计</li>
</ul>
<ol>
<li><strong>核心概念</strong>：
<ul>
<li><strong>面向批处理</strong>：适合处理离线、静态的大数据集（比如日志文件）。</li>
<li><strong>编程模型</strong>：任务分为两个阶段：
<ul>
<li><strong>Map 阶段</strong>：数据分片处理（例如统计每个单词出现的次数）。将输入数据分割成多个子任务，并将每个子任务映射为一个中间结果。Map 函数接收一个键值对作为输入，输出一个新的键值对。</li>
<li><strong>Reduce 阶段</strong>：汇总中间结果（例如合并所有分片的单词统计）。将 Map 阶段输出的中间结果按键进行聚合，输出最终的结果。<br>
MapReduce 程序通常由 Mapper 和 Reducer 类组成，分别对应计算的两个阶段。<br>
在 MapReduce 程序执行过程中，数据会首先从 HDFS 中读取到集群的各个节点上，Map 阶段并行处理这些数据，并将结果传递给 Reducer 进行进一步的聚合。最终，Reduce 阶段的输出会被写回 HDFS 中。</li>
</ul>
</li>
</ul>
</li>
<li><strong>核心思想</strong>：
<ul>
<li><strong>分而治之</strong>：将大数据拆分成小块，并行处理。</li>
<li><strong>移动计算而非数据</strong>：将计算逻辑发送到数据所在的节点，减少数据传输开销。<br>
<strong>通俗比喻</strong>：</li>
</ul>
</li>
</ol>
<blockquote>
<p>假设你要数一仓库的书籍，Map 是让每个工人数自己面前的箱子，Reduce 是把所有工人数的结果加起来。</p>
</blockquote>
<p>特点与优势</p>
<ol>
<li><strong>特点</strong>：
<ul>
<li><strong>计算跟着数据走</strong>：直接在数据存储节点（HDFS）上计算，减少网络传输。</li>
<li><strong>高扩展性</strong>：节点越多，计算能力越强（近似线性扩展）。</li>
<li><strong>高容错</strong>：任务失败后自动重新分配，无需人工干预。</li>
<li><strong>适合海量数据离线处理</strong>：如日志分析、数据清洗。</li>
</ul>
</li>
<li><strong>优势</strong>：
<ul>
<li><strong>降低分布式编程门槛</strong>：开发者只需关注 Map 和 Reduce 逻辑，无需处理分布式细节。</li>
<li><strong>状态监控</strong>：可通过日志和 Web UI 监控任务进度。<br>
<strong>典型场景</strong>：</li>
</ul>
</li>
</ol>
<blockquote>
<p>统计网站的每日 PV（页面访问量）和 UV（独立访客数）。</p>
</blockquote>
<table>
<thead>
<tr>
<th><strong>适用场景</strong></th>
<th><strong>不适用场景</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>海量数据离线批处理</strong></td>
<td><strong>实时计算（OLAP）</strong></td>
</tr>
<tr>
<td>例如：日志分析、数据清洗</td>
<td>要求秒级返回结果（如BI报表）</td>
</tr>
<tr>
<td><strong>简单数据统计与聚合</strong></td>
<td><strong>流计算</strong></td>
</tr>
<tr>
<td>例如：统计单词频率</td>
<td>输入数据是动态实时流，而MR是静态的（如传感器数据）</td>
</tr>
<tr>
<td><strong>可并行化的计算任务</strong></td>
<td><strong>复杂依赖任务（DAG）</strong></td>
</tr>
<tr>
<td>例如：排序、过滤</td>
<td>多个任务依赖形成有向无环图（如机器学习流水线）</td>
</tr>
<tr>
<td><strong>为什么不适合 DAG 计算？</strong></td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>有向无环图：多个作业存在依赖关系，后一个的输入是前一个的输出</li>
<li>MapReduce 每个阶段的结果必须写入磁盘，多阶段任务会导致大量磁盘 I/O，性能低下。</li>
<li>一般DAG运算针对Spark来说，因为Spark的数据都存储在内存中，所以不落盘就可以直接给到下一个任务进行计算</li>
</ul>
<h2 id="MapReduce词频统计原理">MapReduce词频统计原理</h2>
<p>以统计单词出现次数为例，假设输入数据为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Deer Bear River</span><br><span class="line">Deer Bear River</span><br><span class="line">Car Car River</span><br><span class="line">Deer Car Bear</span><br></pre></td></tr></table></figure>
<ol>
<li><strong>Input &amp; Split（输入与分块）</strong>
<ul>
<li><strong>输入</strong>：将文本文件按行分割成多个数据块（Split）。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Split 1: Deer Bear River</span><br><span class="line">Split 2: Deer Bear River</span><br><span class="line">Split 3: Car Car River</span><br><span class="line">Split 4: Deer Car Bear</span><br></pre></td></tr></table></figure>
</li>
<li><strong>通俗理解</strong>：把一本厚书拆成几章，分给不同人同时阅读。</li>
</ul>
</li>
<li><strong>Map（映射）</strong>
<ul>
<li><strong>任务</strong>：每个 Split 由独立的 Map 任务处理，将每行文本拆成单词，输出 <code>&lt;单词, 1&gt;</code>。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Map 处理 Split 1 → [ (Deer,1), (Bear,1), (River,1) ]</span><br><span class="line">Map 处理 Split 2 → [ (Deer,1), (Bear,1), (River,1) ]</span><br><span class="line">Map 处理 Split 3 → [ (Car,1), (Car,1), (River,1) ]</span><br><span class="line">Map 处理 Split 4 → [ (Deer,1), (Car,1), (Bear,1) ]</span><br></pre></td></tr></table></figure>
</li>
<li><strong>通俗理解</strong>：每个人读完自己那章后，把每个单词标记为“见过一次”。</li>
</ul>
</li>
<li><strong>Shuffle &amp; Sort（混洗与排序）</strong>
<ul>
<li><strong>Shuffle</strong>：将相同单词的键值对汇总到一起（通过哈希取模）。</li>
<li><strong>Sort</strong>：按单词字母顺序排序。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Bear → [1, 1, 1]</span><br><span class="line">Car  → [1, 1, 1]</span><br><span class="line">Deer → [1, 1, 1, 1]</span><br><span class="line">River→ [1, 1, 1]</span><br></pre></td></tr></table></figure>
</li>
<li><strong>通俗理解</strong>：把所有人标记的单词卡片按字母分类，叠成一摞。</li>
</ul>
</li>
<li><strong>Reduce（合并）</strong>
<ul>
<li><strong>任务</strong>：对每个单词的计数列表求和。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Bear → 1+1+1 = 3</span><br><span class="line">Car  → 1+1+1 = 3</span><br><span class="line">Deer → 1+1+1+1 = 4</span><br><span class="line">River→ 1+1+1 = 3</span><br></pre></td></tr></table></figure>
</li>
<li><strong>通俗理解</strong>：数每摞卡片有多少张，得到最终数量。</li>
</ul>
</li>
<li><strong>Output（输出）</strong></li>
</ol>
<ul>
<li>最终结果写入文件：  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Bear 3</span><br><span class="line">Car  3</span><br><span class="line">Deer 4</span><br><span class="line">River 3</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>流程总结</p>
<ol>
<li><strong>分块处理</strong>：大任务拆成小任务并行执行。</li>
<li><strong>标记计数</strong>：每个单词标记为 1。</li>
<li><strong>归类汇总</strong>：相同单词的标记合并。</li>
<li><strong>简单高效</strong>：MapReduce 通过“分而治之”轻松处理海量数据。</li>
</ol>
<h2 id="MapReduce运行原理">MapReduce运行原理</h2>
<ul>
<li>将要执行的需求，分解为多个Map Task和Reduce Task</li>
<li>将Map Task 和 Reduce Task分配到对应的服务器去执行</li>
</ul>
<ol>
<li><strong>Map 阶段</strong><br>
<strong>核心任务</strong>：处理输入数据，生成键值对（Key-Value Pairs）。<br>
<strong>具体流程</strong>：
<ol>
<li><strong>输入分块（Split）</strong>
<ul>
<li>输入文件被拆分成多个 <strong>Split</strong>（如每块 128MB），每个 Split 由一个 Map 任务处理。</li>
<li><em>示例</em>：一个文本文件被分为 4 个 Split，分别处理不同行。</li>
</ul>
</li>
<li><strong>执行 Map 函数</strong>
<ul>
<li>每个 Map 任务逐行读取 Split，按业务逻辑生成键值对。</li>
<li><em>WordCount 示例</em>：
<ul>
<li>输入行 <code>Deer Bear River</code> → 输出 <code>&lt;Deer,1&gt;</code>, <code>&lt;Bear,1&gt;</code>, <code>&lt;River,1&gt;</code>。</li>
</ul>
</li>
</ul>
</li>
<li><strong>分区（Partition）</strong>
<ul>
<li>将 Map 输出的键值对按 Key 的哈希值分配到不同 <strong>分区</strong>（Partition），确保相同 Key 进入同一 Reduce 任务。</li>
<li><em>示例</em>：<code>Deer</code> 和 <code>Bear</code> 可能分配到不同分区，由不同 Reduce 处理。</li>
</ul>
</li>
<li><strong>排序与溢写（Sort &amp; Spill）</strong>
<ul>
<li><strong>内存缓冲区</strong>：Map 输出的键值对先缓存在内存中，按 Key 排序。</li>
<li><strong>溢写到磁盘</strong>：当缓冲区满时，数据排序后写入本地磁盘，生成多个临时文件。</li>
</ul>
</li>
</ol>
</li>
<li><strong>Shuffle 阶段</strong><br>
<strong>核心任务</strong>：将 Map 阶段的输出高效、有序地传输给 Reduce 任务。<br>
<strong>详细流程</strong>：
<ol>
<li><strong>复制阶段（Copy Phase）</strong>
<ul>
<li>Reduce 任务从所有 Map 任务的磁盘中 <strong>拉取（Fetch）</strong> 属于自己分区的数据。</li>
<li><em>示例</em>：Reduce 任务 1 拉取所有 <code>Deer</code> 相关的键值对。</li>
</ul>
</li>
<li><strong>合并与排序（Merge &amp; Sort）</strong>
<ul>
<li>Reduce 将拉取的数据在内存中合并，若内存不足则溢写到磁盘。</li>
<li>最终对所有数据按 Key 全局排序，为 Reduce 阶段的聚合做准备。</li>
<li><em>示例</em>：合并后得到 <code>&lt;Deer, [1,1,1,1]&gt;</code>。</li>
</ul>
</li>
</ol>
</li>
<li><strong>Reduce 阶段</strong><br>
<strong>核心任务</strong>：聚合键值对，生成最终结果。<br>
<strong>具体流程</strong>：
<ol>
<li><strong>执行 Reduce 函数</strong>
<ul>
<li>对排序后的键值对按 Key 分组，执行业务逻辑（如求和）。</li>
<li><em>WordCount 示例</em>：<code>&lt;Deer, [1,1,1,1]&gt;</code> → 输出 <code>&lt;Deer,4&gt;</code>。</li>
</ul>
</li>
<li><strong>输出结果</strong>
<ul>
<li>结果写入 HDFS，默认存储路径为 <code>/output</code>。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2027.png" alt="image 27"><br>
<strong>为什么 Shuffle 重要？</strong></li>
</ul>
</li>
</ol>
</li>
</ol>
<ul>
<li><strong>性能瓶颈</strong>：Shuffle 涉及大量磁盘 I/O 和网络传输，是 MapReduce 最耗时的阶段。</li>
<li><strong>数据有序性</strong>：通过排序和分区，确保相同 Key 的数据集中处理，提高效率。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2028.png" alt="image 28"><br>
<strong>总结：MapReduce 的核心流程</strong></li>
</ul>
<ol>
<li><strong>分而治之</strong>：拆分任务并行处理（Map）。</li>
<li><strong>归并排序</strong>：Shuffle 确保数据有序聚合。</li>
<li><strong>汇总结果</strong>：Reduce 生成最终输出。</li>
</ol>
<h2 id="作业提交、监控与诊断">作业提交、监控与诊断</h2>
<p>一、作业提交</p>
<ol>
<li><strong>提交命令</strong>
<ul>
<li><strong>基本语法</strong>：  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar &lt;jar文件路径&gt; [主类名] &lt;输入路径&gt; &lt;输出路径&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><strong>示例</strong>（计算圆周率）：  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar pi 10 10</span><br></pre></td></tr></table></figure>
<ul>
<li><code>pi</code>：示例程序的主类名，用于估算圆周率。</li>
<li><code>10 10</code>：参数，表示使用10个Map任务，每个任务采样10次。</li>
</ul>
</li>
</ul>
</li>
<li><strong>命令输出解读</strong>
<ul>
<li><strong>关键日志信息</strong>：  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Number of Maps = 10        # 启用的Map任务数量</span><br><span class="line">Sample per Map = 10       # 每个Map任务的采样次数</span><br><span class="line">Submitted application_xxx # 作业的唯一ID</span><br><span class="line">Tracking URL: &lt;http://xxx&gt;  # 监控页面的链接</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><strong>终止作业</strong>
<ul>
<li><strong>命令</strong>：  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn application -kill &lt;application_id&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li>示例：<code>yarn application -kill application_123456789_0001</code></li>
</ul>
</li>
</ul>
</li>
</ol>
<p>二、作业监控</p>
<ol>
<li><strong>Web 监控页面</strong>
<ul>
<li><strong>访问地址</strong>：<code>http://&lt;ResourceManager_IP&gt;:8088</code></li>
<li><strong>核心功能</strong>：
<ul>
<li><strong>Applications</strong>：查看所有作业状态（如 <code>RUNNING</code>、<code>FINISHED</code>、<code>FAILED</code>）。</li>
<li><strong>Nodes</strong>：监控各节点的资源使用情况（内存、CPU、容器数量）。</li>
<li><strong>Logs</strong>：直接查看任务日志（需配置权限）。</li>
</ul>
</li>
</ul>
</li>
<li><strong>页面关键指标</strong>
<ul>
<li><strong>Memory Used</strong>：集群已用内存，若长期超过80%需扩容。</li>
<li><strong>Containers Running</strong>：当前运行的容器数，反映集群负载。</li>
<li><strong>Active Nodes</strong>：正常工作的节点数，若减少可能有节点故障。</li>
</ul>
</li>
<li><strong>示例场景</strong>
<ul>
<li><strong>任务卡在</strong> <code>**ACCEPTED**</code> <strong>状态</strong>：资源不足，检查其他任务是否占用过多资源。</li>
<li><strong>任务</strong> <code>**FAILED**</code>：点击作业ID查看日志，定位错误原因（如代码Bug或数据格式错误）。</li>
</ul>
</li>
</ol>
<p>三、日志诊断<br>
7. <strong>日志存储路径</strong><br>
- <strong>默认目录</strong>：<code>/mmt/disk*/hadoop/yarn/logs/</code>（路径由 <code>yarn.nodemanager.log-dirs</code> 配置）。<br>
- <strong>日志文件</strong>：<br>
- <code>stderr</code>：错误日志。<br>
- <code>stdout</code>：标准输出日志。<br>
- <code>syslog</code>：系统日志。<br>
8. <strong>查看日志示例</strong><br>
- <strong>命令</strong>：<br>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入日志目录</span></span><br><span class="line">cd /mmt/disk2/hadoop/yarn/logs/application_123456789_0001/container_123456789_0001_01_000002/</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看错误日志</span></span><br><span class="line">cat stderr</span><br></pre></td></tr></table></figure><br>
9. <strong>常见错误类型</strong><br>
- <strong>数据读取失败</strong>：输入路径不存在或权限不足。<br>
- <strong>内存不足</strong>：调整 <code>mapreduce.map.memory.mb</code> 和 <code>mapreduce.reduce.memory.mb</code> 参数。<br>
- <strong>代码异常</strong>：检查Map/Reduce函数逻辑（如空指针或类型转换错误）。</p>
<p>通俗总结：</p>
<ul>
<li><strong>作业提交</strong>：就像点外卖，你下单（提交作业），厨房（集群）开始做菜（处理数据）。</li>
<li><strong>Shuffle阶段</strong>：类似快递分拣，把不同包裹（数据）按地址（Key）分类，送到对应配送站（Reduce任务）。</li>
<li><strong>日志诊断</strong>：如果外卖送错了，查看订单记录（日志）找问题，是地址写错还是厨师漏放了食材。</li>
</ul>
<h1>Spark</h1>
<h2 id="一、为什么需要-Spark？">一、为什么需要 Spark？</h2>
<p><strong>MapReduce 的局限性</strong>：</p>
<ol>
<li><strong>功能单一</strong>：仅支持 Map 和 Reduce 两种操作，复杂任务需串联多个作业，效率低。</li>
<li><strong>速度慢</strong>：每个阶段结果写磁盘，频繁 I/O 拖慢速度（如处理 1TB 数据需 10 分钟）。</li>
<li><strong>场景有限</strong>：只适合离线批处理，不支持迭代计算（如机器学习）、实时流处理（如秒级统计）等。<br>
<strong>Spark 的定位</strong>：</li>
</ol>
<ul>
<li><strong>统一计算框架</strong>：一个框架支持批处理、流处理、机器学习、图计算等多种场景。</li>
<li><strong>高效替代 MapReduce</strong>：通过内存计算和优化算法，速度提升 10~100 倍。</li>
</ul>
<h2 id="二、Spark-核心组件">二、Spark 核心组件</h2>
<table>
<thead>
<tr>
<th><strong>组件</strong></th>
<th><strong>功能</strong></th>
<th><strong>类比</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Spark Core</strong></td>
<td>底层计算引擎，提供任务调度、内存管理、容错等基础功能。</td>
<td>汽车的发动机和底盘，驱动所有功能。</td>
</tr>
<tr>
<td><strong>Spark SQL</strong></td>
<td>处理结构化数据，支持 SQL 查询和 DataFrame API。</td>
<td>Excel 表格，支持筛选、统计、连接。</td>
</tr>
<tr>
<td><strong>Spark Streaming</strong></td>
<td>实时处理数据流（如日志、传感器数据）。</td>
<td>流水线传送带，数据源源不断实时处理。</td>
</tr>
<tr>
<td><strong>MLlib</strong></td>
<td>机器学习库，提供分类、回归、聚类等算法。</td>
<td>智能工具箱，内置各种AI模型。</td>
</tr>
<tr>
<td><strong>GraphX</strong></td>
<td>图计算库，用于社交网络分析、路径规划等场景。</td>
<td>人际关系图，分析谁和谁关系紧密。</td>
</tr>
</tbody>
</table>
<h2 id="三、Spark-的四大优势">三、Spark 的四大优势</h2>
<ol>
<li><strong>内存计算</strong>
<ul>
<li>数据尽量保留在<mark>内存</mark>中，减少磁盘 I/O（MapReduce 每次都要读写磁盘）。</li>
<li><em>示例</em>：处理相同数据，Spark 耗时 1 分钟，MapReduce 耗时 10 分钟。</li>
</ul>
</li>
<li><strong>DAG 执行引擎</strong>
<ul>
<li>将任务拆分成<mark>有向无环图（DAG）</mark>，优化执行顺序，减少冗余计算。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2029.png" alt="image 29"></li>
<li><em>通俗解释</em>：
<blockquote>
<p>做饭时，先洗菜→切菜→炒菜（顺序优化），而不是洗菜→等锅热→切菜→炒菜（低效流程）。</p>
</blockquote>
</li>
</ul>
</li>
<li><strong>通用性</strong>
<ul>
<li>同一份代码可处理批数据、流数据，甚至混合场景（如 Lambda 架构）。</li>
<li><em>示例</em>：用 Spark Streaming 处理实时日志，同时用 Spark SQL 分析历史数据。</li>
</ul>
</li>
<li><strong>多语言支持</strong>
<ul>
<li>支持 Scala、Java、Python、R，开发者可用熟悉的语言编写代码。</li>
</ul>
</li>
</ol>
<h2 id="四、Spark-运行模式">四、Spark 运行模式</h2>
<ol>
<li><strong>本地模式（Local Mode）</strong>：单机调试用，适合学习和测试。</li>
<li><strong>Standalone 模式</strong>：Spark 自带的集群管理模式，无需依赖其他框架。</li>
<li><strong>YARN 模式</strong>：运行在 Hadoop YARN 上，复用 HDFS 数据（企业常用）。</li>
<li><strong>Mesos 模式</strong>：通用集群管理，适合混合负载场景。<br>
<strong>选择建议</strong>：</li>
</ol>
<ul>
<li>企业生产环境优先选 <strong>YARN 模式</strong>（与 Hadoop 生态集成）。</li>
<li>小规模测试可用 <strong>本地模式</strong> 或 <strong>Standalone 模式</strong>。</li>
</ul>
<h2 id="五、Spark-vs-MapReduce-场景对比">五、Spark vs MapReduce 场景对比</h2>
<table>
<thead>
<tr>
<th><strong>场景</strong></th>
<th><strong>MapReduce</strong></th>
<th><strong>Spark</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>离线批处理</strong></td>
<td>支持，但速度慢</td>
<td>支持，速度更快</td>
</tr>
<tr>
<td><strong>实时流处理</strong></td>
<td>不支持</td>
<td>支持（微批处理）</td>
</tr>
<tr>
<td><strong>迭代计算</strong></td>
<td>不支持（需多次读写）</td>
<td>支持（内存缓存中间结果）</td>
</tr>
<tr>
<td><strong>交互式查询</strong></td>
<td>不支持</td>
<td>支持（Spark SQL）</td>
</tr>
</tbody>
</table>
<h2 id="SparkRDD与编程框架">SparkRDD与编程框架</h2>
<p>一、RDD 是什么？<br>
<strong>定义</strong>：弹性分布式数据集（Resilient Distributed Dataset），是 Spark 中最基本的数据抽象。<br>
<strong>核心特性</strong>：</p>
<ol>
<li><strong>分布式存储</strong>：数据分散在集群多个节点上（如 Node01、Node02）。</li>
<li><strong>只读性</strong>：RDD 不可修改，只能通过转换生成新 RDD。可以避免并发冲突</li>
<li><strong>弹性（容错）</strong>：数据丢失时，可根据血缘关系（Lineage）自动重新计算恢复，无需恢复整个数据集</li>
<li><strong>分区（Partition）</strong>：数据被划分为多个分区（如 Partition1、Partition2），并行处理。<br>
<strong>通俗比喻</strong>：</li>
</ol>
<blockquote>
<p>RDD 像一箱乐高积木，箱子分散在多个仓库（节点），每个仓库有部分积木（分区）。如果某个仓库失火（节点故障），可以根据图纸（血缘关系）用其他仓库的积木重新拼装。</p>
</blockquote>
<h2 id="二、RDD-操作类型">二、RDD 操作类型</h2>
<table>
<thead>
<tr>
<th><strong>操作类型</strong></th>
<th><strong>特点</strong></th>
<th><strong>示例</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Transformation（转换）</strong></td>
<td>定义计算逻辑，生成<mark>新</mark> RDD（惰性执行，不立即计算）。</td>
<td><code>map</code>、<code>filter</code>、<code>flatMap</code>、<code>reduceByKey</code></td>
</tr>
<tr>
<td><strong>Action（动作）</strong></td>
<td>触发实际计算，返回结果或保存数据。</td>
<td><code>count</code>、<code>collect</code>、<code>saveAsTextFile</code></td>
</tr>
<tr>
<td><strong>执行逻辑</strong>：</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Transformation</strong> 只记录操作链（如 <code>textFile → flatMap → map → reduceByKey</code>），不执行计算。</li>
<li><strong>Action</strong>（如 <code>saveAsTextFile</code>）触发整个链条的实际计算。</li>
</ul>
<h2 id="三、RDD-依赖关系">三、RDD 依赖关系</h2>
<ol>
<li><strong>窄依赖（Narrow Dependency）</strong>
<ul>
<li><strong>特点</strong>：父 RDD 的每个分区最多被子 RDD 的一个分区依赖。</li>
<li><strong>容错恢复</strong>：子分区数据丢失时，只需重新计算对应的父分区。</li>
<li><strong>示例操作</strong>：<code>map</code>、<code>filter</code>、<code>union</code>。<br>
<strong>通俗理解</strong>：</li>
</ul>
<blockquote>
<p>窄依赖像一对一接力赛，每个队员（子分区）只依赖前一棒的一个队员（父分区）。</p>
</blockquote>
</li>
<li><strong>宽依赖（Shuffle/Wide Dependency）</strong>
<ul>
<li><strong>特点</strong>：父 RDD 的每个分区可能被子 RDD 的多个分区依赖（需跨节点混洗数据）。</li>
<li><strong>容错恢复</strong>：子分区数据丢失时，需重新计算所有父分区。</li>
<li><strong>示例操作</strong>：<code>reduceByKey</code>、<code>groupByKey</code>、<code>join</code>（未分区时）。<br>
<strong>通俗理解</strong>：</li>
</ul>
<blockquote>
<p>宽依赖像多人合作拼图，每个子分区需要多个父分区的碎片，一旦丢失需重新收集所有碎片。</p>
</blockquote>
</li>
</ol>
<h2 id="四、RDD-持久化">四、RDD 持久化</h2>
<p><strong>为什么需要持久化</strong>：</p>
<ul>
<li>避免重复计算（如多次使用同一 RDD 时）。</li>
<li>缓存策略：可存储在内存或磁盘。<br>
<strong>示例</strong>：</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd = sc.textFile(<span class="string">&quot;hdfs://data/logs&quot;</span>)</span><br><span class="line">rdd.cache()  <span class="comment">// 缓存到内存</span></span><br><span class="line">rdd.count()  <span class="comment">// 触发计算并缓存</span></span><br><span class="line">rdd.filter(...).saveAsTextFile(...)  <span class="comment">// 直接使用缓存数据</span></span><br></pre></td></tr></table></figure>
<p><strong>存储级别</strong>：</p>
<ul>
<li><code>MEMORY_ONLY</code>：只存内存（默认）。</li>
<li><code>MEMORY_AND_DISK</code>：内存不足时溢写到磁盘。</li>
</ul>
<h2 id="五、RDD-的优缺点">五、RDD 的优缺点</h2>
<table>
<thead>
<tr>
<th><strong>优点</strong></th>
<th><strong>缺点</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>内存计算，速度快</td>
<td>不支持实时流处理（需用 Spark Streaming）</td>
</tr>
<tr>
<td>容错性强，自动恢复数据</td>
<td>API 较底层，需手动优化</td>
</tr>
<tr>
<td>支持复杂数据处理逻辑</td>
<td>不适合频繁更新的场景</td>
</tr>
<tr>
<td>总结</td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li><strong>RDD 是 Spark 的基石</strong>：理解其分区、依赖和操作是掌握 Spark 的关键。</li>
<li><strong>Transformation vs Action</strong>：前者定义逻辑，后者触发计算。</li>
<li><strong>依赖关系决定性能</strong>：尽量避免宽依赖（Shuffle），优化计算效率。</li>
</ul>
<h2 id="MR-VS-RDD">MR VS RDD</h2>
<table>
<thead>
<tr>
<th><strong>特性</strong></th>
<th><strong>MapReduce</strong></th>
<th><strong>RDD</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>数据抽象</strong></td>
<td>基于键值对（Key-Value）</td>
<td>基于分区数据集（Partitioned Dataset）</td>
</tr>
<tr>
<td><strong>计算模型</strong></td>
<td>两阶段模型（Map → Reduce）</td>
<td>多阶段模型（支持任意转换操作）</td>
</tr>
<tr>
<td><strong>数据存储</strong></td>
<td>每个阶段结果写磁盘</td>
<td>尽量将数据保留在内存中</td>
</tr>
<tr>
<td><strong>执行方式</strong></td>
<td>每个阶段写磁盘，适合离线批处理</td>
<td>尽量内存计算，适合迭代和交互式任务</td>
</tr>
<tr>
<td><strong>容错机制</strong></td>
<td>依赖数据副本（HDFS 多副本机制）</td>
<td>依赖血缘关系（Lineage）重计算</td>
</tr>
<tr>
<td><strong>灵活性</strong></td>
<td>仅支持 Map 和 Reduce 两种操作</td>
<td>支持任意转换操作（如 <code>filter</code>、<code>join</code>）</td>
</tr>
<tr>
<td><strong>性能</strong></td>
<td>较慢（频繁磁盘 I/O）</td>
<td>较快（内存计算）</td>
</tr>
<tr>
<td><strong>MapReduce 流程</strong>：</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ol>
<li><strong>Map 阶段</strong>：
<ul>
<li>输入数据分片（Split）→ Map 任务处理 → 输出键值对。</li>
</ul>
</li>
<li><strong>Shuffle 阶段</strong>：
<ul>
<li>按 Key 排序并分发到 Reduce 任务。</li>
</ul>
</li>
<li><strong>Reduce 阶段</strong>：
<ul>
<li>聚合键值对，生成最终结果。<br>
<strong>RDD 流程</strong>：</li>
</ul>
</li>
<li><strong>数据加载</strong>：
<ul>
<li>从 HDFS 或其他数据源加载数据，生成初始 RDD。</li>
</ul>
</li>
<li><strong>转换操作（Transformation）</strong>：
<ul>
<li>通过 <code>map</code>、<code>filter</code>、<code>reduceByKey</code> 等操作生成新 RDD。</li>
</ul>
</li>
<li><strong>触发计算（Action）</strong>：
<ul>
<li>调用 <code>collect</code>、<code>count</code>、<code>saveAsTextFile</code> 等操作时，Spark 根据血缘关系执行计算。</li>
</ul>
</li>
</ol>
<ul>
<li><strong>RDD 的 WordCount</strong>：  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val rdd = sc.textFile(&quot;data.txt&quot;)</span><br><span class="line">val words = rdd.flatMap(_.split(&quot; &quot;))</span><br><span class="line">val counts = words.map((_, 1)).reduceByKey(_ + _)</span><br><span class="line">counts.saveAsTextFile(&quot;output&quot;)</span><br></pre></td></tr></table></figure>
</li>
<li><strong>MapReduce 的 WordCount</strong>：  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Map: (Deer,1), (Bear,1), (River,1)</span><br><span class="line">Shuffle: 按 Key 排序</span><br><span class="line">Reduce: (Deer,3), (Bear,2), (River,2)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="Spark程序运行架构">Spark程序运行架构</h2>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2030.png" alt="image 30"><br>
Spark 采用 <strong>Master/Slave 架构</strong>，核心组件包括：</p>
<ol>
<li><strong>Driver（驱动器）</strong>
<ul>
<li><strong>作用</strong>：运行用户编写的 <code>main</code> 函数，负责作业的解析、调度和监控。</li>
<li><strong>任务</strong>：
<ul>
<li>将用户代码转换为 DAG（有向无环图）。</li>
<li>将 DAG 拆分为多个 Stage（阶段），并生成 Task（任务）。</li>
<li>与 Cluster Manager 通信，申请资源并分发 Task。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Cluster Manager（集群管理器）【主】</strong>
<ul>
<li><strong>作用</strong>：管理集群资源，分配 Executor。</li>
<li><strong>常见类型</strong>：
<ul>
<li><strong>Standalone</strong>：Spark 自带的集群管理器。</li>
<li><strong>YARN</strong>：Hadoop 的资源管理器（企业常用）。</li>
<li><strong>Mesos</strong>：通用的集群管理器。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Executor（执行器）</strong>
<ul>
<li><strong>作用</strong>：在 Worker 节点上运行 Task，缓存数据并返回结果。</li>
<li><strong>特点</strong>：
<ul>
<li>每个 Executor 是一个 JVM 进程，可运行多个 Task。</li>
<li>任务完成后，Executor 不会立即退出，可复用。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Worker Node（工作节点）【从】</strong>
<ul>
<li><strong>作用</strong>：运行 Executor，执行具体计算任务。<br>
<strong>通俗比喻</strong>：</li>
</ul>
</li>
</ol>
<blockquote>
<p>Driver 像项目经理，负责规划任务（DAG）和分配资源。Cluster Manager 像人力资源部，负责招聘和管理员工（Executor）。Executor 像一线员工，负责具体工作（Task）。</p>
</blockquote>
<h2 id="Spark作业提交模式">Spark作业提交模式</h2>
<ol>
<li><strong>Local 模式</strong>
<ul>
<li><strong>核心特点</strong>：
<ul>
<li>适合快速验证代码逻辑或小规模数据处理。
<ul>
<li>单机运行，所有任务在<mark>本地线程</mark>中执行，无需启动分布式集群。</li>
</ul>
</li>
</ul>
</li>
<li><strong>局限性</strong>：
<ul>
<li>无法利用分布式计算资源，性能受限于单机硬件。</li>
<li>无容错机制，任务失败需手动重启。<br>
<strong>示例命令</strong>：</li>
</ul>
</li>
</ul>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --master local[4] --class MainClass app.jar</span><br></pre></td></tr></table></figure>
<code>local[4]</code>：使用 4 个线程模拟分布式环境。</li>
<li><strong>Standalone 模式</strong>
<ul>
<li><strong>核心特点</strong>：
<ul>
<li>Spark 自带的轻量级集群模式，无需依赖 Hadoop 或 Mesos。</li>
<li><strong>Master</strong>：管理集群资源，分配任务给 Worker。</li>
<li><strong>Worker</strong>：运行 Executor，执行具体 Task。</li>
<li>支持通过 ZooKeeper 实现 Master 高可用（HA）。</li>
</ul>
</li>
<li><strong>适用场景</strong>：
<ul>
<li>中小规模集群（如 10~100 节点）。</li>
<li>无需与 Hadoop 集成的场景。<br>
<strong>部署步骤</strong>：</li>
</ul>
</li>
</ul>
<ol>
<li>配置 Master 和 Worker 节点的 <code>spark-env.sh</code> 和 <code>slaves</code> 文件。</li>
<li>启动集群：<code>sbin/start-master.sh</code> 和 <code>sbin/start-workers.sh</code>。<br>
<strong>示例命令</strong>：</li>
</ol>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --master spark://master:7077 --class MainClass app.jar</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><strong>3. YARN 模式</strong></p>
<ul>
<li><strong>核心特点</strong>：
<ul>
<li>依赖 Hadoop YARN 进行资源调度，适合与 HDFS 集成的大规模生产环境。</li>
<li><strong>YARN-Client 模式</strong>：
<ul>
<li>Driver 运行在客户端，适合<mark>调试和交互</mark>式任务（如 Spark Shell）。</li>
<li>客户端需保持运行，否则作业中断。</li>
</ul>
</li>
<li><strong>YARN-Cluster 模式</strong>：
<ul>
<li>Driver 运行在 YARN 的 ApplicationMaster 中，客户端提交后即可断开。</li>
<li>适合<mark>生产</mark>环境长时间运行的作业。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2031.png" alt="image 31"></li>
</ul>
</li>
</ul>
</li>
<li><strong>优势</strong>：
<ul>
<li>支持动态资源分配（根据负载调整 Executor 数量）。</li>
<li>与 Hadoop 生态无缝集成（如 HDFS、Hive）。<br>
<strong>示例命令</strong>：</li>
</ul>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">YARN-Client 模式</span></span><br><span class="line">spark-submit --master yarn --deploy-mode client --class MainClass app.jar</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">YARN-Cluster 模式</span></span><br><span class="line">spark-submit --master yarn --deploy-mode cluster --class MainClass app.jar</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th><strong>对比项</strong></th>
<th><strong>Local 模式</strong></th>
<th><strong>Standalone 模式</strong></th>
<th><strong>YARN 模式</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>资源管理</strong></td>
<td>无独立资源管理器，单机多线程运行</td>
<td>Spark 自带的 Master/Worker 资源管理</td>
<td>依赖 Hadoop YARN 资源管理</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>本地测试、小规模数据验证</td>
<td>中小规模集群，无 Hadoop 依赖</td>
<td>大规模生产环境，需集成 Hadoop 生态</td>
</tr>
<tr>
<td><strong>高可用性</strong></td>
<td>不支持</td>
<td>通过 ZooKeeper 实现 Master HA</td>
<td>YARN 原生支持 ResourceManager HA</td>
</tr>
<tr>
<td><strong>Driver 位置</strong></td>
<td>本地进程</td>
<td>默认在客户端，可配置在集群中（Cluster 模式）</td>
<td>- <strong>Client 模式</strong>：Driver 在提交作业的客户端  <br>- <strong>Cluster 模式</strong>：Driver 在 YARN ApplicationMaster</td>
</tr>
<tr>
<td><strong>部署复杂度</strong></td>
<td>无需部署，直接运行</td>
<td>需手动部署 Master 和 Worker 节点</td>
<td>依赖 Hadoop YARN 环境，部署较复杂</td>
</tr>
<tr>
<td><strong>容错性</strong></td>
<td>无容错机制</td>
<td>依赖集群重启和任务重试</td>
<td>基于 YARN 的 Container 重试机制</td>
</tr>
<tr>
<td><strong>性能</strong></td>
<td>低（单机资源限制）</td>
<td>中（适合中小规模并行）</td>
<td>高（支持大规模分布式计算）</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Local 模式</strong>：开发者的“试验田”，快速验证代码，无需复杂部署。</li>
<li><strong>Standalone 模式</strong>：中小型公司的“自建工厂”，独立灵活但规模有限。</li>
<li><strong>YARN 模式</strong>：大型企业的“工业流水线”，依托 Hadoop 生态处理海量数据。</li>
</ul>
<h2 id="Spark-作业解析与监控">Spark 作业解析与监控</h2>
<p>Spark 作业执行流程：<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2032.png" alt="image 32"></p>
<ol>
<li><strong>生成逻辑查询计划</strong>
<ol>
<li><strong>读取数据</strong>：
<ul>
<li>使用 <code>sc.textFile(inputArg)</code> 从 HDFS 读取数据，生成初始 RDD。</li>
</ul>
</li>
<li><strong>转换操作</strong>：
<ul>
<li><code>flatMap(_.split(&quot;\\t&quot;))</code>：将每行数据按制表符拆分。</li>
<li><code>map((_, 1))</code>：将每个单词映射为键值对 <code>&lt;单词, 1&gt;</code>。</li>
<li><code>reduceByKey(_ + _)</code>：按单词聚合计数。</li>
</ul>
</li>
<li><strong>保存结果</strong>：
<ul>
<li><code>saveAsTextFile(outArg)</code>：将结果保存到 HDFS。<br>
<strong>逻辑计划示例</strong>：</li>
</ul>
</li>
</ol>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HDFS → textFile → flatMap → map → reduceByKey → saveAsTextFile → HDFS</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2033.png" alt="image 33">
<ul>
<li><strong>特点</strong>：
<ul>
<li>仅定义操作顺序（如 <code>textFile → flatMap → map → reduceByKey</code>）。</li>
<li>不关心数据如何分区、任务如何调度。</li>
</ul>
</li>
</ul>
</li>
<li><strong>生成物理查询计划</strong>
<ol>
<li><strong>划分 Stage</strong>：
<ul>
<li>根据宽依赖（Shuffle）将逻辑计划划分为多个 Stage。</li>
<li>示例：<code>reduceByKey</code> 是宽依赖，因此划分为两个 Stage：
<ul>
<li><strong>Stage 1</strong>：<code>textFile → flatMap → map</code></li>
<li><strong>Stage 2</strong>：<code>reduceByKey → saveAsTextFile</code><br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2034.png" alt="image 34"></li>
</ul>
</li>
</ul>
</li>
<li><strong>生成 Task</strong>：
<ul>
<li>每个 Stage 包含多个 Task，Task 是执行的最小单元。</li>
<li>示例：Stage 1 有 4 个分区，生成 4 个 Task。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2035.png" alt="image 35"><br>
<strong>通俗理解</strong>：</li>
</ul>
</li>
</ol>
<blockquote>
<p>物理计划像“厨房分工”，将菜谱分解为具体任务（如切菜、炒菜），分配给不同厨师（Executor）<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2036.png" alt="image 36"><br>
Spark划分Stage是基于宽依赖（Shuffle Dependency）的。也就是说，每当遇到一个宽依赖，就会将之前的操作划分为一个Stage，之后的操作属于新的Stage。宽依赖通常发生在需要Shuffle操作的时候，比如reduceByKey、groupByKey、join等操作。而窄依赖（Narrow Dependency）则不会引起Stage的划分，比如map、filter等操作。<br>
stage1：A<br>
stage2：CDE<br>
stage3：BF<br>
stage越多，shuffle越多，性能越差</p>
</blockquote>
</li>
<li><strong>任务调度与执行</strong>
<ol>
<li><strong>Driver 调度</strong>：
<ul>
<li>Driver 将 Task 分配给 Executor，并监控任务状态。</li>
</ul>
</li>
<li><strong>Executor 执行</strong>：
<ul>
<li>Executor 在 Worker 节点上运行 Task，并将结果返回给 Driver。</li>
</ul>
</li>
<li><strong>Shuffle 阶段</strong>：
<ul>
<li>在 Stage 之间传输数据（如 <code>reduceByKey</code> 需将相同 Key 的数据分发到同一 Task）。<br>
<strong>执行流程示例</strong>：</li>
</ul>
</li>
</ol>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Driver:</span><br><span class="line">- 调度 Stage 1 的 Task 1、Task 2、Task 3</span><br><span class="line">- 调度 Stage 2 的 Task 4、Task 5</span><br><span class="line">Executor:</span><br><span class="line">- 执行 Task 1：读取分区 1 数据 → flatMap → map</span><br><span class="line">- 执行 Task 4：聚合分区 1 的结果 → 保存到 HDFS</span><br></pre></td></tr></table></figure>
<strong>通俗理解</strong>：
<blockquote>
<p>Driver 像“项目经理”，分配任务并监督进度；Executor 像“一线员工”，负责具体工作。</p>
</blockquote>
</li>
<li><strong>Web 监控</strong><br>
<strong>访问地址</strong>：<code>http://&lt;Driver_IP&gt;:4040</code><br>
<strong>核心功能</strong>：
<ol>
<li><strong>Jobs</strong>：查看所有作业的状态（如 Running、Completed）。</li>
<li><strong>Stages</strong>：查看每个 Stage 的进度和 Task 分布。</li>
<li><strong>Storage</strong>：查看 RDD 的缓存情况。</li>
<li><strong>Executors</strong>：查看 Executor 的资源使用情况。<br>
<strong>示例场景</strong>：</li>
</ol>
<ul>
<li><strong>任务卡住</strong>：检查 Stages 页面，查看哪个 Task 耗时过长。</li>
<li><strong>任务失败</strong>：查看 Executor 日志，排查错误原因（如数据倾斜或资源不足）。</li>
</ul>
</li>
</ol>
<p>总结</p>
<ol>
<li><strong>逻辑计划</strong>：定义数据处理流程（如 <code>textFile → flatMap → map → reduceByKey</code>）。</li>
<li><strong>物理计划</strong>：将逻辑计划划分为 Stage 和 Task，优化执行顺序。</li>
<li><strong>任务调度</strong>：Driver 分配 Task 给 Executor，Executor 执行具体计算。</li>
<li><strong>Web 监控</strong>：通过 Web UI 实时掌握作业状态，快速定位问题。<br>
<strong>1. 作业解析</strong></li>
</ol>
<ul>
<li><strong>DAG 生成</strong>：
<ul>
<li>Driver 将用户代码转换为 DAG，表示任务的依赖关系。</li>
<li>示例：<code>textFile → flatMap → map → reduceByKey → saveAsTextFile</code>。</li>
</ul>
</li>
<li><strong>Stage 划分</strong>：
<ul>
<li>根据宽依赖（Shuffle）将 DAG 划分为多个 Stage。</li>
<li>每个 Stage 包含多个 Task，Task 是执行的最小单元。<br>
<strong>2. 作业监控</strong></li>
</ul>
</li>
<li><strong>Web UI</strong>：
<ul>
<li>访问地址：<code>http://&lt;Driver_IP&gt;:4040</code>（默认端口）。</li>
<li>核心功能：
<ul>
<li><strong>Jobs</strong>：查看所有作业的状态（如 Running、Completed）。</li>
<li><strong>Stages</strong>：查看每个 Stage 的进度和 Task 分布。</li>
<li><strong>Storage</strong>：查看 RDD 的缓存情况。</li>
<li><strong>Executors</strong>：查看 Executor 的资源使用情况。</li>
</ul>
</li>
</ul>
</li>
<li><strong>日志查看</strong>：
<ul>
<li><strong>Driver 日志</strong>：在提交作业的终端查看。</li>
<li><strong>Executor 日志</strong>：通过 Web UI 或集群管理工具（如 YARN）查看。<br>
<strong>3. 示例场景</strong></li>
</ul>
</li>
<li><strong>任务卡住</strong>：
<ul>
<li>检查 Web UI 的 Stages 页面，查看哪个 Task 耗时过长。</li>
<li>查看 Executor 日志，排查是否有数据倾斜或资源不足。</li>
</ul>
</li>
<li><strong>任务失败</strong>：
<ul>
<li>查看 Driver 日志，定位错误原因（如代码 Bug 或数据格式问题）。<br>
总结</li>
</ul>
</li>
<li><strong>运行架构</strong>：Driver 负责调度，Executor 负责执行，Cluster Manager 负责资源管理。</li>
<li><strong>提交模式</strong>：根据集群环境选择本地、Standalone、YARN 或 Mesos 模式。</li>
<li><strong>作业监控</strong>：通过 Web UI 和日志实时掌握作业状态，快速定位问题。</li>
</ul>
<h2 id="YARN-VS-Spark">YARN VS Spark</h2>
<table>
<thead>
<tr>
<th><strong>功能描述</strong></th>
<th><strong>YARN 组件</strong></th>
<th><strong>Spark 组件</strong></th>
<th><strong>区别与说明</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>作业调度与资源管理</strong></td>
<td>ResourceManager (RM)</td>
<td>Cluster Manager</td>
<td>- YARN 的 RM 负责全局资源管理。  <br>- Spark 的 Cluster Manager 可以是 YARN、Standalone 或 Mesos。</td>
</tr>
<tr>
<td><strong>任务执行与资源分配</strong></td>
<td>NodeManager (NM)</td>
<td>Executor</td>
<td>- YARN 的 NM 管理节点资源并启动 Container。  <br>- Spark 的 Executor 是运行 Task 的 JVM 进程。</td>
</tr>
<tr>
<td><strong>作业生命周期管理</strong></td>
<td>ApplicationMaster (AM)</td>
<td>Driver</td>
<td>- YARN 的 AM 负责单个作业的资源申请和任务调度。  <br>- Spark 的 Driver 负责 DAG 生成和 Task 分发。</td>
</tr>
<tr>
<td><strong>资源隔离与任务运行</strong></td>
<td>Container</td>
<td>Task</td>
<td>- YARN 的 Container 是资源隔离单位，运行 ApplicationMaster 或 Task。  <br>- Spark 的 Task 是计算的最小单位，运行在 Executor 中。</td>
</tr>
<tr>
<td><strong>作业监控与状态跟踪</strong></td>
<td>ResourceManager Web UI</td>
<td>Spark Web UI</td>
<td>- YARN 的 Web UI 显示集群资源使用和作业状态。  <br>- Spark 的 Web UI 显示作业的 DAG、Stage 和 Task 进度。</td>
</tr>
<tr>
<td><strong>日志管理与故障排查</strong></td>
<td>NodeManager 日志目录</td>
<td>Executor 日志目录</td>
<td>- YARN 的日志存储在 NodeManager 节点上。  <br>- Spark 的日志存储在 Executor 节点上，可通过 Web UI 查看。</td>
</tr>
</tbody>
</table>
<ol>
<li><strong>ResourceManager (YARN) vs Cluster Manager (Spark)</strong>
<ul>
<li><strong>YARN 的 ResourceManager</strong>：
<ul>
<li>负责全局资源管理和调度，分配 Container 给 ApplicationMaster。</li>
<li>支持多租户，可同时运行多个计算框架（如 MapReduce、Spark）。</li>
</ul>
</li>
<li><strong>Spark 的 Cluster Manager</strong>：
<ul>
<li>负责为 Spark 作业申请资源，可以是 YARN、Standalone 或 Mesos。</li>
<li>如果使用 YARN 模式，Spark 的 Cluster Manager 就是 YARN 的 ResourceManager。<br>
<strong>区别</strong>：</li>
</ul>
</li>
<li>YARN 的 ResourceManager 是通用的资源管理器，而 Spark 的 Cluster Manager 是 Spark 专用的资源申请接口。</li>
</ul>
</li>
<li><strong>NodeManager (YARN) vs Executor (Spark)</strong>
<ul>
<li><strong>YARN 的 NodeManager</strong>：
<ul>
<li>管理单个节点的资源，启动和监控 Container。</li>
<li>负责与 ResourceManager 通信，汇报资源使用情况。</li>
</ul>
</li>
<li><strong>Spark 的 Executor</strong>：
<ul>
<li>在 Worker 节点上运行，负责执行 Task 并缓存数据。</li>
<li>每个 Executor 是一个 JVM 进程，可运行<mark>多个</mark> Task。<br>
<strong>区别</strong>：</li>
</ul>
</li>
<li>NodeManager 是 YARN 的资源管理组件，而 Executor 是 Spark 的计算执行组件。</li>
<li>NodeManager 启动的 Container 可以运行 ApplicationMaster 或 Task，而 Executor 只运行 Task。</li>
</ul>
</li>
<li><strong>ApplicationMaster (YARN) vs Driver (Spark)</strong>
<ul>
<li><strong>YARN 的 ApplicationMaster</strong>：
<ul>
<li>负责单个作业的资源申请、任务调度和监控。</li>
<li>与 ResourceManager 通信申请资源，与 NodeManager 通信启动 Task。</li>
</ul>
</li>
<li><strong>Spark 的 Driver</strong>：
<ul>
<li>运行用户编写的 <code>main</code> 函数，生成 DAG 并拆分为 Task。</li>
<li>与 Cluster Manager 通信申请资源，与 Executor 通信分发 Task。<br>
<strong>区别</strong>：</li>
</ul>
</li>
<li>ApplicationMaster 是 YARN 的作业管理者，而 Driver 是 Spark 的作业控制中心。</li>
<li>在 YARN 模式下，Spark 的 Driver 运行在 ApplicationMaster 中。</li>
</ul>
</li>
<li><strong>Container (YARN) vs Task (Spark)</strong>
<ul>
<li><strong>YARN 的 Container</strong>：
<ul>
<li>是资源隔离单位，封装了 CPU、内存等资源。</li>
<li>可以运行 ApplicationMaster 或 Task。</li>
</ul>
</li>
<li><strong>Spark 的 Task</strong>：
<ul>
<li>是计算的最小单位，运行在 Executor 中。</li>
<li>每个 Task 处理一个分区的数据。<br>
<strong>区别</strong>：</li>
</ul>
</li>
<li>Container 是 YARN 的资源抽象，而 Task 是 Spark 的计算抽象。</li>
<li>一个 Container 可以运行多个 Task（如果资源允许）。</li>
</ul>
</li>
<li><strong>ResourceManager Web UI (YARN) vs Spark Web UI</strong>
<ul>
<li><strong>YARN 的 Web UI</strong>：
<ul>
<li>显示集群资源使用情况、作业状态和日志。</li>
<li>访问地址：<code>http://&lt;ResourceManager_IP&gt;:8088</code>。</li>
</ul>
</li>
<li><strong>Spark 的 Web UI</strong>：
<ul>
<li>显示作业的 DAG、Stage 进度、Task 分布和 Executor 日志。</li>
<li>访问地址：<code>http://&lt;Driver_IP&gt;:4040</code>。<br>
<strong>区别</strong>：</li>
</ul>
</li>
<li>YARN 的 Web UI 关注集群全局状态，而 Spark 的 Web UI 关注单个作业的执行细节。</li>
</ul>
</li>
<li><strong>NodeManager 日志目录 (YARN) vs Executor 日志目录 (Spark)</strong>
<ul>
<li><strong>YARN 的日志目录</strong>：
<ul>
<li>存储 ApplicationMaster 和 Task 的日志，路径由 <code>yarn.nodemanager.log-dirs</code> 配置。</li>
</ul>
</li>
<li><strong>Spark 的日志目录</strong>：
<ul>
<li>存储 Executor 的日志，路径由 <code>spark.executor.logs</code> 配置。<br>
<strong>区别</strong>：</li>
</ul>
</li>
<li>YARN 的日志分散在多个 NodeManager 节点上，而 Spark 的日志集中在 Executor 节点上。</li>
</ul>
</li>
</ol>
<p>总结</p>
<ul>
<li><strong>YARN</strong> 是通用的资源管理框架，支持多种计算框架（如 MapReduce、Spark）。</li>
<li><strong>Spark</strong> 是专用的计算框架，依赖 Cluster Manager（如 YARN）申请资源。</li>
<li><strong>核心组件对比</strong>：
<ul>
<li>YARN 的 ResourceManager 和 Spark 的 Cluster Manager 功能类似，但后者更专注于 Spark 作业。</li>
<li>YARN 的 ApplicationMaster 和 Spark 的 Driver 都是作业管理者，但 Driver 还负责 DAG 生成和 Task 分发。</li>
</ul>
</li>
</ul>
<h1>Hive</h1>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/0c25f9df2de74cbcb1d60d714493825a.png" alt="0c25f9df2de74cbcb1d60d714493825a"><br>
<strong>MapReduce支持程序开发（Java、Python等）但不支持SQL直接进行开发</strong><br>
<strong>分布式SQL计算 - Hive</strong><br>
分布式 SQL 计算是指通过分布式计算框架，执行 SQL 查询语句进行数据统计和分析的过程。在这种方式下，SQL 查询会被分发到多个节点上执行，从而实现对大规模数据集的高效处理。<br>
Apache Hive 是一个用于处理分布式SQL计算的工具，它为用户提供了一个类 SQL 接口，让开发人员能够方便地在 Hadoop 集群上执行 SQL 查询。Hive 通过将 SQL 语句翻译成 MapReduce 程序来执行计算，从而帮助用户处理大规模数据。</p>
<h2 id="Hive的主要功能">Hive的主要功能</h2>
<ul>
<li><strong>将 SQL 语句翻译成 MapReduce 程序</strong>：Hive 允许用户编写 SQL 查询语句，而底层会自动将 SQL 转换为 MapReduce 程序进行处理。</li>
<li><strong>基于 Hive 的分布式 SQL 计算能力</strong>：Hive 使得用户能够以类 SQL 语法的方式进行分布式数据计算，同时底层使用 MapReduce 来执行数据处理任务。</li>
</ul>
<h2 id="为什么使用-Hive？">为什么使用 Hive？</h2>
<p>使用 Hadoop 的原生 MapReduce 直接处理数据时会遇到一些挑战：</p>
<ol>
<li><strong>人员学习成本太高</strong>：MapReduce 编程需要掌握 Java、Python 等编程语言，对于许多非开发人员而言，学习曲线陡峭。</li>
<li><strong>开发复杂查询逻辑的难度太大</strong>：MapReduce 更适合底层的数据处理，而对于复杂的 SQL 查询，开发起来非常困难。</li>
</ol>
<h2 id="使用-Hive-的好处">使用 Hive 的好处</h2>
<ul>
<li><strong>简化的接口</strong>：Hive 提供了类似 SQL 的接口，开发者无需编写复杂的 MapReduce 代码即可进行数据查询，大大降低了学习成本。</li>
<li><strong>高效的分布式数据处理</strong>：虽然用户写的是 SQL 查询，但底层通过 MapReduce 执行，能够处理海量数据。</li>
</ul>
<p>假设要设计一个类似 Hive 的系统，它的基本要求包括：</p>
<ul>
<li>用户只需要编写 SQL 语句。</li>
<li>Hive 会自动将 SQL 转换为 MapReduce 程序并提交运行。</li>
<li>系统需要处理存储在 HDFS 上的结构化数据。<br>
<strong>如何实现？</strong></li>
</ul>
<ol>
<li><strong>元数据管理</strong>：为了执行 SQL 查询，需要知道数据的存储位置、数据结构和数据类型。Hive 必须具备管理这些元数据的能力。元数据是对数据的描述，帮助系统了解如何处理数据。<br>
例如，对于一个 <code>SELECT city, COUNT(*) FROM t_user GROUP BY city;</code> 的查询，系统需要知道：<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2037.png" alt="image 37">
<ul>
<li>数据存储在哪里？</li>
<li>列之间的分隔符是什么？</li>
<li><code>city</code> 列的类型是什么？</li>
</ul>
</li>
<li><strong>SQL 解析器</strong>：一旦有了元数据管理，接下来需要通过 SQL 解析器将 SQL 语句转换为可执行的 MapReduce 程序。SQL 解析器的工作包括：
<ul>
<li>解析 SQL 语句。</li>
<li>将 SQL 转换成相应的 MapReduce 程序。</li>
<li>提交 MapReduce 程序并收集执行结果。</li>
</ul>
</li>
</ol>
<h2 id="Hive-架构">Hive 架构</h2>
<p>Apache Hive 的架构主要包括两个重要组件：</p>
<ol>
<li><strong>SQL 解析器</strong>：负责将 SQL 语句转换为 MapReduce 程序。</li>
<li><strong>元数据存储</strong>：用于存储和管理数据的元数据信息，包括表结构、数据位置等。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/880c01f20bed4f29b8d3242b49c61ad3.png" alt="880c01f20bed4f29b8d3242b49c61ad3"></li>
</ol>
<h2 id="Hive基础架构">Hive基础架构</h2>
<p>Hive是一个基于Hadoop的分布式数据仓库，提供类SQL查询语言（HiveQL）用于数据分析。Hive的架构由多个组件组成，每个组件扮演着不同的角色，下面将详细介绍Hive的基础架构。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2038.png" alt="image 38"><br>
Hive架构的核心组件包括：</p>
<ol>
<li><strong>用户接口</strong></li>
<li><strong>Driver驱动程序</strong></li>
<li><strong>Metastore元数据存储</strong></li>
<li><strong>用户接口</strong><br>
Hive 提供了多种用户接口供<mark>用户与 Hive 进行交互</mark>：
<ul>
<li><strong>CLI (Command Line Interface)</strong>：Hive Shell，通过命令行进行交互。</li>
<li><strong>JDBC/ODBC</strong>：通过 JDBC 或 ODBC 协议，外部客户端可以与 Hive 进行通信。</li>
<li><strong>WebGUI</strong>：Web 界面，用户可以通过浏览器访问 Hive，方便进行数据查询和管理。<br>
Hive 提供了 <strong>Hive Shell</strong>、<strong>ThriftServer</strong> 等服务进程，供用户与 Hive 交互。ThriftServer 使得外部客户端可以通过网络与 Hive 进行交互，类似于 JDBC 或 ODBC 协议。</li>
</ul>
</li>
<li><strong>Driver驱动程序（SQL解析器）</strong><br>
<strong>Driver</strong> 是 Hive 的核心组件之一，负责将 HiveQL（Hive 查询语言）查询语句转换为可执行的 MapReduce 任务。其主要功能包括：
<ul>
<li><strong>语法解析器</strong>：负责解析输入的 HiveQL 查询语句，进行词法分析和语法分析。</li>
<li><strong>计划编译器</strong>：编译解析后的查询，生成查询计划。</li>
<li><strong>优化器</strong>：对查询计划进行优化，提高执行效率。</li>
<li><strong>执行器</strong>：最终执行优化后的查询计划，并将执行结果返回给用户。<br>
这部分内容不是具体的服务进程，而是封装在Hive所依赖的Jar文件即Java代码中。</li>
</ul>
</li>
<li><strong>Metastore元数据存储</strong><br>
元数据包含:用Hive创建的database、table、表的字段等元信息。<br>
Metastore 是 Hive 用来存储和管理元数据的组件。它包含了数据库、表、字段等元数据，这些数据描述了存储在 HDFS 中的数据结构。Metastore 服务通常与关系型数据库（如 MySQL 或内置的 Derby 数据库）结合使用，提供 Hive 元数据的存储、管理和查询功能。<br>
<strong>Metastore 的作用</strong>：
<ul>
<li>存储和管理数据库、表、字段等元数据。</li>
<li>客户端连接 Metastore 服务，Metastore 再与关系型数据库（如 MySQL）进行交互来存取元数据。有了metastore服务，就可以有多个客户端同时连接，而且这些客户端不需要知道MySQL等数据库的用户名和密码，只需要连接metastore 服务即可<br>
<strong>Metastore 有三种配置模式：</strong><br>
<strong>区分3种配置方式的关键是弄清楚两个问题：</strong></li>
</ul>
<ol>
<li><strong>Metastore服务是否需要单独配置、单独启动？</strong></li>
<li><strong>Metadata是存储在内置库derby中，还是第三方库Mysql等中。</strong><br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/8747a3bbeb9f4830a53a656e830af0b5.png" alt="8747a3bbeb9f4830a53a656e830af0b5"></li>
</ol>
<ul>
<li><strong>内嵌模式</strong>：Metastore 和 Hive 服务都运行在同一个进程中。适用于<mark>测试</mark>环境，不建议用于生产。
<ul>
<li><strong>优点</strong>：无需额外配置，Hive 解压后即能启动bin/hive，方便测试和小规模使用。</li>
<li><strong>缺点</strong>：不适合生产环境，derby和Metastore服务都嵌入在主Hive Server进程中，一个服务只能被一个客户端连接（如果用两个客户端以上就非常浪费资源），且不能共享元数据，且每次启动 Hive 都会内嵌启动 Metastore 服务，资源浪费较大。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/70936254c30e46429f0abda285ae085e.png" alt="70936254c30e46429f0abda285ae085e"></li>
</ul>
</li>
<li><strong>本地模式</strong>：Metastore 可以<mark>独立</mark>运行，并使用外部数据库（如 MySQL）来存储元数据。每次启动 Hive 服务时，Metastore 也会一起启动，但这种模式相对<mark>浪费资源</mark>。
<ul>
<li><strong>优点</strong>：可以使用外部数据库（如 MySQL）来存储元数据，支持元数据共享。</li>
<li><strong>缺点</strong>：metastore嵌入到了hive进程中，每次启动 Hive 服务时，Metastore 也会一同启动，增加资源消耗。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/316e4de859174e309ace64e63a7c1e3a.png" alt="316e4de859174e309ace64e63a7c1e3a"></li>
</ul>
</li>
<li><strong>远程模式（推荐）</strong>：Metastore 作为独立的服务运行，可以通过网络连接其他 Hive 组件。多个 Hive 客户端可以同时连接 Metastore 服务进行元数据管理，是推荐的<mark>生产</mark>环境模式。
<ul>
<li><strong>优点</strong>：Metastore 可独立启动并通过网络连接，支持多客户端<mark>共享</mark>元数据。能够灵活配置，适合生产环境。<br>
可以单独使用外部库(mysql) 可以共享元数据 可以连接metastore服务也可以连接hiveserver2服务<br>
metastore可以单独启动,配置 其他依赖hive的软件都可以通过Metastore访问hive</li>
<li><strong>缺点</strong>：需要确保在启动 HiveServer2 服务之前先启动 Metastore 服务。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/f470a62631254473bec125e7b8788891.png" alt="f470a62631254473bec125e7b8788891"></li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="Hive部署">Hive部署</h2>
<p>在部署 Hive 时，首先要保证 Hive 和元数据存储服务（如 MySQL）都能顺利运行。<br>
<strong>Hive是分布式运行的框架还是单机运行的?</strong><br>
Hive是单机工具，只需要部署在一台服务器即可<br>
Hive虽然是单机的，但是它可以提交分布式运行的MapReduce程序运行。<br>
由于Hive是单机工具，只需要准备一台服务器供Hive使用；同时Hive需要使用元数据服务，即需要提供一个关系型数据库，也需要选择一台服务器安装关系型数据库</p>
<ul>
<li><strong>Hive</strong> 可以部署在一台单独的服务器上，这台服务器即为 Hive 的<mark>主节点</mark>。</li>
<li><strong>元数据存储</strong>：Hive 需要一个关系型数据库（如 MySQL）来存储元数据，可以将数据库部署在同一台服务器上，也可以部署在不同的服务器上。</li>
</ul>
<p>为了简单起见，Hive和MySQL都安装到node1服务器<br>
部署 Hive 时，确保 Hive 依赖的组件（如 Hadoop 和 HDFS）已经正常安装并配置好。</p>
<ol>
<li>安装MYSQL，略<br>
注：退出mysql，ctrl+d</li>
<li><strong>配置Hadoop</strong><br>
Hive的运行依赖于Hadoop（HDFS、MapReduce、YARN都依赖）<br>
同时涉及到HDFS文件系统的访问，所以需要配置Hadoop的代理用户，即设置hadggp用户允许代理（模拟）其它用户<br>
配置如下内容在Hadoop的<code>/export/server/hadoop/etc/hadoop/core-site.xml</code>中，并分发到其它节点，且重启HDFS集群 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.hadoop.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.hadoop.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li>下载Hive
<ol>
<li><strong>切换到</strong> <code>**hadoop**</code> <strong>用户</strong>su - hadoop</li>
<li><strong>下载 Hive 安装包</strong> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget &lt;http://archive.apache.org/dist/hive/hive-3.1.3/apache-hive-3.1.3-bin.tar.gz&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><strong>解压并设置软链接</strong> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-hive-3.1.3-bin.tar.gz -C /export/server/</span><br><span class="line">ln -s /export/server/apache-hive-3.1.3-bin /export/server/hive</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
<li><strong>配置 MySQL 驱动</strong><br>
4. <strong>下载 MySQL 驱动包</strong><br>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.28/mysql-connector-java-8.0.28.jar</span><br></pre></td></tr></table></figure><br>
5. <strong>将驱动包放入 Hive 的</strong> <code>**lib**</code> <strong>目录</strong><br>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv mysql-connector-java-8.0.28.jar /export/server/hive/lib/</span><br></pre></td></tr></table></figure></li>
<li><strong>配置 Hive</strong>
<ol>
<li><strong>创建</strong> <code>**hive-env.sh**</code> <strong>文件</strong><br>
在 <code>$HIVE_HOME/conf</code>（/export/server/hive/conf） 目录下<code>mv hive-env.sh.template hive-env.sh</code>，并添加以下内容： <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_HOME=/export/server/hadoop</span><br><span class="line">export HIVE_CONF_DIR=/export/server/hive/conf</span><br><span class="line">export HIVE_AUX_JARS_PATH=/export/server/hive/lib</span><br></pre></td></tr></table></figure>
</li>
<li><strong>创建</strong> <code>**hive-site.xml**</code> <strong>文件</strong><br>
在 <code>$HIVE_HOME/conf</code> 目录下创建 <code>hive-site.xml</code>，并添加以下内容： <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://node1:3306/hive?createDatabaseIfNotExist=true<span class="symbol">&amp;amp;</span>useSSL=false<span class="symbol">&amp;amp;</span>useUnicode=true<span class="symbol">&amp;amp;</span>characterEncoding=UTF-8<span class="symbol">&amp;amp;</span>allowPublicKeyRetrieval=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>123456<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://node1:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.event.db.notification.api.auth<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
<li><strong>初始化元数据库</strong>
<ol>
<li><strong>在 MySQL 中创建 Hive 元数据库</strong> <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DATABASE hive CHARSET UTF8;</span><br></pre></td></tr></table></figure>
</li>
<li><strong>执行元数据库初始化命令</strong> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/hive</span><br><span class="line">bin/schematool -initSchema -dbType mysql -verbose</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>成功标志</strong>：在 MySQL 的 <code>hive</code> 数据库中生成 74 张元数据表。</li>
</ul>
</li>
</ol>
</li>
<li><strong>启动 Hive</strong><br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2039.png" alt="image 39">
<ol>
<li><strong>创建日志目录</strong> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir /export/server/hive/logs</span><br></pre></td></tr></table></figure>
</li>
<li><strong>启动元数据服务</strong>
<ul>
<li>前台启动：  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hive --service metastore</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：使用此命令启动 Hive 的 Metastore 服务，且该服务会在当前终端会话中前台运行。Metastore 服务会持续监听客户端的请求，负责与数据库进行交互，获取和管理元数据。</li>
<li><strong>前台运行</strong>：服务将直接显示在终端中，若终端会话结束或出现异常，服务会被停止。</li>
</ul>
</li>
<li>后台启动：  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup bin/hive --service metastore &gt;&gt; logs/metastore.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：<code>nohup</code> 命令会让 Metastore 服务在后台启动，即使当前终端关闭，服务仍会继续运行。<code>&gt;&gt; logs/metastore.log 2&gt;&amp;1</code> 将日志输出重定向到 <code>logs/metastore.log</code> 文件，这样你可以查看日志文件了解服务的运行情况。</li>
<li><strong>后台运行</strong>：此命令启动 Metastore 服务并将其置于后台运行，不会占用当前终端窗口。即使你退出终端，服务也会继续运行。</li>
</ul>
</li>
</ul>
</li>
<li><strong>启动 Hive 客户端</strong>
<ul>
<li><strong>Hive Shell</strong>（直接执行 SQL）：  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hive</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：这是启动 Hive 命令行工具的标准方式。当你执行此命令时，会启动一个 Hive Shell 环境，可以直接在其中执行 HiveQL（类似 SQL）语句，如创建表、查询数据等。</li>
<li><strong>交互式操作</strong>：启动后，用户可以直接输入 HiveQL 查询来与 Hive 集群进行交互。所有的操作都会被发送到 Hive 的查询引擎，处理结果会在命令行界面显示。</li>
</ul>
</li>
<li><strong>Hive ThriftServer</strong>（外部客户端连接）：  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/hive</span><br><span class="line">bin/hive --service hiveserver2</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：Hive ThriftServer 提供了一个接口，允许外部客户端通过 Thrift 协议连接到 Hive。这使得非 Hive 本地的客户端（如通过 JDBC 或 ODBC 连接的应用）能够通过网络访问 Hive 服务。</li>
<li><strong>外部客户端连接</strong>：此命令启动 HiveServer2 服务，通常用于生产环境中，允许外部应用（如 DataGrip、Beeline 或其他自定义应用）连接到 Hive 进行查询。HiveServer2 支持多种协议，如 JDBC、ODBC 和 Beeline。</li>
</ul>
</li>
</ul>
</li>
</ol>
</li>
<li><strong>验证 Hive 运行</strong><br>
4. <strong>访问 Hive Shell</strong><br>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hive</span><br></pre></td></tr></table></figure><br>
- 执行简单查询：<br>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> DATABASES;</span><br></pre></td></tr></table></figure><br>
5. <strong>查看日志</strong><br>
- 检查 <code>logs/metastore.log</code> 和 <code>logs/hiveserver2.log</code>，确保无报错。</li>
</ol>
<h2 id="Hive初体验">Hive初体验</h2>
<ol>
<li><strong>启动 Metastore 服务</strong>：首先确保 Metastore 服务已启动。<br>
在终端中执行： <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hive</span><br></pre></td></tr></table></figure>
进入 Hive Shell 环境，可以开始执行 SQL 查询。</li>
<li><strong>配置环境变量</strong>：在 <code>/etc/profile</code> 中配置 Hive 的环境变量： <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export HIVE_HOME=/export/server/apache-hive-3.1.3-bin</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin:$HIVE_HOME/sbin</span><br></pre></td></tr></table></figure>
执行 <code>source /etc/profile</code> 使其立即生效。</li>
<li><strong>创建表</strong>： <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test(id <span class="type">INT</span>, name STRING, gender STRING);</span><br></pre></td></tr></table></figure>
</li>
<li><strong>插入数据</strong>： <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test <span class="keyword">VALUES</span>(<span class="number">1</span>, <span class="string">&#x27;王力红&#x27;</span>, <span class="string">&#x27;男&#x27;</span>), (<span class="number">2</span>, <span class="string">&#x27;周杰伦&#x27;</span>, <span class="string">&#x27;男&#x27;</span>), (<span class="number">3</span>, <span class="string">&#x27;林志玲&#x27;</span>, <span class="string">&#x27;女&#x27;</span>);</span><br></pre></td></tr></table></figure>
</li>
<li><strong>查询数据</strong>： <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> gender, <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">AS</span> cnt <span class="keyword">FROM</span> test <span class="keyword">GROUP</span> <span class="keyword">BY</span> gender;</span><br></pre></td></tr></table></figure>
</li>
<li><strong>验证数据存储</strong>：Hive 的数据存储在 HDFS 中，默认路径为 <code>/user/hive/warehouse</code>。</li>
<li><strong>查看 MapReduce 执行情况</strong>：可以通过 YARN Web UI 查看 Hive 执行的 MapReduce 任务。<br>
URL 示例：<code>[http://node1:8088](http://node1:8088)</code><br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/f3e12450dcbb4f779fa20d9280628fab.png" alt="f3e12450dcbb4f779fa20d9280628fab"></li>
</ol>
<ul>
<li>Hive中可以使用类MySQL的SQL语法完成基本的库、表、插入、查询等操作</li>
<li>通过YARN控制台可以看到，Hive是将SQL翻译成MapReduce程序运行在YARN中</li>
<li>Hive中创建的库和表的数据，存储在HDFS中，默认存放在：hdfs://node1:8020/user/hive/warehouse中。</li>
</ul>
<h2 id="Hive客户端">Hive客户端</h2>
<p><strong>Hive 的两种使用方式</strong></p>
<ol>
<li><strong>方式1：Hive Shell 客户端</strong>
<ul>
<li><strong>功能</strong>：直接通过命令行执行 Hive SQL。</li>
<li><strong>启动命令</strong>：  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/hive</span><br><span class="line">bin/hive  # 直接进入交互式 SQL 环境</span><br></pre></td></tr></table></figure>
</li>
<li><strong>适用场景</strong>：本地快速调试或简单查询。</li>
</ul>
</li>
<li><strong>方式2：HiveServer2（远程服务）</strong>
<ul>
<li><strong>功能</strong>：时Hive内置的一个ThriftServer服务器，提供 Thrift 服务端口，支持远程客户端通过 JDBC/ODBC 连接。</li>
<li><strong>启动命令</strong>：  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">后台启动 HiveServer2</span></span><br><span class="line">nohup bin/hive --service hiveserver2 &gt;&gt; logs/hiveserver2.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>
</li>
<li><strong>适用场景</strong>：团队协作、第三方工具集成（如 DataGrip、DBeaver）。<br>
<strong>服务依赖与启动顺序</strong><br>
启动 Metastore → 启动 HiveServer2 → 连接客户端（Beeline/DataGrip）<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/17f97af3d2dc432180f85e8410774c98.png" alt="17f97af3d2dc432180f85e8410774c98"></li>
</ul>
</li>
<li><strong>必启服务：Metastore</strong>
<ul>
<li><strong>作用</strong>：管理 Hive 元数据（表结构、存储位置等）。</li>
<li><strong>启动命令</strong>：  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">前台启动（调试用）</span></span><br><span class="line">bin/hive --service metastore</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">后台启动（生产环境）</span></span><br><span class="line">nohup bin/hive --service metastore &gt;&gt; logs/metastore.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><strong>可选服务：HiveServer2</strong>
<ul>
<li><strong>依赖条件</strong>：必须先启动 Metastore 服务。</li>
<li><strong>启动命令</strong>：  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">后台启动 HiveServer2</span></span><br><span class="line">nohup bin/hive --service hiveserver2 &gt;&gt; logs/hiveserver2.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ol>
<p><strong>客户端连接方式</strong><br>
5. <strong>Beeline（命令行工具）</strong><br>
- <strong>连接步骤</strong>：<br>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入 Beeline 客户端</span></span><br><span class="line">cd /export/server/hive</span><br><span class="line">bin/beeline</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">连接 HiveServer2</span></span><br><span class="line">!connect jdbc:hive2://node1:10000</span><br></pre></td></tr></table></figure><br>
- <strong>输入信息</strong>：<br>
- <strong>Username</strong>：hadoop（有hdfs权限的用户）<br>
- <strong>Password</strong>：留空（默认无密码）<br>
- <strong>验证连接</strong>：<br>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> DATABASES;  <span class="comment">-- 成功执行表示连接正常</span></span><br></pre></td></tr></table></figure><br>
6. <strong>第三方客户端（DataGrip/DBeaver）</strong><br>
- <strong>通用配置</strong>：<br>
- <strong>JDBC URL</strong>：<code>jdbc:hive2://node1:10000</code><br>
- <strong>Driver Class</strong>：<code>org.apache.hive.jdbc.HiveDriver</code><br>
- <strong>Username/Password</strong>：默认无密码，用户名可填 <code>hadoop</code><br>
- <strong>DataGrip 配置示例</strong>：<br>
1. 新建数据源，选择 <strong>Apache Hive</strong>。<br>
2. 填写主机名（<code>node1</code>）和端口（<code>10000</code>）。<br>
3. 下载 Hive JDBC 驱动（或手动指定 <code>/export/server/hive/lib</code> 下的 JAR）。<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/image%2040.png" alt="image 40"><br>
- <strong>DBeaver 配置示例</strong>：<br>
1. 创建新连接，选择 <strong>Apache Hive</strong>。<br>
2. 设置连接参数：<br>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Host: node1</span><br><span class="line">Port: 10000</span><br><span class="line">Database/Schema: default</span><br></pre></td></tr></table></figure><br>
注：<br>
7. <strong>服务启动顺序</strong>：<br>
- 必须先启动 <code>metastore</code>，再启动 <code>hiveserver2</code>。<br>
8. <strong>端口与防火墙</strong>：<br>
- <strong>Metastore</strong>：默认端口 <code>9083</code>（需开放）。<br>
- <strong>HiveServer2</strong>：默认端口 <code>10000</code>（需开放）。<br>
- Ubuntu 防火墙命令：<br>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo ufw allow 9083/tcp</span><br><span class="line">sudo ufw allow 10000/tcp</span><br><span class="line">sudo ufw reload</span><br></pre></td></tr></table></figure><br>
9. <strong>日志排查</strong>：<br>
- <strong>Metastore 日志</strong>：<code>logs/metastore.log</code><br>
- <strong>HiveServer2 日志</strong>：<code>logs/hiveserver2.log</code><br>
- 常见错误：<br>
- <code>Connection refused</code>：检查服务是否启动、端口是否开放。<br>
- <code>Authentication error</code>：确认用户名/密码配置。<br>
10. <strong>HiveServer2 启动延迟</strong>：<br>
- 服务启动后需等待 1-2 分钟才能响应连接，可通过日志监控状态。</p>
<p>启动Hive</p>
<ol>
<li><strong>确保 Hadoop 集群已启动</strong>
<ul>
<li>检查 HDFS 和 YARN 服务状态：  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps  # 确保 NameNode、DataNode、ResourceManager、NodeManager 进程正常运行</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><strong>确保 MySQL 服务已启动</strong>
<ul>
<li>检查 MySQL 服务状态：  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl status mysql</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><strong>确保 Metastore 数据库已初始化</strong>
<ul>
<li>如果未初始化，执行以下命令：  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/hive</span><br><span class="line">bin/schematool -initSchema -dbType mysql -verbose</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ol>
<p>Hive 的运行依赖于两个核心服务：<br>
4. <strong>Metastore 服务</strong>：管理 Hive 元数据（表结构、存储位置等）。<br>
- <strong>前台启动</strong>（调试用）：<br>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/hive</span><br><span class="line">bin/hive --service metastore</span><br></pre></td></tr></table></figure><br>
- <strong>后台启动</strong>（生产环境）：<br>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup bin/hive --service metastore &gt;&gt; logs/metastore.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><br>
5. <strong>HiveServer2 服务</strong>：提供 Thrift 服务端口，支持远程客户端连接。<br>
- <strong>前台启动</strong>（调试用）：<br>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hive --service hiveserver2</span><br></pre></td></tr></table></figure><br>
- <strong>后台启动</strong>（生产环境）：<br>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup bin/hive --service hiveserver2 &gt;&gt; logs/hiveserver2.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><br>
<strong>验证服务状态</strong><br>
6. <strong>检查 Metastore 服务</strong><br>
- 查看日志文件：<br>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tail -f logs/metastore.log</span><br></pre></td></tr></table></figure><br>
- 确保无报错信息，且日志中包含 <code>Metastore is running</code>。<br>
7. <strong>检查 HiveServer2 服务</strong><br>
- 查看日志文件：<br>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tail -f logs/hiveserver2.log</span><br></pre></td></tr></table></figure><br>
- 确保无报错信息，且日志中包含 <code>HiveServer2 is running</code>。<br>
8. <strong>检查端口监听</strong><br>
- Metastore 默认端口：<code>9083</code><br>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -tuln | grep 9083</span><br></pre></td></tr></table></figure><br>
- HiveServer2 默认端口：<code>10000</code><br>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -tuln | grep 10000</span><br></pre></td></tr></table></figure><br>
<strong>客户端连接</strong><br>
9. <strong>使用 Beeline 连接 HiveServer2</strong><br>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/hive</span><br><span class="line">bin/beeline</span><br><span class="line">!connect jdbc:hive2://node1:10000</span><br></pre></td></tr></table></figure><br>
- 输入用户名（如 <code>root</code>），密码留空。<br>
10. <strong>使用第三方工具连接</strong><br>
- <strong>DataGrip/DBeaver</strong>：配置 JDBC URL 为 <code>jdbc:hive2://node1:10000</code>，驱动选择 <code>Apache Hive</code>。<br>
<strong>停止 Hive 服务</strong><br>
11. <strong>停止 HiveServer2 服务</strong><br>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pkill -f &quot;HiveServer2&quot;</span><br></pre></td></tr></table></figure><br>
12. <strong>停止 Metastore 服务</strong><br>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pkill -f &quot;HiveMetaStore&quot;</span><br></pre></td></tr></table></figure></p>
<h3 id="HiveQL-常用操作整理与注释">HiveQL 常用操作整理与注释</h3>
<h4 id="一、Hive-基本数据类型">一、Hive 基本数据类型</h4>
<h5 id="1-基本数据类型">1. 基本数据类型</h5>
<table>
<thead>
<tr>
<th>类型</th>
<th>字节数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>tinyint</td>
<td>1</td>
<td>1 字节有符号整数</td>
</tr>
<tr>
<td>smallint</td>
<td>2</td>
<td>2 字节有符号整数</td>
</tr>
<tr>
<td>int</td>
<td>4</td>
<td>4 字节有符号整数</td>
</tr>
<tr>
<td>bigint</td>
<td>8</td>
<td>8 字节有符号整数</td>
</tr>
<tr>
<td>boolean</td>
<td>-</td>
<td>布尔值（true/false）</td>
</tr>
<tr>
<td>float</td>
<td>4</td>
<td>单精度浮点数</td>
</tr>
<tr>
<td>double</td>
<td>8</td>
<td>双精度浮点数</td>
</tr>
<tr>
<td>string</td>
<td>-</td>
<td>可变长度字符串</td>
</tr>
<tr>
<td>varchar</td>
<td>-</td>
<td>可变长度字符串（指定最大长度）</td>
</tr>
<tr>
<td>char</td>
<td>-</td>
<td>固定长度字符串</td>
</tr>
</tbody>
</table>
<h5 id="2-复杂数据类型">2. 复杂数据类型</h5>
<table>
<thead>
<tr>
<th>类型</th>
<th>说明</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>array</td>
<td>有序元素集合</td>
<td>array<string> hobbies</td>
</tr>
<tr>
<td>map</td>
<td>键值对集合（键为基本类型）</td>
<td>map&lt;int, string&gt; scores</td>
</tr>
<tr>
<td>struct</td>
<td>命名字段集合</td>
<td>struct&lt;name:string, age:int&gt;</td>
</tr>
</tbody>
</table>
<h4 id="二、数据定义操作（DDL）">二、数据定义操作（DDL）</h4>
<h5 id="1-数据库操作">1. 数据库操作</h5>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> database if <span class="keyword">not</span> <span class="keyword">exists</span> hive;       <span class="comment">-- 创建数据库（不存在时创建）</span></span><br><span class="line"><span class="keyword">show</span> databases;                           <span class="comment">-- 查看所有数据库</span></span><br><span class="line"><span class="keyword">show</span> databases <span class="keyword">like</span> <span class="string">&#x27;h.*&#x27;</span>;                <span class="comment">-- 查看以h开头的数据库（正则匹配）</span></span><br><span class="line"><span class="keyword">describe</span> database extended hive;          <span class="comment">-- 查看数据库详情（含存储路径）</span></span><br><span class="line"><span class="keyword">alter</span> database hive <span class="keyword">set</span> dbproperties(<span class="string">&#x27;owner&#x27;</span><span class="operator">=</span><span class="string">&#x27;admin&#x27;</span>);  <span class="comment">-- 设置数据库属性</span></span><br><span class="line">use hive;                                 <span class="comment">-- 切换到hive数据库</span></span><br><span class="line"><span class="keyword">drop</span> database if <span class="keyword">exists</span> hive;             <span class="comment">-- 删除空数据库</span></span><br><span class="line"><span class="keyword">drop</span> database if <span class="keyword">exists</span> hive cascade;     <span class="comment">-- 强制删除数据库及所有表</span></span><br></pre></td></tr></table></figure>
<h5 id="2-表操作">2. 表操作</h5>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- ---------------------</span></span><br><span class="line"><span class="comment">-- 创建内部表（管理表）</span></span><br><span class="line"><span class="comment">-- ---------------------</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> hive.usr (</span><br><span class="line">    name string comment <span class="string">&#x27;用户名&#x27;</span>,</span><br><span class="line">    pwd string comment <span class="string">&#x27;密码&#x27;</span>,</span><br><span class="line">    <span class="comment">-- 结构化地址信息：街道、城市、州、邮编</span></span><br><span class="line">    address struct<span class="operator">&lt;</span>street:string, city:string, state:string, zip:<span class="type">int</span><span class="operator">&gt;</span> comment <span class="string">&#x27;家庭地址&#x27;</span>,</span><br><span class="line">    <span class="comment">-- 映射类型：编号到性别的映射</span></span><br><span class="line">    identify map<span class="operator">&lt;</span><span class="type">int</span>, tinyint<span class="operator">&gt;</span> comment <span class="string">&#x27;编号-性别&#x27;</span></span><br><span class="line">) comment <span class="string">&#x27;用户信息表&#x27;</span></span><br><span class="line">tblproperties(<span class="string">&#x27;creator&#x27;</span><span class="operator">=</span><span class="string">&#x27;me&#x27;</span>, <span class="string">&#x27;create_time&#x27;</span><span class="operator">=</span><span class="string">&#x27;2016-01-01&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- ---------------------</span></span><br><span class="line"><span class="comment">-- 创建外部表</span></span><br><span class="line"><span class="comment">-- ---------------------</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> usr2 (</span><br><span class="line">    name string,</span><br><span class="line">    pwd string,</span><br><span class="line">    address struct<span class="operator">&lt;</span>street:string, city:string, state:string, zip:<span class="type">int</span><span class="operator">&gt;</span>,</span><br><span class="line">    identify map<span class="operator">&lt;</span><span class="type">int</span>, tinyint<span class="operator">&gt;</span></span><br><span class="line">) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span>  <span class="comment">-- 字段以逗号分隔</span></span><br><span class="line">location <span class="string">&#x27;/usr/local/hive/warehouse/hive.db/usr&#x27;</span>;  <span class="comment">-- 显式指定存储路径</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- ---------------------</span></span><br><span class="line"><span class="comment">-- 创建分区表</span></span><br><span class="line"><span class="comment">-- ---------------------</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> usr3 (</span><br><span class="line">    name string,</span><br><span class="line">    pwd string,</span><br><span class="line">    address struct<span class="operator">&lt;</span>street:string, city:string, state:string, zip:<span class="type">int</span><span class="operator">&gt;</span>,</span><br><span class="line">    identify map<span class="operator">&lt;</span><span class="type">int</span>, tinyint<span class="operator">&gt;</span></span><br><span class="line">) partitioned <span class="keyword">by</span> (city string, state string);  <span class="comment">-- 按城市和州分区</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- ---------------------</span></span><br><span class="line"><span class="comment">-- 复制表结构</span></span><br><span class="line"><span class="comment">-- ---------------------</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> hive.usr1 <span class="keyword">like</span> hive.usr;  <span class="comment">-- 仅复制表结构，不复制数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- ---------------------</span></span><br><span class="line"><span class="comment">-- 表查询与管理</span></span><br><span class="line"><span class="comment">-- ---------------------</span></span><br><span class="line"><span class="keyword">show</span> tables <span class="keyword">in</span> hive;          <span class="comment">-- 查看hive数据库下的所有表</span></span><br><span class="line"><span class="keyword">show</span> tables <span class="string">&#x27;u.*&#x27;</span>;            <span class="comment">-- 查看以u开头的表（正则匹配）</span></span><br><span class="line"><span class="keyword">describe</span> formatted hive.usr;  <span class="comment">-- 查看表详细结构（含存储信息）</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> usr rename <span class="keyword">to</span> custom;  <span class="comment">-- 重命名表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- ---------------------</span></span><br><span class="line"><span class="comment">-- 分区管理</span></span><br><span class="line"><span class="comment">-- ---------------------</span></span><br><span class="line"><span class="comment">-- 添加分区（含存储路径）</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> usr2 <span class="keyword">add</span> if <span class="keyword">not</span> <span class="keyword">exists</span></span><br><span class="line"><span class="keyword">partition</span>(city<span class="operator">=</span><span class="string">&#x27;beijing&#x27;</span>, state<span class="operator">=</span><span class="string">&#x27;China&#x27;</span>)</span><br><span class="line">location <span class="string">&#x27;/usr/local/hive/warehouse/usr2/China/beijing&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 修改分区路径</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> usr2 <span class="keyword">partition</span>(city<span class="operator">=</span><span class="string">&#x27;beijing&#x27;</span>, state<span class="operator">=</span><span class="string">&#x27;China&#x27;</span>)</span><br><span class="line"><span class="keyword">set</span> location <span class="string">&#x27;/usr/local/hive/warehouse/usr2/CH/beijing&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 删除分区</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> usr2 <span class="keyword">drop</span> if <span class="keyword">exists</span> <span class="keyword">partition</span>(city<span class="operator">=</span><span class="string">&#x27;beijing&#x27;</span>, state<span class="operator">=</span><span class="string">&#x27;China&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- ---------------------</span></span><br><span class="line"><span class="comment">-- 表结构修改</span></span><br><span class="line"><span class="comment">-- ---------------------</span></span><br><span class="line"><span class="comment">-- 修改列名、类型及位置</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> usr change <span class="keyword">column</span> pwd password string after address;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 添加新列</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> usr <span class="keyword">add</span> columns(hobby string comment <span class="string">&#x27;爱好&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 替换所有列（删除旧列，添加新列）</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> usr replace columns(uname string comment <span class="string">&#x27;用户名&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 修改表属性</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> usr <span class="keyword">set</span> tblproperties(<span class="string">&#x27;creator&#x27;</span><span class="operator">=</span><span class="string">&#x27;liming&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 修改分区存储格式</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> usr2 <span class="keyword">partition</span>(city<span class="operator">=</span><span class="string">&#x27;beijing&#x27;</span>, state<span class="operator">=</span><span class="string">&#x27;China&#x27;</span>)</span><br><span class="line"><span class="keyword">set</span> fileformat sequencefile;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 删除表</span></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> if <span class="keyword">exists</span> usr1;</span><br></pre></td></tr></table></figure>
<h4 id="三、数据操作（DML）">三、数据操作（DML）</h4>
<h5 id="1-表创建与数据装载">1. 表创建与数据装载</h5>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建基础表（字段以制表符分隔）</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> hive.stu (id <span class="type">int</span>, name string)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>; 【重要】</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> hive.course (cid <span class="type">int</span>, sid <span class="type">int</span>)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- ---------------------</span></span><br><span class="line"><span class="comment">-- 从文件导入数据</span></span><br><span class="line"><span class="comment">-- ---------------------</span></span><br><span class="line"><span class="comment">-- 本地文件导入（覆盖模式）【重要】</span></span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/usr/local/hadoop/examples/stu.txt&#x27;</span></span><br><span class="line">overwrite <span class="keyword">into</span> <span class="keyword">table</span> stu;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- HDFS文件导入（追加模式）</span></span><br><span class="line">load data inpath <span class="string">&#x27;/hdfs/path/stu.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> stu;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- ---------------------</span></span><br><span class="line"><span class="comment">-- 通过查询插入数据</span></span><br><span class="line"><span class="comment">-- ---------------------</span></span><br><span class="line"><span class="comment">-- 创建表并插入查询结果（CTAS）</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> stu1 <span class="keyword">as</span> <span class="keyword">select</span> id, name <span class="keyword">from</span> stu;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 向已存在表插入数据（覆盖模式）【重要】</span></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> stu1 <span class="keyword">select</span> id, name <span class="keyword">from</span> stu <span class="keyword">where</span> id <span class="operator">&gt;</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 向已存在表追加数据</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> stu1 <span class="keyword">select</span> id, name <span class="keyword">from</span> stu <span class="keyword">where</span> id <span class="operator">&lt;=</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>
<p>数据导出操作</p>
<ol>
<li>HDFS 文件系统拷贝（底层操作）</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 语法：从源路径拷贝到目标路径</span></span><br><span class="line">hadoop fs -<span class="built_in">cp</span> source_path target_path;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例：将HDFS上的表数据拷贝到新目录</span></span><br><span class="line">hadoop fs -<span class="built_in">cp</span> /user/hive/warehouse/stu/ /user/hive/backup/stu_backup;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例：将本地文件拷贝到HDFS</span></span><br><span class="line">hadoop fs -<span class="built_in">cp</span> file:///usr/local/data/stu.txt /user/hive/input/;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>source_path</code>：支持 HDFS 路径（<code>hdfs://</code>）或本地路径（<code>file://</code>）</li>
<li><code>target_path</code>：目标路径不能已存在（如需覆盖，需先删除）</li>
<li>该操作直接操作底层文件系统，不通过 Hive 元数据</li>
</ul>
<ol start="2">
<li>HiveQL 导出到本地文件（SQL 方式）</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 语法：覆盖模式导出到本地目录</span></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">local</span> directory <span class="string">&#x27;/usr/local/hadoop/tmp/stu&#x27;</span></span><br><span class="line"><span class="keyword">select</span> id, name <span class="keyword">from</span> stu;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 示例：带格式导出（字段以逗号分隔）</span></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">local</span> directory <span class="string">&#x27;/tmp/export&#x27;</span></span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> sales;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 示例：导出为Parquet格式</span></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">local</span> directory <span class="string">&#x27;/tmp/parquet_export&#x27;</span></span><br><span class="line">stored <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">user</span>;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>local</code>关键字表示导出到本地文件系统，省略则导出到 HDFS</li>
<li><code>row format</code>可指定字段分隔符、集合分隔符等格式</li>
<li>导出目录会自动生成多个分区文件（如<code>part-00000</code>）</li>
<li>覆盖模式（<code>overwrite</code>）会删除原有目录数据</li>
</ul>
<h5 id="3-HiveQL-导出到-HDFS（生产常用）">3. HiveQL 导出到 HDFS（生产常用）</h5>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 导出到HDFS指定路径（追加模式）</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> directory <span class="string">&#x27;/hdfs/export/stu&#x27;</span></span><br><span class="line"><span class="keyword">select</span> id, name <span class="keyword">from</span> stu;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 导出时指定存储格式</span></span><br><span class="line"><span class="keyword">insert</span> overwrite directory <span class="string">&#x27;/hdfs/export/stu_orc&#x27;</span></span><br><span class="line">stored <span class="keyword">as</span> orc</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> stu;</span><br></pre></td></tr></table></figure>
<p><strong>应用场景</strong>：</p>
<ul>
<li>数据归档：将 Hive 表数据备份到 HDFS 长期存储</li>
<li>跨系统数据共享：导出为 Parquet/ORC 格式供其他系统使用</li>
<li>ETL 流程：导出中间结果供后续处理</li>
</ul>
<p>二、查询操作扩展</p>
<ol>
<li>CASE WHEN THEN 条件表达式</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 语法格式</span></span><br><span class="line"><span class="keyword">select</span> id, name,</span><br><span class="line">  <span class="keyword">case</span></span><br><span class="line">    <span class="keyword">when</span> id <span class="operator">=</span> <span class="number">1</span> <span class="keyword">then</span> <span class="string">&#x27;first&#x27;</span></span><br><span class="line">    <span class="keyword">when</span> id <span class="operator">=</span> <span class="number">2</span> <span class="keyword">then</span> <span class="string">&#x27;second&#x27;</span></span><br><span class="line">    <span class="keyword">else</span> <span class="string">&#x27;third&#x27;</span></span><br><span class="line">  <span class="keyword">end</span> <span class="keyword">as</span> rank</span><br><span class="line"><span class="keyword">from</span> stu;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 示例：成绩等级划分</span></span><br><span class="line"><span class="keyword">select</span> student_id, score,</span><br><span class="line">  <span class="keyword">case</span></span><br><span class="line">    <span class="keyword">when</span> score <span class="operator">&gt;=</span> <span class="number">90</span> <span class="keyword">then</span> <span class="string">&#x27;A&#x27;</span></span><br><span class="line">    <span class="keyword">when</span> score <span class="operator">&gt;=</span> <span class="number">80</span> <span class="keyword">then</span> <span class="string">&#x27;B&#x27;</span></span><br><span class="line">    <span class="keyword">when</span> score <span class="operator">&gt;=</span> <span class="number">70</span> <span class="keyword">then</span> <span class="string">&#x27;C&#x27;</span></span><br><span class="line">    <span class="keyword">else</span> <span class="string">&#x27;D&#x27;</span></span><br><span class="line">  <span class="keyword">end</span> <span class="keyword">as</span> grade</span><br><span class="line"><span class="keyword">from</span> exam_scores;</span><br></pre></td></tr></table></figure>
<ul>
<li>类似 SQL 中的 IF 函数，用于字段值转换</li>
<li>可嵌套多层条件，处理复杂逻辑</li>
<li>最终生成一个新的计算列</li>
</ul>
<ol start="2">
<li>表连接（JOIN）操作<br>
a. 内连接（INNER JOIN）【重点】</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 语法：查询两表匹配的行</span></span><br><span class="line"><span class="keyword">select</span> stu.<span class="operator">*</span>, course.<span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> stu <span class="keyword">join</span> course <span class="keyword">on</span>(stu.id <span class="operator">=</span> course.sid);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 示例：查询有选课记录的学生</span></span><br><span class="line"><span class="keyword">select</span> s.name, c.course_name</span><br><span class="line"><span class="keyword">from</span> student s <span class="keyword">join</span> course_selection c <span class="keyword">on</span>(s.id <span class="operator">=</span> c.student_id);</span><br></pre></td></tr></table></figure>
<ul>
<li>仅返回两表在连接条件上匹配的行</li>
<li>等价于<code>select ... from stu, course where stu.id = course.sid;</code></li>
</ul>
<p>b. 左连接（LEFT JOIN）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 语法：返回左表所有行，右表匹配行</span></span><br><span class="line"><span class="keyword">select</span> stu.<span class="operator">*</span>, course.<span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> stu <span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">join</span> course <span class="keyword">on</span>(stu.id <span class="operator">=</span> course.sid);</span><br></pre></td></tr></table></figure>
<ul>
<li>左表（stu）的所有行都会保留</li>
<li>右表（course）仅返回匹配的行，未匹配行设为 NULL</li>
<li>常用于查询 “所有用户及其订单” 场景</li>
</ul>
<p>c. 右连接（RIGHT JOIN）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 语法：返回右表所有行，左表匹配行</span></span><br><span class="line"><span class="keyword">select</span> stu.<span class="operator">*</span>, course.<span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> stu <span class="keyword">right</span> <span class="keyword">outer</span> <span class="keyword">join</span> course <span class="keyword">on</span>(stu.id <span class="operator">=</span> course.sid);</span><br></pre></td></tr></table></figure>
<ul>
<li>右表（course）的所有行都会保留</li>
<li>左表（stu）仅返回匹配的行，未匹配行设为 NULL</li>
<li>常用于查询 “所有订单及其用户” 场景</li>
</ul>
<p>d. 全连接（FULL JOIN）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 语法：返回两表所有行，未匹配行设为NULL</span></span><br><span class="line"><span class="keyword">select</span> stu.<span class="operator">*</span>, course.<span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> stu <span class="keyword">full</span> <span class="keyword">outer</span> <span class="keyword">join</span> course <span class="keyword">on</span>(stu.id <span class="operator">=</span> course.sid);</span><br></pre></td></tr></table></figure>
<ul>
<li>合并左表和右表的所有行</li>
<li>两表未匹配的行对应列设为 NULL</li>
<li>Hive 0.14.0 + 支持该操作</li>
</ul>
<p>e. 半连接（LEFT SEMI JOIN）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 语法：Hive特有的连接，等价于子查询中的IN</span></span><br><span class="line"><span class="keyword">select</span> stu.<span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> stu <span class="keyword">left</span> semi <span class="keyword">join</span> course <span class="keyword">on</span>(stu.id <span class="operator">=</span> course.sid);</span><br></pre></td></tr></table></figure>
<ul>
<li>仅返回左表在右表中存在匹配的行</li>
<li>比 IN 子查询效率更高</li>
<li>右表不能出现在 SELECT 列中</li>
</ul>
<p>三、子查询限制与实践</p>
<ol>
<li>HiveQL 子查询规则</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 合法子查询：在FROM子句中使用</span></span><br><span class="line"><span class="keyword">select</span> id, name</span><br><span class="line"><span class="keyword">from</span> (<span class="keyword">select</span> id, name <span class="keyword">from</span> stu <span class="keyword">where</span> id <span class="operator">&gt;</span> <span class="number">10</span>) t;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 非法子查询：在WHERE子句中使用IN</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> stu <span class="keyword">where</span> id <span class="keyword">in</span> (<span class="keyword">select</span> sid <span class="keyword">from</span> course);</span><br><span class="line"><span class="comment">-- 需改为LEFT SEMI JOIN</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 推荐写法：用LEFT SEMI JOIN替代IN子查询</span></span><br><span class="line"><span class="keyword">select</span> s.<span class="operator">*</span> <span class="keyword">from</span> stu s <span class="keyword">left</span> semi <span class="keyword">join</span> course c <span class="keyword">on</span>(s.id <span class="operator">=</span> c.sid);</span><br></pre></td></tr></table></figure>
<p><strong>限制说明</strong>：</p>
<ul>
<li>仅支持<code>FROM子句中的子查询</code>（又称派生表）</li>
<li>不支持<code>WHERE子句中的IN/EXISTS子查询</code></li>
<li>子查询中不能使用 ORDER BY（可在外部使用）</li>
</ul>
<ol start="2">
<li>子查询优化示例</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 需求：查询各班级最高分的学生</span></span><br><span class="line"><span class="keyword">select</span> t.class, t.name, t.score</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">  <span class="keyword">select</span> class, name, score,</span><br><span class="line">    <span class="built_in">rank</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> class <span class="keyword">order</span> <span class="keyword">by</span> score <span class="keyword">desc</span>) <span class="keyword">as</span> rk</span><br><span class="line">  <span class="keyword">from</span> student_scores</span><br><span class="line">) t <span class="keyword">where</span> t.rk <span class="operator">=</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure><div class="main-hero-waves-area"><div class="waves-area"><svg class="waves-svg" version="1.1" xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 1440 140" preserveAspectRatio="none"><path class="parallax" d="M 0 44 C 355 167 415 0 725 44 L 725 44 L 0 44 Z"></path><use class="parallax" xlink:href="#wave1" x="48" y="3"></use><use class="parallax" xlink:href="#wave1" x="48" y="5"></use><use class="parallax" xlink:href="#wave1" x="48" y="7"></use><use class="parallax" xlink:href="#wave1" x="48" y="9"></use></svg></div></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://labi.com">Lorinda</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://labi.com/post/1b6b2911.html">http://labi.com/post/1b6b2911.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://labi.com" target="_blank">蜡笔梦工厂</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/NoSQL/">NoSQL</a><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a><a class="post-meta__tags" href="/tags/HDFS/">HDFS</a><a class="post-meta__tags" href="/tags/MapReduce/">MapReduce</a><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><a class="post-meta__tags" href="/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/">云计算</a><a class="post-meta__tags" href="/tags/%E7%89%A9%E8%81%94%E7%BD%91/">物联网</a><a class="post-meta__tags" href="/tags/HBase/">HBase</a></div><div class="post-share"><div class="social-share" data-image="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112844.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://lib.baomitu.com/social-share.js/1.0.16/css/share.min.css" media="print" onload="this.media='all'"><script src="https://lib.baomitu.com/social-share.js/1.0.16/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/post/9ca97f19.html" title="Linux基础知识总结"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2024_1123_160146.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Linux基础知识总结</div></div><div class="info-2"><div class="info-item-1">本文详细总结了Linux的基础知识，包括主要发行版、文件系统结构、常用命令（ls、cd、mkdir等）、用户与权限管理、Shell脚本及系统配置等核心内容，适合Linux初学者入门学习。</div></div></div></a><a class="pagination-related" href="/post/1595973a.html" title="大数据Hadoop实操全流程总结"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112650.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">大数据Hadoop实操全流程总结</div></div><div class="info-2"><div class="info-item-1">本文详细总结大数据Hadoop生态实操全流程，包括Ubuntu虚拟机克隆与固定IP配置、SSH免密登录设置、HDFS集群部署与Shell操作（文件增删改查、权限管理）、YARN集群配置与启停、MapReduce任务提交（单词统计、圆周率计算）及Hive查询分析等核心实操内容，附带命令示例与配置代码，适合大数据初学者上手实践。</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/post/1595973a.html" title="大数据Hadoop实操全流程总结"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112650.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-05-24</div><div class="info-item-2">大数据Hadoop实操全流程总结</div></div><div class="info-2"><div class="info-item-1">本文详细总结大数据Hadoop生态实操全流程，包括Ubuntu虚拟机克隆与固定IP配置、SSH免密登录设置、HDFS集群部署与Shell操作（文件增删改查、权限管理）、YARN集群配置与启停、MapReduce任务提交（单词统计、圆周率计算）及Hive查询分析等核心实操内容，附带命令示例与配置代码，适合大数据初学者上手实践。</div></div></div></a><a class="pagination-related" href="/post/bae4ff13.html" title="Redis"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2024_1123_160146.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-12</div><div class="info-item-2">Redis</div></div><div class="info-2"><div class="info-item-1">Redis 作为内存 NoSQL 数据库的定位，支持 String/Hash 等多数据结构，具备 RDB/AOF 持久化与主从高可用，核心用于缓存、分布式锁，性能高效。</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="card-info-avatar"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2024_1123_155535.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-status-box"><div class="author-status"><g-emoji class="g-emoji" alias="palm_tree" fallback-src="https://lskypro.acozycotage.net/LightPicture/2022/12/fe1dc0402e623096.jpg">🐟</g-emoji><span>认真摸鱼中</span></div></div></div><div class="author-info-name">Lorinda</div><div class="author-info-description">欢迎来到Lorinda的个人博客\^o^/</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">29</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">109</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://lr0513.github.io/"><i class="fab fa-github"></i><span>你回来了~</span><i class="faa-passing animated" style="padding-left:20px;display:inline-block;vertical-align:middle;"><svg class="icon" style="height:28px;width:28px;fill:currentColor;position:relative;top:5px"><use xlink:href="#icon-hexolabixiaoxin1"></use></svg></i></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content"></div><div id="welcome-info"></div></div><div class="xpand" style="height:200px;"><canvas class="illo" width="800" height="800" style="max-width: 200px; max-height: 200px; touch-action: none; width: 640px; height: 640px;"></canvas></div><script src="https://npm.elemecdn.com/ethan4116-blog/lib/js/other/two-people/twopeople1.js"></script><script src="https://npm.elemecdn.com/ethan4116-blog/lib/js/other/two-people/zdog.dist.js"></script><script id="rendered-js" src="https://npm.elemecdn.com/ethan4116-blog/lib/js/other/two-people/twopeople.js"></script><style>.card-widget.card-announcement {
margin: 0;
align-items: center;
justify-content: center;
text-align: center;
}
canvas {
display: block;
margin: 0 auto;
cursor: move;
}</style><div class="card-widget" id="newYear"><div class="item-headline"><i></i><span></span></div><div class="item-content"><div id="newYear-main"><div class="mask"></div> <p class="title"></p> <div class="newYear-time"></div> <p class="today" style="text-align: right;"></p> </div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#font-color-ff0000-RDD%E4%B9%8B%E9%97%B4%E7%9A%84%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB-font"><span class="toc-number">1.</span> <span class="toc-text">RDD之间的依赖关系</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#font-color-ff0000-%E9%98%B6%E6%AE%B5%E7%9A%84%E5%88%92%E5%88%86-font"><span class="toc-number">2.</span> <span class="toc-text">阶段的划分</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number"></span> <span class="toc-text">基本概念</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%A0%E7%BB%9F%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%9E%B6%E6%9E%84"><span class="toc-number"></span> <span class="toc-text">传统的数据处理架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9C%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%83%8C%E6%99%AF%E4%B8%8B%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%9A"><span class="toc-number"></span> <span class="toc-text">在大数据背景下存在的问题：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84%E7%89%B9%E5%BE%81"><span class="toc-number"></span> <span class="toc-text">大数据的特征</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84%E6%A0%B8%E5%BF%83%E5%B7%A5%E4%BD%9C"><span class="toc-number"></span> <span class="toc-text">大数据的核心工作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8"><span class="toc-number">1.</span> <span class="toc-text">为什么需要分布式存储</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number"></span> <span class="toc-text">大数据应用场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%8F%91%E5%B1%95%E9%98%B6%E6%AE%B5"><span class="toc-number"></span> <span class="toc-text">大数据发展阶段</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%BD%AF%E4%BB%B6%E7%94%9F%E6%80%81"><span class="toc-number"></span> <span class="toc-text">大数据软件生态</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6"><span class="toc-number">1.</span> <span class="toc-text">常见的大数据技术框架</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6"><span class="toc-number">1.1.</span> <span class="toc-text">一、数据存储与计算框架</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E5%AD%98%E5%82%A8"><span class="toc-number">1.2.</span> <span class="toc-text">二、分布式数据库与存储</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%9F%A5%E8%AF%A2%E5%BC%95%E6%93%8E"><span class="toc-number">1.3.</span> <span class="toc-text">三、数据仓库与查询引擎</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%8E%E6%B5%81%E6%95%B0%E6%8D%AE%E9%9B%86%E6%88%90"><span class="toc-number">1.4.</span> <span class="toc-text">四、消息队列与流数据集成</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E8%B5%84%E6%BA%90%E8%B0%83%E5%BA%A6%E4%B8%8E%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86"><span class="toc-number">1.5.</span> <span class="toc-text">五、资源调度与集群管理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.6.</span> <span class="toc-text">六、数据挖掘与机器学习</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%83%E3%80%81%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%B8%8EBI%E5%B7%A5%E5%85%B7"><span class="toc-number">1.7.</span> <span class="toc-text">七、数据可视化与BI工具</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AD%98%E5%82%A8%E3%80%81%E8%AE%A1%E7%AE%97%E4%B8%8E%E4%BC%A0%E8%BE%93%E7%9A%84%E5%8D%8F%E5%90%8C%E6%9E%B6%E6%9E%84"><span class="toc-number">1.8.</span> <span class="toc-text">存储、计算与传输的协同架构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%B0%E5%85%B4%E8%B6%8B%E5%8A%BF%E4%B8%8E%E9%80%89%E5%9E%8B%E5%BB%BA%E8%AE%AE"><span class="toc-number">1.9.</span> <span class="toc-text">新兴趋势与选型建议</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B"><span class="toc-number">2.</span> <span class="toc-text">大数据处理流程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%84%E5%BB%BA%E6%B5%81%E7%A8%8B"><span class="toc-number">2.1.</span> <span class="toc-text">1. 数据仓库构建流程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E6%B5%81%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B"><span class="toc-number">2.2.</span> <span class="toc-text">2. 流处理流程</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number"></span> <span class="toc-text">Hadoop</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%EF%BC%88%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">HDFS（数据存储）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%B6%E6%9E%84"><span class="toc-number">1.</span> <span class="toc-text">架构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E9%87%87%E7%94%A8%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84%EF%BC%8C%E4%B8%BB%E8%A6%81%E7%94%B1NameNode%E3%80%81DataNode%E5%92%8CStandby-NameNode%E7%BB%84%E6%88%90%E3%80%82image-png-450%E4%B8%BB%E4%BB%8E%EF%BC%88Master-Slave%EF%BC%89%E5%8A%A0%E4%B8%BB%E5%A4%87%EF%BC%88Active-Standby%EF%BC%89%E6%9E%B6%E6%9E%84%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E5%9B%BEimage-6"><span class="toc-number"></span> <span class="toc-text">HDFS采用主从架构，主要由NameNode、DataNode和Standby NameNode组成。

主从（Master&#x2F;Slave）加主备（Active&#x2F;Standby）架构的系统架构图
</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%A0%B8%E5%BF%83%E8%A7%92%E8%89%B2"><span class="toc-number">0.1.</span> <span class="toc-text">一、核心角色</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E7%BB%84%E4%BB%B6%E9%97%B4%E5%85%B3%E7%B3%BB"><span class="toc-number">0.2.</span> <span class="toc-text">二、组件间关系</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E4%B8%8E%E7%AE%A1%E7%90%86"><span class="toc-number">0.3.</span> <span class="toc-text">三、数据传输与管理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B"><span class="toc-number">0.4.</span> <span class="toc-text">四、架构演进</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E6%93%8D%E4%BD%9C%E5%BB%BA%E8%AE%AE"><span class="toc-number">0.5.</span> <span class="toc-text">五、操作建议</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8Block"><span class="toc-number">1.</span> <span class="toc-text">数据存储Block</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Block%E6%96%87%E4%BB%B6%E7%9A%84%E5%AD%98%E5%82%A8%E5%92%8C%E5%85%83%E6%95%B0%E6%8D%AE"><span class="toc-number">2.</span> <span class="toc-text">Block文件的存储和元数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%83%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8"><span class="toc-number">3.</span> <span class="toc-text">元数据存储</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E5%85%83%E6%95%B0%E6%8D%AE"><span class="toc-number">4.</span> <span class="toc-text">内存元数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%87%E4%BB%B6%E5%85%83%E6%95%B0%E6%8D%AE"><span class="toc-number">5.</span> <span class="toc-text">文件元数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#edits-%E5%AE%9A%E6%9C%9F%E5%90%88%E5%B9%B6%E5%88%B0-fsimage-%E7%9A%84%E8%BF%87%E7%A8%8B"><span class="toc-number">6.</span> <span class="toc-text">edits 定期合并到 fsimage 的过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%80%A7%E8%83%BD%E4%B8%8E%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1"><span class="toc-number">7.</span> <span class="toc-text">4. 性能与负载均衡</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B"><span class="toc-number">8.</span> <span class="toc-text">读写流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E5%85%A8%E6%A8%A1%E5%BC%8F"><span class="toc-number">9.</span> <span class="toc-text">安全模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AB%98%E5%8F%AF%E7%94%A8%EF%BC%88HA%EF%BC%89"><span class="toc-number">10.</span> <span class="toc-text">高可用（HA）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95"><span class="toc-number">11.</span> <span class="toc-text">基本用法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86"><span class="toc-number">12.</span> <span class="toc-text">运维管理</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number"></span> <span class="toc-text">Yarn（分布式资源管理系统）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84"><span class="toc-number"></span> <span class="toc-text">基本架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#YARN-%E7%9A%84%E8%BE%85%E5%8A%A9%E8%A7%92%E8%89%B2"><span class="toc-number"></span> <span class="toc-text">YARN 的辅助角色</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E5%8F%AF%E7%94%A8"><span class="toc-number"></span> <span class="toc-text">高可用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5"><span class="toc-number"></span> <span class="toc-text">调度策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%90%E7%BB%B4%E5%92%8C%E7%9B%91%E6%8E%A7"><span class="toc-number"></span> <span class="toc-text">运维和监控</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number"></span> <span class="toc-text">MapReduce</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1%E5%8E%9F%E7%90%86"><span class="toc-number"></span> <span class="toc-text">MapReduce词频统计原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86"><span class="toc-number"></span> <span class="toc-text">MapReduce运行原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A%E6%8F%90%E4%BA%A4%E3%80%81%E7%9B%91%E6%8E%A7%E4%B8%8E%E8%AF%8A%E6%96%AD"><span class="toc-number"></span> <span class="toc-text">作业提交、监控与诊断</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number"></span> <span class="toc-text">Spark</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81-Spark%EF%BC%9F"><span class="toc-number"></span> <span class="toc-text">一、为什么需要 Spark？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81Spark-%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6"><span class="toc-number"></span> <span class="toc-text">二、Spark 核心组件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81Spark-%E7%9A%84%E5%9B%9B%E5%A4%A7%E4%BC%98%E5%8A%BF"><span class="toc-number"></span> <span class="toc-text">三、Spark 的四大优势</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81Spark-%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="toc-number"></span> <span class="toc-text">四、Spark 运行模式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81Spark-vs-MapReduce-%E5%9C%BA%E6%99%AF%E5%AF%B9%E6%AF%94"><span class="toc-number"></span> <span class="toc-text">五、Spark vs MapReduce 场景对比</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SparkRDD%E4%B8%8E%E7%BC%96%E7%A8%8B%E6%A1%86%E6%9E%B6"><span class="toc-number"></span> <span class="toc-text">SparkRDD与编程框架</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81RDD-%E6%93%8D%E4%BD%9C%E7%B1%BB%E5%9E%8B"><span class="toc-number"></span> <span class="toc-text">二、RDD 操作类型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81RDD-%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB"><span class="toc-number"></span> <span class="toc-text">三、RDD 依赖关系</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81RDD-%E6%8C%81%E4%B9%85%E5%8C%96"><span class="toc-number"></span> <span class="toc-text">四、RDD 持久化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81RDD-%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number"></span> <span class="toc-text">五、RDD 的优缺点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MR-VS-RDD"><span class="toc-number"></span> <span class="toc-text">MR VS RDD</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark%E7%A8%8B%E5%BA%8F%E8%BF%90%E8%A1%8C%E6%9E%B6%E6%9E%84"><span class="toc-number"></span> <span class="toc-text">Spark程序运行架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark%E4%BD%9C%E4%B8%9A%E6%8F%90%E4%BA%A4%E6%A8%A1%E5%BC%8F"><span class="toc-number"></span> <span class="toc-text">Spark作业提交模式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark-%E4%BD%9C%E4%B8%9A%E8%A7%A3%E6%9E%90%E4%B8%8E%E7%9B%91%E6%8E%A7"><span class="toc-number"></span> <span class="toc-text">Spark 作业解析与监控</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#YARN-VS-Spark"><span class="toc-number"></span> <span class="toc-text">YARN VS Spark</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number"></span> <span class="toc-text">Hive</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive%E7%9A%84%E4%B8%BB%E8%A6%81%E5%8A%9F%E8%83%BD"><span class="toc-number"></span> <span class="toc-text">Hive的主要功能</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8-Hive%EF%BC%9F"><span class="toc-number"></span> <span class="toc-text">为什么使用 Hive？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-Hive-%E7%9A%84%E5%A5%BD%E5%A4%84"><span class="toc-number"></span> <span class="toc-text">使用 Hive 的好处</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive-%E6%9E%B6%E6%9E%84"><span class="toc-number"></span> <span class="toc-text">Hive 架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84"><span class="toc-number"></span> <span class="toc-text">Hive基础架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive%E9%83%A8%E7%BD%B2"><span class="toc-number"></span> <span class="toc-text">Hive部署</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive%E5%88%9D%E4%BD%93%E9%AA%8C"><span class="toc-number"></span> <span class="toc-text">Hive初体验</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive%E5%AE%A2%E6%88%B7%E7%AB%AF"><span class="toc-number"></span> <span class="toc-text">Hive客户端</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#HiveQL-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E6%95%B4%E7%90%86%E4%B8%8E%E6%B3%A8%E9%87%8A"><span class="toc-number">1.</span> <span class="toc-text">HiveQL 常用操作整理与注释</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E3%80%81Hive-%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.1.</span> <span class="toc-text">一、Hive 基本数据类型</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.1.1.</span> <span class="toc-text">1. 基本数据类型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E5%A4%8D%E6%9D%82%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.1.2.</span> <span class="toc-text">2. 复杂数据类型</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E6%95%B0%E6%8D%AE%E5%AE%9A%E4%B9%89%E6%93%8D%E4%BD%9C%EF%BC%88DDL%EF%BC%89"><span class="toc-number">1.2.</span> <span class="toc-text">二、数据定义操作（DDL）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C"><span class="toc-number">1.2.1.</span> <span class="toc-text">1. 数据库操作</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E8%A1%A8%E6%93%8D%E4%BD%9C"><span class="toc-number">1.2.2.</span> <span class="toc-text">2. 表操作</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%EF%BC%88DML%EF%BC%89"><span class="toc-number">1.3.</span> <span class="toc-text">三、数据操作（DML）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E8%A1%A8%E5%88%9B%E5%BB%BA%E4%B8%8E%E6%95%B0%E6%8D%AE%E8%A3%85%E8%BD%BD"><span class="toc-number">1.3.1.</span> <span class="toc-text">1. 表创建与数据装载</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-HiveQL-%E5%AF%BC%E5%87%BA%E5%88%B0-HDFS%EF%BC%88%E7%94%9F%E4%BA%A7%E5%B8%B8%E7%94%A8%EF%BC%89"><span class="toc-number">1.3.2.</span> <span class="toc-text">3. HiveQL 导出到 HDFS（生产常用）</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/post/reggie-deployment.html" title="瑞吉外卖：Linux环境与自动化部署"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112618.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="瑞吉外卖：Linux环境与自动化部署"/></a><div class="content"><a class="title" href="/post/reggie-deployment.html" title="瑞吉外卖：Linux环境与自动化部署">瑞吉外卖：Linux环境与自动化部署</a><time datetime="2025-09-02T02:04:00.000Z" title="发表于 2025-09-02 10:04:00">2025-09-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/reggie-optimization.html" title="瑞吉外卖：性能优化与架构升级"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112938.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="瑞吉外卖：性能优化与架构升级"/></a><div class="content"><a class="title" href="/post/reggie-optimization.html" title="瑞吉外卖：性能优化与架构升级">瑞吉外卖：性能优化与架构升级</a><time datetime="2025-09-02T02:03:00.000Z" title="发表于 2025-09-02 10:03:00">2025-09-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/reggie-business.html" title="瑞吉外卖：核心业务功能开发"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2024_1123_160146.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="瑞吉外卖：核心业务功能开发"/></a><div class="content"><a class="title" href="/post/reggie-business.html" title="瑞吉外卖：核心业务功能开发">瑞吉外卖：核心业务功能开发</a><time datetime="2025-09-02T02:01:00.000Z" title="发表于 2025-09-02 10:01:00">2025-09-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/reggie-business.html" title="瑞吉外卖：核心业务功能开发"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2024_1123_160146.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="瑞吉外卖：核心业务功能开发"/></a><div class="content"><a class="title" href="/post/reggie-business.html" title="瑞吉外卖：核心业务功能开发">瑞吉外卖：核心业务功能开发</a><time datetime="2025-09-02T02:01:00.000Z" title="发表于 2025-09-02 10:01:00">2025-09-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/reggie-overview.html" title="瑞吉外卖：项目概述与整体架构"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2024_1123_160146.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="瑞吉外卖：项目概述与整体架构"/></a><div class="content"><a class="title" href="/post/reggie-overview.html" title="瑞吉外卖：项目概述与整体架构">瑞吉外卖：项目概述与整体架构</a><time datetime="2025-09-02T02:00:00.000Z" title="发表于 2025-09-02 10:00:00">2025-09-02</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2024 - 2025  <i id="heartbeat" class="fa fas fa-heartbeat"></i> By Lorinda</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">I wish you to become your own sun, no need to rely on who's light.<p><a target="_blank" href="https://hexo.io/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo" title="博客框架为Hexo"></a>&nbsp;<a target="_blank" href="https://butterfly.js.org/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender" title="主题采用butterfly"></a>&nbsp;<a target="_blank" href="https://www.jsdelivr.com/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr" title="本站使用JsDelivr为静态资源提供CDN加速"></a> &nbsp;<a target="_blank" href="https://vercel.com/ "><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Vervel-brightgreen?style=flat&logo=Vercel" title="本站采用双线部署，默认线路托管于Vercel"></a>&nbsp;<a target="_blank" href="https://vercel.com/ "><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Coding-0cedbe?style=flat&logo=Codio" title="本站采用双线部署，联通线路托管于Coding"></a>&nbsp;<a target="_blank" href="https://github.com/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub" title="本站项目由Gtihub托管"></a>&nbsp;<a target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></p></div></div><div class="js-pjax" id="rightMenu"><div class="rightMenu-group rightMenu-small"><a class="rightMenu-item" href="javascript:window.history.back();"><i class="fa fa-arrow-left"></i></a><a class="rightMenu-item" href="javascript:window.history.forward();"><i class="fa fa-arrow-right"></i></a><a class="rightMenu-item" href="javascript:window.location.reload();"><i class="fa fa-refresh"></i></a><a class="rightMenu-item" href="javascript:rmf.scrollToTop();"><i class="fa fa-arrow-up"></i></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:rmf.copySelect();"><i class="fa fa-copy"></i><span>复制</span></a><a class="rightMenu-item" href="javascript:window.open(&quot;https://www.baidu.com/s?wd=&quot;+window.getSelection().toString());window.location.reload();"><i class="fa fa-search"></i><span>百度搜索</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-too"><a class="rightMenu-item" href="javascript:window.open(window.getSelection().toString());window.location.reload();"><i class="fa fa-link"></i><span>转到链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-paste"><a class="rightMenu-item" href="javascript:rmf.paste()"><i class="fa fa-copy"></i><span>粘贴</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-post"><a class="rightMenu-item" href="javascript:rmf.copyWordsLink()"><i class="fa fa-link"></i><span>复制本文地址</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-to"><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()"><i class="fa fa-window-restore"></i><span>新窗口打开</span></a><a class="rightMenu-item" id="menu-too" href="javascript:rmf.open()"><i class="fa fa-link"></i><span>转到链接</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()"><i class="fa fa-copy"></i><span>复制链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-img"><a class="rightMenu-item" href="javascript:rmf.saveAs()"><i class="fa fa-download"></i><span>保存图片</span></a><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()"><i class="fa fa-window-restore"></i><span>在新窗口打开</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()"><i class="fa fa-copy"></i><span>复制图片链接</span></a></div><div class="rightMenu-group rightMenu-line"><a class="rightMenu-item" href="javascript:randomPost()"><i class="fa fa-paper-plane"></i><span>随便逛逛</span></a><a class="rightMenu-item" href="javascript:switchNightMode();"><i class="fa fa-moon"></i><span>昼夜切换</span></a><a class="rightMenu-item" href="javascript:rmf.switchReadMode();"><i class="fa fa-book"></i><span>阅读模式</span></a><a class="rightMenu-item" href="/about/"><i class="fa fa-info-circle"></i><span>关于博客</span></a><a class="rightMenu-item" href="javascript:rmf.fullScreen();"><i class="fas fa-expand"></i><span>切换全屏</span></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><a class="icon-V hidden" onclick="switchNightMode()" title="日间和夜间模式切换"><svg width="25" height="25" viewBox="0 0 1024 1024"><use id="modeicon" xlink:href="#icon-moon"></use></svg></a><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="to_comment" type="button" title="前往评论" onclick="FixedCommentBtn();"><i class="fas fa-comments"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i><span id="percent">0<span>%</span></span></button><button id="go-down" type="button" title="直达底部" onclick="btf.scrollToDest(document.body.scrollHeight, 500)"><i class="fas fa-arrow-down"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.36/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@5.1.0/instantpage.min.js" type="module"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/19.1.3/lazyload.iife.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/node-snackbar/0.1.16/snackbar.min.js"></script><script>(() => {
  const panguFn = () => {
    if (typeof pangu === 'object') pangu.autoSpacingPage()
    else {
      btf.getScript('https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js')
        .then(() => {
          pangu.autoSpacingPage()
        })
    }
  }

  const panguInit = () => {
    if (false){
      GLOBAL_CONFIG_SITE.isPost && panguFn()
    } else {
      panguFn()
    }
  }

  btf.addGlobalFn('pjaxComplete', panguInit, 'pangu')
  document.addEventListener('DOMContentLoaded', panguInit)
})()</script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.4.0/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.isShuoshuo
  const option = null

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo-api-three-beta.vercel.app/',
      region: 'ap-beijing',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const init = (el = document, path = location.pathname) => {
    twikoo.init({
      el: el.querySelector('#twikoo-wrap'),
      envId: 'https://twikoo-api-three-beta.vercel.app/',
      region: 'ap-beijing',
      onCommentLoaded: () => {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      },
      ...option,
      path: isShuoshuo ? path : (option && option.path) || path
    })

    

    isShuoshuo && (window.shuoshuoComment.destroyTwikoo = () => {
      if (el.children.length) {
        el.innerHTML = ''
        el.classList.add('no-comment')
      }
    })
  }

  const loadTwikoo = (el, path) => {
    if (typeof twikoo === 'object') setTimeout(() => init(el, path), 0)
    else btf.getScript('https://cdn.staticfile.org/twikoo/1.6.8/twikoo.all.min.js').then(() => init(el, path))
  }

  if (isShuoshuo) {
    'Twikoo' === 'Twikoo'
      ? window.shuoshuoComment = { loadComment: loadTwikoo }
      : window.loadOtherComment = loadTwikoo
    return
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script></div><script async src="//at.alicdn.com/t/c/font_4860073_9duzoqyl2cn.js"></script><script defer data-pjax src="/js/readPercent.js"></script><script src="/js/pagination-jump.js"></script><script async src="/js/fps.js"></script><script async data-pjax src="/js/txmap.js"></script><script defer type="text/javascript" src="https://cdn1.tianli0.top/npm/sweetalert2@8.19.0/dist/sweetalert2.all.js"></script><script async data-pjax src="/js/music.js"></script><script defer src="/js/lunar.js"></script><script async src="https://cdn1.tianli0.top/npm/vue@2.6.14/dist/vue.min.js"></script><script async src="https://cdn1.tianli0.top/npm/element-ui@2.15.6/lib/index.js"></script><script type="text/javascript" src="https://cdn1.tianli0.top/npm/jquery@latest/dist/jquery.min.js"></script><script> let backimg =["url(https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/d42bcc24810cda2c22eaed769b79a93.jpg)","url(https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/2f5e89ae13329dd89bdcdbfc68c5fde.jpg)","url(https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/48b137c38cc79ad960ecf2a9a12fc20.jpg)","url(https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/4474312751631fedb37381e37cdb9c0.jpg)","url(https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/be978bd80f41d2781455513ba1676a2.jpg)","url(https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/a01223e0819746191dd135670a2d7da.jpg)","url(https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/af380cb8a5ed3f047e66dbfe731f488.jpg)"];let index = Math.floor(Math.random() * backimg.length);;document.getElementById("web_bg").style.backgroundImage = backimg[index]</script><script type="text/javascript" src="/js/rightmenu.js"></script><script src="/js/history.js"></script><script src="/js/historyroll.js"></script><script async src="//at.alicdn.com/t/font_2264842_3izu8i5eoc2.js"></script><script defer src="/js/day.js"></script><script async src="/js/title.js"></script><script defer src="/js/random.js"></script><canvas id="universe"></canvas><script defer src="/js/universe.js"></script><script async src="//npm.elemecdn.com/pace-js@1.2.4/pace.min.js"></script><script src="/js/sun_moon.js" async></script><script>
  document.addEventListener('copy', function(e) {
    const selection = window.getSelection().toString()
    if (selection.length > 30) {
      const notice = document.createElement('div')
      notice.className = 'copy-notification'
      notice.textContent = '内容已复制到剪贴板'

      document.body.appendChild(notice)
      setTimeout(() => notice.classList.add('show'), 10)

      setTimeout(() => {
        notice.classList.remove('show')
        setTimeout(() => notice.remove(), 300)
      }, 2000)
    }
  })
</script>
<div class="aplayer no-destroy" data-id="7338633309" data-server="netease" data-type="playlist" data-fixed="true" data-mini="true" data-listFolded="false" data-order="random" data-lrctype="1" data-preload="none" data-autoplay="true" muted></div><script src="https://cdn.staticfile.org/jquery/3.6.3/jquery.min.js"></script><script async data-pjax src="https://cdn.wpon.cn/2022-sucai/Gold-ingot.js"></script><script async data-pjax src="/js/newYear.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="30" mobile="false" src="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.4/canvas-nest.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.4/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-show-text" src="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.4/click-show-text.min.js" data-mobile="false" data-text="Ha,Ha,Ha" data-fontsize="15px" data-random="false" async="async"></script><script>(() => {
  const isChatBtn = true
  const isChatHideShow = true

  if (isChatBtn) {
    const close = () => {
      Chatra('minimizeWidget')
      Chatra('hide')
    }

    const open = () => {
      Chatra('openChat', true)
      Chatra('show')
    }

    window.ChatraSetup = { startHidden: true }
  
    window.chatBtnFn = () => {
      document.getElementById('chatra').classList.contains('chatra--expanded') ? close() : open()
    }
  } else if (isChatHideShow) {
    window.chatBtn = {
      hide: () => Chatra('hide'),
      show: () => Chatra('show')
    }
  }

  (function(d, w, c) {
    w.ChatraID = 'E3NZpK6rk4cR7jmwK'
    var s = d.createElement('script')
    w[c] = w[c] || function() {
      (w[c].q = w[c].q || []).push(arguments)
    }
    s.async = true
    s.src = 'https://call.chatra.io/chatra.js'
    if (d.head) d.head.appendChild(s)
  })(document, window, 'Chatra')
})()</script><link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/aplayer/1.10.1/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/aplayer/1.10.1/APlayer.min.js"></script><script src="https://npm.elemecdn.com/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script>(() => {
  const destroyAplayer = () => {
    if (window.aplayers) {
      for (let i = 0; i < window.aplayers.length; i++) {
        if (!window.aplayers[i].options.fixed) {
          window.aplayers[i].destroy()
        }
      }
    }
  }

  const runMetingJS = () => {
    typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()
  }

  btf.addGlobalFn('pjaxSend', destroyAplayer, 'destroyAplayer')
  btf.addGlobalFn('pjaxComplete', loadMeting, 'runMetingJS')
})()</script><script src="https://lib.baomitu.com/pjax/0.2.8/pjax.min.js"></script><script>(() => {
  const pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

  window.pjax = new Pjax({
    elements: 'a:not([target="_blank"]):not([href="/music/"]):not([href="/no-pjax/"])',
    selectors: pjaxSelectors,
    cacheBust: false,
    analytics: false,
    scrollRestoration: false
  })

  const triggerPjaxFn = (val) => {
    if (!val) return
    Object.values(val).forEach(fn => fn())
  }

  document.addEventListener('pjax:send', () => {
    // removeEventListener
    btf.removeGlobalFnEvent('pjaxSendOnce')
    btf.removeGlobalFnEvent('themeChange')

    // reset readmode
    const $bodyClassList = document.body.classList
    if ($bodyClassList.contains('read-mode')) $bodyClassList.remove('read-mode')

    triggerPjaxFn(window.globalFn.pjaxSend)
  })

  document.addEventListener('pjax:complete', () => {
    btf.removeGlobalFnEvent('pjaxCompleteOnce')
    document.querySelectorAll('script[data-pjax]').forEach(item => {
      const newScript = document.createElement('script')
      const content = item.text || item.textContent || item.innerHTML || ""
      Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
      newScript.appendChild(document.createTextNode(content))
      item.parentNode.replaceChild(newScript, item)
    })

    triggerPjaxFn(window.globalFn.pjaxComplete)
  })

  document.addEventListener('pjax:error', e => {
    if (e.request.status === 404) {
      pjax.loadUrl('/404.html')
    }
  })
})()</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><!-- hexo injector body_end start --><script data-pjax>
    function butterfly_categories_card_injector_config(){
      var parent_div_git = document.getElementsByClassName('recent-posts')[0];
      var item_html = '<div class="recent-post-item" style="height:auto;width:100%;padding:0px;"><div id="categoryBar"><ul class="categoryBar-list"><li class="categoryBar-list-item" style="background:url(https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2024_1123_155818.png);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/操作系统/&quot;);" href="javascript:void(0);">操作系统</a><span class="categoryBar-list-count">6</span><span class="categoryBar-list-descr">java指南</span></li><li class="categoryBar-list-item" style="background:url(https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112813.png);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/技术栈/&quot;);" href="javascript:void(0);">技术栈</a><span class="categoryBar-list-count">1</span><span class="categoryBar-list-descr">java技术栈</span></li><li class="categoryBar-list-item" style="background:url(https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112758.png);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/编程语言/&quot;);" href="javascript:void(0);">编程语言</a><span class="categoryBar-list-count">2</span><span class="categoryBar-list-descr">计算机基础指南</span></li><li class="categoryBar-list-item" style="background:url(https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/4e357962b00044466380f6850a120ec.jpg);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/大数据技术-实操/&quot;);" href="javascript:void(0);">大数据技术-实操</a><span class="categoryBar-list-count">1</span><span class="categoryBar-list-descr">专业课</span></li><li class="categoryBar-list-item" style="background:url(undefined);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/大数据技术/&quot;);" href="javascript:void(0);">大数据技术</a><span class="categoryBar-list-count">1</span><span class="categoryBar-list-descr"></span></li><li class="categoryBar-list-item" style="background:url(undefined);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/瑞吉外卖项目/&quot;);" href="javascript:void(0);">瑞吉外卖项目</a><span class="categoryBar-list-count">5</span><span class="categoryBar-list-descr"></span></li><li class="categoryBar-list-item" style="background:url(undefined);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/计算机基础/&quot;);" href="javascript:void(0);">计算机基础</a><span class="categoryBar-list-count">2</span><span class="categoryBar-list-descr"></span></li><li class="categoryBar-list-item" style="background:url(undefined);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/苍穹外卖项目/&quot;);" href="javascript:void(0);">苍穹外卖项目</a><span class="categoryBar-list-count">4</span><span class="categoryBar-list-descr"></span></li><li class="categoryBar-list-item" style="background:url(undefined);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/计算机基础/专业课/&quot;);" href="javascript:void(0);">专业课</a><span class="categoryBar-list-count">1</span><span class="categoryBar-list-descr"></span></li><li class="categoryBar-list-item" style="background:url(undefined);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/计算机组成原理/&quot;);" href="javascript:void(0);">计算机组成原理</a><span class="categoryBar-list-count">7</span><span class="categoryBar-list-descr"></span></li></ul></div></div>';
      console.log('已挂载butterfly_categories_card')
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      }
    if( document.getElementsByClassName('recent-posts')[0] && (location.pathname ==='/'|| '/' ==='all')){
    butterfly_categories_card_injector_config()
    }
  </script><script data-pjax>
  function butterfly_clock_anzhiyu_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock_anzhiyu')
    if(parent_div_git) {
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var qweather_key = '9aac1b5db191491a8993c445d664de8f';
  var gaud_map_key = '3cc01a5a19f500daa0e9e680ef0f6db2';
  var baidu_ak_key = 'undefined';
  var flag = 0;
  var clock_rectangle = '120.780172,40.624088';
  var clock_default_rectangle_enable = 'false';

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_anzhiyu_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_anzhiyu_injector_config();
  }
  </script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.js"></script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '2s');
    arr[i].setAttribute('data-wow-delay', '1s');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/g86c4e7a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112938.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-08-29</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/g86c4e7a.html&quot;);" href="javascript:void(0);" alt="">第 7 章 计算机系统结构</a><div class="blog-slider__text">阐述计算机系统结构的基本概念，分析并行处理技术的实现方式，详解存储层次的优化策略，介绍系统性能的评价指标与方法。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/g86c4e7a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/f75b3d6f.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112650.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-08-29</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/f75b3d6f.html&quot;);" href="javascript:void(0);" alt="">第 6 章 输入输出系统</a><div class="blog-slider__text">介绍I/O设备的分类与特性，详解程序查询、中断与DMA三种控制方式，分析中断系统的处理机制，理解设备与主机的信息交换过程。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/f75b3d6f.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/d64a2c5e.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112938.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-08-29</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/d64a2c5e.html&quot;);" href="javascript:void(0);" alt="">第 5 章 中央处理器</a><div class="blog-slider__text">详解CPU的功能组成与工作原理，分析时序系统的作用，对比微程序与硬布线控制方式，介绍流水线技术的性能优化机制。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/d64a2c5e.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/reggie-deployment.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112618.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-09-02</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/reggie-deployment.html&quot;);" href="javascript:void(0);" alt="">瑞吉外卖：Linux环境与自动化部署</a><div class="blog-slider__text">详解瑞吉外卖部署流程，包括Linux环境配置、Git版本管理、自动化脚本与项目发布实践。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/reggie-deployment.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/b93e5f6d.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112938.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-08-29</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/b93e5f6d.html&quot;);" href="javascript:void(0);" alt="">第 4 章 指令系统</a><div class="blog-slider__text">详解指令的基本格式与寻址方式，对比CISC与RISC体系结构特点，分析指令的执行流程，理解指令系统对硬件的适配关系。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/b93e5f6d.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/ce4585c2.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2024_1123_155656.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-08-30</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/ce4585c2.html&quot;);" href="javascript:void(0);" alt="">前端实现：界面与交互逻辑</a><div class="blog-slider__text">详解苍穹外卖前端开发实现，包括Vue组件架构设计、核心页面（登录、首页、订单页）开发，接口交互封装与状态管理，确保前端界面与后端服务高效协同。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/ce4585c2.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/reggie-optimization.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112938.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-09-02</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/reggie-optimization.html&quot;);" href="javascript:void(0);" alt="">瑞吉外卖：性能优化与架构升级</a><div class="blog-slider__text">详解瑞吉外卖优化方案，包括Redis缓存应用、数据库读写分离、系统架构升级等性能提升手段。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/reggie-optimization.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/a81d4c7b.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112618.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-08-29</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/a81d4c7b.html&quot;);" href="javascript:void(0);" alt="">第 3 章 存储系统</a><div class="blog-slider__text">分析存储系统的层次结构设计，详解主存储器的组成与工作流程，阐述Cache的映射方式与替换策略，介绍存储器性能优化方法。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/a81d4c7b.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/d67b0a8b.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112626.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-08-30</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/d67b0a8b.html&quot;);" href="javascript:void(0);" alt="">核心功能开发：业务流程实现</a><div class="blog-slider__text">聚焦苍穹外卖核心业务功能开发，详解用户管理、菜品管理、订单全流程及购物车交互逻辑，结合数据统计功能实现业务闭环，覆盖项目核心场景。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/d67b0a8b.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/e72f3b9c.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112938.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-08-29</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/e72f3b9c.html&quot;);" href="javascript:void(0);" alt="">第 2 章 数据的表示与计算</a><div class="blog-slider__text">详解数制转换规则，阐述定点数与浮点数的表示方法，分析补码运算机制，介绍ALU的功能与实现，掌握数据在计算机中的处理方式。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/e72f3b9c.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/b85186f.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112938.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-08-30</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/b85186f.html&quot;);" href="javascript:void(0);" alt="">基础开发：环境搭建与核心配置</a><div class="blog-slider__text">详解苍穹外卖项目基础开发流程，包括本地开发环境搭建、数据库表结构设计与初始化，核心配置（跨域、日志等）及基础工具类实现，构建项目开发基石。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/b85186f.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/reggie-business.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2024_1123_160146.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-09-02</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/reggie-business.html&quot;);" href="javascript:void(0);" alt="">瑞吉外卖：核心业务功能开发</a><div class="blog-slider__text">详解瑞吉外卖后端核心业务实现，包括员工管理、菜品分类、订单流程等功能的接口与逻辑开发。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/reggie-business.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/reggie-business.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2024_1123_160146.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-09-02</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/reggie-business.html&quot;);" href="javascript:void(0);" alt="">瑞吉外卖：核心业务功能开发</a><div class="blog-slider__text">详解瑞吉外卖后端核心业务实现，包括员工管理、菜品分类、订单流程等功能的接口与逻辑开发。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/reggie-business.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/bae4ff13.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2024_1123_160146.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-03-12</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/bae4ff13.html&quot;);" href="javascript:void(0);" alt="">Redis</a><div class="blog-slider__text">Redis 作为内存 NoSQL 数据库的定位，支持 String/Hash 等多数据结构，具备 RDB/AOF 持久化与主从高可用，核心用于缓存、分布式锁，性能高效。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/bae4ff13.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/c45d1e8a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112938.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-08-29</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/c45d1e8a.html&quot;);" href="javascript:void(0);" alt="">第 1 章 计算机系统概述</a><div class="blog-slider__text">介绍计算机系统的硬件与软件组成，详解五大功能部件及总线工作机制，阐述指令集体系结构的核心作用，建立计算机系统的整体认知。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/c45d1e8a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/25e0fe54.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112758.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-08-30</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/25e0fe54.html&quot;);" href="javascript:void(0);" alt="">项目概述：架构与需求分析</a><div class="blog-slider__text">全面解析苍穹外卖项目的整体规划，包括项目背景、核心需求、技术栈选型依据，详解系统架构设计与开发规范，为项目开发提供整体指导。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/25e0fe54.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/77666db.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112626.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-04-07</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/77666db.html&quot;);" href="javascript:void(0);" alt="">王道计组pdf</a><div class="blog-slider__text">计算机组成原理</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/77666db.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/833e46bb.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112650.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-08-29</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/833e46bb.html&quot;);" href="javascript:void(0);" alt="">第 2 章 进程与线程：并发管理核心</a><div class="blog-slider__text">讲解进程与线程的定义、状态转换及控制逻辑，分析进程调度策略，阐述进程同步互斥（PV 操作）与死锁的处理机制，是操作系统并发管理的核心。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/833e46bb.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/790dfc8c.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2024_1123_160146.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-08-29</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/790dfc8c.html&quot;);" href="javascript:void(0);" alt="">第 4 章 文件管理：存储与访问机制</a><div class="blog-slider__text">介绍文件的逻辑与物理结构，讲解目录管理（按名存取）、索引节点功能及外存空闲空间分配策略，实现文件的安全存储与高效共享。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/790dfc8c.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/ce20e5e9.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112813.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-08-29</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/ce20e5e9.html&quot;);" href="javascript:void(0);" alt="">第 3 章 内存管理：地址映射与虚拟内存</a><div class="blog-slider__text">覆盖内存分配方式（连续/分页/分段）与地址转换机制，详解虚拟内存技术、请求分页流程及页面置换策略，解决多道程序下内存利用率与地址映射问题。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/ce20e5e9.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/169339cb.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112618.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-08-29</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/169339cb.html&quot;);" href="javascript:void(0);" alt="">第 5 章 输入输出管理：设备协同与优化</a><div class="blog-slider__text">详解I/O设备分类与控制方式（程序直接控制/DMA/通道），分析磁盘结构与调度策略，介绍SPOOLing等I/O优化技术，保障设备与CPU、内存的高效协同。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/169339cb.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/b328aa63.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112618.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-08-29</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/b328aa63.html&quot;);" href="javascript:void(0);" alt="">第 1 章 操作系统概述：计算机系统基础</a><div class="blog-slider__text">阐述操作系统的定义与核心功能，详解四大特征（并发 / 共享 / 虚拟 / 异步）、处理器运行模式及系统结构分类，介绍 OS 引导流程，奠定操作系统认知基础。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/b328aa63.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/79666db.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112855.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-03-12</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/79666db.html&quot;);" href="javascript:void(0);" alt="">数据结构</a><div class="blog-slider__text">数据结构的核心是高效组织数据，区分逻辑结构（线性 / 非线性）与物理结构（顺序 / 链式），覆盖数组、树、图等核心类型，为优化算法效率、支撑工程应用奠定基础。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/79666db.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/reggie-overview.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2024_1123_160146.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-09-02</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/reggie-overview.html&quot;);" href="javascript:void(0);" alt="">瑞吉外卖：项目概述与整体架构</a><div class="blog-slider__text">全面解析瑞吉外卖项目背景、技术选型、整体架构设计及核心业务流程，建立项目全局认知。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/reggie-overview.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;post/b8b0eacd.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://obsidian-1322827540.cos.ap-guangzhou.myqcloud.com/img/Screenshot_2025_0314_112758.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-03-12</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;post/b8b0eacd.html&quot;);" href="javascript:void(0);" alt="">java基础</a><div class="blog-slider__text">Java基础</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;post/b8b0eacd.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body></html>